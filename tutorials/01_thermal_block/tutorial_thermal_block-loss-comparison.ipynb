{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TUTORIAL 01 - Thermal block problem\n",
    "**_Keywords: certified reduced basis method, scalar problem_**\n",
    "\n",
    "### 1. Introduction\n",
    "In this Tutorial, we consider steady heat conduction in a two-dimensional domain $\\Omega$.\n",
    "\n",
    "<img src=\"data/thermal_block.png\" />\n",
    "\n",
    "We define two subdomains $\\Omega_1$ and $\\Omega_2$, such that\n",
    "1. $\\Omega_1$ is a disk centered at the origin of radius $r_0=0.5$, and\n",
    "2. $\\Omega_2=\\Omega/\\ \\overline{\\Omega_1}$. \n",
    "\n",
    "The conductivity $\\kappa$ is assumed to be constant on $\\Omega_1$ and $\\Omega_2$, i.e.\n",
    "$$\n",
    "\\kappa|_{\\Omega_1}=\\kappa_0 \\quad \\textrm{and} \\quad \\kappa|_{\\Omega_2}=1.\n",
    "$$\n",
    "\n",
    "For this problem, we consider $P=2$ parameters:\n",
    "1. the first one is related to the conductivity in $\\Omega_1$, i.e. $\\mu_0\\equiv k_0$ (_note that parameters numbering is zero-based_);\n",
    "2. the second parameter $\\mu_1$ takes into account the constant heat flux over $\\Gamma_{base}$.\n",
    "\n",
    "The parameter vector $\\boldsymbol{\\mu}$ is thus given by \n",
    "$$\n",
    "\\boldsymbol{\\mu} = (\\mu_0,\\mu_1)\n",
    "$$\n",
    "on the parameter domain\n",
    "$$\n",
    "\\mathbb{P}=[0.1,10]\\times[-1,1].\n",
    "$$\n",
    "\n",
    "In this problem we model the heat transfer process due to the heat flux over the bottom boundary $\\Gamma_{base}$ and the following conditions on the remaining boundaries:\n",
    "* the left and right boundaries $\\Gamma_{side}$ are insulated,\n",
    "* the top boundary $\\Gamma_{top}$ is kept at a reference temperature (say, zero),\n",
    "\n",
    "with the aim of measuring the average temperature on $\\Gamma_{base}$.\n",
    "\n",
    "In order to obtain a faster evaluation (yet, provably accurate) of the output of interest we propose to use a certified reduced basis approximation for the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Parametrized formulation\n",
    "\n",
    "Let $u(\\boldsymbol{\\mu})$ be the temperature in the domain $\\Omega$.\n",
    "\n",
    "The strong formulation of the parametrized problem is given by:\n",
    "<center>for a given parameter $\\boldsymbol{\\mu}\\in\\mathbb{P}$, find $u(\\boldsymbol{\\mu})$ such that</center>\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "\t- \\text{div} (\\kappa(\\mu_0)\\nabla u(\\boldsymbol{\\mu})) = 0 & \\text{in } \\Omega,\\\\\n",
    "\tu(\\boldsymbol{\\mu}) = 0 & \\text{on } \\Gamma_{top},\\\\\n",
    "\t\\kappa(\\mu_0)\\nabla u(\\boldsymbol{\\mu})\\cdot \\mathbf{n} = 0 & \\text{on } \\Gamma_{side},\\\\\n",
    "\t\\kappa(\\mu_0)\\nabla u(\\boldsymbol{\\mu})\\cdot \\mathbf{n} = \\mu_1 & \\text{on } \\Gamma_{base}.\n",
    "\\end{cases}\n",
    "$$\n",
    "<br>\n",
    "\n",
    "where \n",
    "* $\\mathbf{n}$ denotes the outer normal to the boundaries $\\Gamma_{side}$ and $\\Gamma_{base}$,\n",
    "* the conductivity $\\kappa(\\mu_0)$ is defined as follows:\n",
    "$$\n",
    "\\kappa(\\mu_0) =\n",
    "\\begin{cases}\n",
    "\t\\mu_0 & \\text{in } \\Omega_1,\\\\\n",
    "\t1 & \\text{in } \\Omega_2,\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The corresponding weak formulation reads:\n",
    "<center>for a given parameter $\\boldsymbol{\\mu}\\in\\mathbb{P}$, find $u(\\boldsymbol{\\mu})\\in\\mathbb{V}$ such that</center>\n",
    "\n",
    "$$a\\left(u(\\boldsymbol{\\mu}),v;\\boldsymbol{\\mu}\\right)=f(v;\\boldsymbol{\\mu})\\quad \\forall v\\in\\mathbb{V}$$\n",
    "\n",
    "where\n",
    "\n",
    "* the function space $\\mathbb{V}$ is defined as\n",
    "$$\n",
    "\\mathbb{V} = \\{v\\in H^1(\\Omega) : v|_{\\Gamma_{top}}=0\\}\n",
    "$$\n",
    "* the parametrized bilinear form $a(\\cdot, \\cdot; \\boldsymbol{\\mu}): \\mathbb{V} \\times \\mathbb{V} \\to \\mathbb{R}$ is defined by\n",
    "$$a(u, v;\\boldsymbol{\\mu})=\\int_{\\Omega} \\kappa(\\mu_0)\\nabla u\\cdot \\nabla v \\ d\\boldsymbol{x},$$\n",
    "* the parametrized linear form $f(\\cdot; \\boldsymbol{\\mu}): \\mathbb{V} \\to \\mathbb{R}$ is defined by\n",
    "$$f(v; \\boldsymbol{\\mu})= \\mu_1\\int_{\\Gamma_{base}}v \\ ds.$$\n",
    "\n",
    "The (compliant) output of interest $s(\\boldsymbol{\\mu})$ given by\n",
    "$$s(\\boldsymbol{\\mu}) = \\mu_1\\int_{\\Gamma_{base}} u(\\boldsymbol{\\mu})$$\n",
    "is computed for each $\\boldsymbol{\\mu}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from mlnics import NN, Losses, Normalization, RONNData, IO, Training, ErrorAnalysis\n",
    "from dolfin import *\n",
    "from rbnics import *\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Affine decomposition\n",
    "\n",
    "For this problem the affine decomposition is straightforward:\n",
    "$$a(u,v;\\boldsymbol{\\mu})=\\underbrace{\\mu_0}_{\\Theta^{a}_0(\\boldsymbol{\\mu})}\\underbrace{\\int_{\\Omega_1}\\nabla u \\cdot \\nabla v \\ d\\boldsymbol{x}}_{a_0(u,v)} \\ + \\  \\underbrace{1}_{\\Theta^{a}_1(\\boldsymbol{\\mu})}\\underbrace{\\int_{\\Omega_2}\\nabla u \\cdot \\nabla v \\ d\\boldsymbol{x}}_{a_1(u,v)},$$\n",
    "$$f(v; \\boldsymbol{\\mu}) = \\underbrace{\\mu_1}_{\\Theta^{f}_0(\\boldsymbol{\\mu})} \\underbrace{\\int_{\\Gamma_{base}}v \\ ds}_{f_0(v)}.$$\n",
    "We will implement the numerical discretization of the problem in the class\n",
    "```\n",
    "class ThermalBlock(EllipticCoerciveCompliantProblem):\n",
    "```\n",
    "by specifying the coefficients $\\Theta^{a}_*(\\boldsymbol{\\mu})$ and $\\Theta^{f}_*(\\boldsymbol{\\mu})$ in the method\n",
    "```\n",
    "    def compute_theta(self, term):     \n",
    "```\n",
    "and the bilinear forms $a_*(u, v)$ and linear forms $f_*(v)$ in\n",
    "```\n",
    "    def assemble_operator(self, term):\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThermalBlock(EllipticCoerciveCompliantProblem):\n",
    "\n",
    "    # Default initialization of members\n",
    "    def __init__(self, V, **kwargs):\n",
    "        # Call the standard initialization\n",
    "        EllipticCoerciveCompliantProblem.__init__(self, V, **kwargs)\n",
    "        # ... and also store FEniCS data structures for assembly\n",
    "        assert \"subdomains\" in kwargs\n",
    "        assert \"boundaries\" in kwargs\n",
    "        self.subdomains, self.boundaries = kwargs[\"subdomains\"], kwargs[\"boundaries\"]\n",
    "        self.u = TrialFunction(V)\n",
    "        self.v = TestFunction(V)\n",
    "        self.dx = Measure(\"dx\")(subdomain_data=self.subdomains)\n",
    "        self.ds = Measure(\"ds\")(subdomain_data=self.boundaries)\n",
    "\n",
    "    # Return custom problem name\n",
    "    def name(self):\n",
    "        return \"ThermalBlock\"\n",
    "\n",
    "    # Return the alpha_lower bound.\n",
    "    def get_stability_factor_lower_bound(self):\n",
    "        return min(self.compute_theta(\"a\"))\n",
    "\n",
    "    # Return theta multiplicative terms of the affine expansion of the problem.\n",
    "    def compute_theta(self, term):\n",
    "        mu = self.mu\n",
    "        if term == \"a\":\n",
    "            theta_a0 = mu[0]\n",
    "            theta_a1 = 1.\n",
    "            return (theta_a0, theta_a1)\n",
    "        elif term == \"f\":\n",
    "            theta_f0 = mu[1]\n",
    "            return (theta_f0,)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid term for compute_theta().\")\n",
    "\n",
    "    # Return forms resulting from the discretization of the affine expansion of the problem operators.\n",
    "    def assemble_operator(self, term):\n",
    "        v = self.v\n",
    "        dx = self.dx\n",
    "        if term == \"a\":\n",
    "            u = self.u\n",
    "            a0 = inner(grad(u), grad(v)) * dx(1)\n",
    "            a1 = inner(grad(u), grad(v)) * dx(2)\n",
    "            return (a0, a1)\n",
    "        elif term == \"f\":\n",
    "            ds = self.ds\n",
    "            f0 = v * ds(1)\n",
    "            return (f0,)\n",
    "        elif term == \"dirichlet_bc\":\n",
    "            bc0 = [DirichletBC(self.V, Constant(0.0), self.boundaries, 3)]\n",
    "            return (bc0,)\n",
    "        elif term == \"inner_product\":\n",
    "            u = self.u\n",
    "            x0 = inner(grad(u), grad(v)) * dx\n",
    "            return (x0,)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid term for assemble_operator().\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Main program\n",
    "### 4.1. Read the mesh for this problem\n",
    "The mesh was generated by the [data/generate_mesh.ipynb](data/generate_mesh.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = Mesh(\"data/thermal_block.xml\")\n",
    "subdomains = MeshFunction(\"size_t\", mesh, \"data/thermal_block_physical_region.xml\")\n",
    "boundaries = MeshFunction(\"size_t\", mesh, \"data/thermal_block_facet_region.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Create Finite Element space (Lagrange P1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = FunctionSpace(mesh, \"Lagrange\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Allocate an object of the ThermalBlock class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = ThermalBlock(V, subdomains=subdomains, boundaries=boundaries)\n",
    "mu_range = [(0.1, 10.0), (-1.0, 1.0)]\n",
    "problem.set_mu_range(mu_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Prepare reduction with a reduced basis method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction_method = PODGalerkin(problem)#ReducedBasis(problem)\n",
    "reduction_method.set_Nmax(20)\n",
    "reduction_method.set_tolerance(1e-10)#1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Perform the offline phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduction_method.initialize_training_set(100)\n",
    "reduced_problem = reduction_method.offline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5b Train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_normalization = Normalization.StandardNormalization(input_normalization=True)\n",
    "output_normalization = Normalization.StandardNormalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction_method.initialize_testing_set(100)\n",
    "test_mu = torch.tensor(reduction_method.testing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pinn_net  = NN.RONN(problem, reduction_method, n_neurons=20)\n",
    "pinn_loss = Losses.PINN_Loss(pinn_net, output_normalization)\n",
    "data      = RONNData.RONNDataLoader(pinn_net, validation_proportion=0.2)\n",
    "optimizer = torch.optim.Adam(pinn_net.parameters(), lr=0.001)\n",
    "\n",
    "loaded, starting_epoch = IO.initialize_parameters(\n",
    "    pinn_net, data, optimizer, \n",
    "    suffix=pinn_loss.name(), by_validation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.79980980963178 \tLoss(validation) = 1.5519672417099128\n",
      "100 0.11722890806225013 \tLoss(validation) = 0.06819805098379675\n",
      "200 0.07358001134069943 \tLoss(validation) = 0.042672300341602194\n",
      "300 0.06431083443313138 \tLoss(validation) = 0.0355968061081449\n",
      "400 0.05618471394410303 \tLoss(validation) = 0.029008178030453025\n",
      "500 0.04741432300171573 \tLoss(validation) = 0.02217987246098288\n",
      "600 0.037971713254865466 \tLoss(validation) = 0.015540633936772427\n",
      "700 0.029168638558878697 \tLoss(validation) = 0.010600030093477306\n",
      "800 0.022430440047414135 \tLoss(validation) = 0.008316239645576031\n",
      "900 0.018139142829887284 \tLoss(validation) = 0.00802636472741002\n",
      "1000 0.01564439237396074 \tLoss(validation) = 0.00831368054883625\n",
      "1100 0.014016248066655431 \tLoss(validation) = 0.00827150654958674\n",
      "1200 0.012731637254886297 \tLoss(validation) = 0.007776505442831627\n",
      "1300 0.01158320072967247 \tLoss(validation) = 0.006959426061394785\n",
      "1400 0.010494505696414316 \tLoss(validation) = 0.00597139584003091\n",
      "1500 0.009464626871057489 \tLoss(validation) = 0.004983430073489125\n",
      "1600 0.008527749871978671 \tLoss(validation) = 0.004114692577094092\n",
      "1700 0.007711522746893615 \tLoss(validation) = 0.0034056679166605207\n",
      "1800 0.007022760604607467 \tLoss(validation) = 0.0028541115916726778\n",
      "1900 0.006447763805903563 \tLoss(validation) = 0.002433529609941574\n",
      "2000 0.005962024493051922 \tLoss(validation) = 0.002112981429803874\n",
      "2100 0.005541168836306901 \tLoss(validation) = 0.0018665691263274708\n",
      "2200 0.00516634685003419 \tLoss(validation) = 0.0016729862240851539\n",
      "2300 0.00482485663108091 \tLoss(validation) = 0.0015145648668429934\n",
      "2400 0.004508889868262104 \tLoss(validation) = 0.0013778600408586449\n",
      "2500 0.004213948264393983 \tLoss(validation) = 0.0012541091029842188\n",
      "2600 0.003937348329130232 \tLoss(validation) = 0.0011387411961396477\n",
      "2700 0.0036769745000521797 \tLoss(validation) = 0.0010299866434374646\n",
      "2800 0.0034306929084033607 \tLoss(validation) = 0.0009274670488618811\n",
      "2900 0.003196336157520048 \tLoss(validation) = 0.0008312102379387841\n",
      "3000 0.0029719970334109534 \tLoss(validation) = 0.000741403891011856\n",
      "3100 0.002756310396298177 \tLoss(validation) = 0.0006583939340316853\n",
      "3200 0.00254860910097352 \tLoss(validation) = 0.0005826968003991813\n",
      "3300 0.0023489203682371613 \tLoss(validation) = 0.0005149290859098029\n",
      "3400 0.0021578347692933373 \tLoss(validation) = 0.00045565353208040435\n",
      "3500 0.0019762791679394888 \tLoss(validation) = 0.00040524962743246145\n",
      "3600 0.0018052213767786925 \tLoss(validation) = 0.00036380818256289554\n",
      "3700 0.0016453857739009707 \tLoss(validation) = 0.00033107784982225254\n",
      "3800 0.0014970581787312415 \tLoss(validation) = 0.000306448187638075\n",
      "3900 0.0013600159644091988 \tLoss(validation) = 0.0002889774263627952\n",
      "4000 0.0012336081649765753 \tLoss(validation) = 0.0002774509217353148\n",
      "4100 0.0011169250568592915 \tLoss(validation) = 0.0002704970267559607\n",
      "4200 0.001009009975258791 \tLoss(validation) = 0.00026669857092411696\n",
      "4300 0.0009090380875956111 \tLoss(validation) = 0.0002647387868730602\n",
      "4400 0.0008164398400746619 \tLoss(validation) = 0.0002634893170442232\n",
      "4500 0.0007309334032920256 \tLoss(validation) = 0.0002621154798027973\n",
      "4600 0.000652479409940465 \tLoss(validation) = 0.0002601267478660288\n",
      "4700 0.0005811614648184096 \tLoss(validation) = 0.0002573606881483983\n",
      "4800 0.0005174744190408362 \tLoss(validation) = 0.00025412928240825094\n",
      "4900 0.0004613863988524269 \tLoss(validation) = 0.0002504955909237453\n",
      "5000 0.00041264886797249146 \tLoss(validation) = 0.00024654217169628326\n",
      "5100 0.000370264551039256 \tLoss(validation) = 0.0002423357625212984\n",
      "5200 0.0003333781985095885 \tLoss(validation) = 0.00023810698258591584\n",
      "5300 0.00030162558723210997 \tLoss(validation) = 0.0002317340161846395\n",
      "5400 0.0002738177008062421 \tLoss(validation) = 0.00022532150125714867\n",
      "5500 0.00024965228824134144 \tLoss(validation) = 0.00021781186674044414\n",
      "5600 0.00022800478726903427 \tLoss(validation) = 0.00020995321779551475\n",
      "5700 0.0002121733540581691 \tLoss(validation) = 0.000204333185746837\n",
      "5800 0.00019211685811457293 \tLoss(validation) = 0.0001922073767602827\n",
      "5900 0.00017730532313800181 \tLoss(validation) = 0.00018460681009559144\n",
      "6000 0.00016325044285210697 \tLoss(validation) = 0.0001734629071637748\n",
      "6100 0.00015083756346862508 \tLoss(validation) = 0.00016404690991138446\n",
      "6200 0.0001398971895570286 \tLoss(validation) = 0.00015476338753121505\n",
      "6300 0.0001297652620299839 \tLoss(validation) = 0.00014582835149512934\n",
      "6400 0.00015421552587796466 \tLoss(validation) = 0.0001743188793967895\n",
      "6500 0.00011227313762028016 \tLoss(validation) = 0.00012874308039157882\n",
      "6600 0.00010460073305455642 \tLoss(validation) = 0.00012073877722667622\n",
      "6700 9.774502442241395e-05 \tLoss(validation) = 0.00011314716891526655\n",
      "6800 9.143764487238384e-05 \tLoss(validation) = 0.0001058763708180849\n",
      "6900 9.010339096212665e-05 \tLoss(validation) = 0.00010619707441798625\n",
      "7000 8.03761661307323e-05 \tLoss(validation) = 9.25548462631433e-05\n",
      "7100 7.563974912879124e-05 \tLoss(validation) = 8.706145210023112e-05\n",
      "7200 7.110156156411084e-05 \tLoss(validation) = 8.072678809561588e-05\n",
      "7300 6.70029661108537e-05 \tLoss(validation) = 7.54261822840457e-05\n",
      "7400 7.040795710749679e-05 \tLoss(validation) = 9.459070737335268e-05\n",
      "7500 5.985576227770364e-05 \tLoss(validation) = 6.58438926817527e-05\n",
      "7600 5.667836562877617e-05 \tLoss(validation) = 6.152781894621024e-05\n",
      "7700 6.912366812048378e-05 \tLoss(validation) = 8.340341313527596e-05\n",
      "7800 5.1016325299646263e-05 \tLoss(validation) = 5.3843018939515374e-05\n",
      "7900 4.8469531024134095e-05 \tLoss(validation) = 5.043873891634008e-05\n",
      "8000 4.617863385415346e-05 \tLoss(validation) = 4.7204293359623165e-05\n",
      "8100 4.403308278823677e-05 \tLoss(validation) = 4.440168970733814e-05\n",
      "8200 4.2222491400544865e-05 \tLoss(validation) = 4.25434695509036e-05\n",
      "8300 4.020025988456871e-05 \tLoss(validation) = 3.9385270744880145e-05\n",
      "8400 3.846502989472909e-05 \tLoss(validation) = 3.7286289624456716e-05\n",
      "8500 3.689705227579586e-05 \tLoss(validation) = 3.520249009891413e-05\n",
      "8600 3.540688659669141e-05 \tLoss(validation) = 3.3378411069113635e-05\n",
      "8700 4.086196806115512e-05 \tLoss(validation) = 5.9693481667635755e-05\n",
      "8800 3.2748030590397645e-05 \tLoss(validation) = 3.02789208191105e-05\n",
      "8900 3.1533721464333396e-05 \tLoss(validation) = 2.8925777031796198e-05\n",
      "9000 3.161425203990999e-05 \tLoss(validation) = 2.8302836783403254e-05\n",
      "9100 2.9345160475170707e-05 \tLoss(validation) = 2.662163522649048e-05\n",
      "9200 2.9964444146777533e-05 \tLoss(validation) = 3.085686426973159e-05\n",
      "9300 2.7405384086780633e-05 \tLoss(validation) = 2.466171117955362e-05\n",
      "9400 2.651001271190393e-05 \tLoss(validation) = 2.393979008808581e-05\n",
      "9500 2.6415098147451853e-05 \tLoss(validation) = 2.2913954505201436e-05\n",
      "9600 2.4881700601808238e-05 \tLoss(validation) = 2.2538963431833776e-05\n",
      "9700 5.952340221000492e-05 \tLoss(validation) = 0.00010031748781792784\n",
      "9800 2.3420033982943076e-05 \tLoss(validation) = 2.1312527172988394e-05\n",
      "9900 2.2735966502874588e-05 \tLoss(validation) = 2.088536620886606e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlnics.Losses.PINN_Loss at 0x12fbbaf80>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Training.normalize_and_train(\n",
    "    pinn_net, data, pinn_loss, optimizer,\n",
    "    input_normalization, epochs=10000, starting_epoch=starting_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = Training.plot_loss(pinn_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ErrorAnalysis.error_analysis_fixed_net(\n",
    "    pinn_net, test_mu, input_normalization, output_normalization\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ErrorAnalysis.plot_solution_difference(\n",
    "    pinn_net, (8.0, -1.0), input_normalization, output_normalization\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdnn_net  = NN.RONN(problem, reduction_method, n_neurons=20)\n",
    "pdnn_loss = Losses.PDNN_Loss(pdnn_net, output_normalization)\n",
    "data      = RONNData.RONNDataLoader(pdnn_net, validation_proportion=0.2)\n",
    "optimizer = torch.optim.Adam(pdnn_net.parameters(), lr=0.001)\n",
    "\n",
    "loaded, starting_epoch = IO.initialize_parameters(\n",
    "    pdnn_net, data, optimizer, \n",
    "    suffix=pdnn_loss.name(), by_validation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Training.normalize_and_train(\n",
    "    pdnn_net, data, pdnn_loss, optimizer,\n",
    "    input_normalization, epochs=10000, starting_epoch=starting_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = Training.plot_loss(pdnn_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ErrorAnalysis.error_analysis_fixed_net(\n",
    "    pdnn_net, test_mu, input_normalization, output_normalization\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ErrorAnalysis.plot_solution_difference(\n",
    "    pdnn_net, (8.0, -1.0), input_normalization, output_normalization\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prnn_net  = NN.RONN(problem, reduction_method, n_neurons=20)\n",
    "prnn_loss = Losses.PRNN_Loss(prnn_net, output_normalization, omega=1.)\n",
    "data      = RONNData.RONNDataLoader(prnn_net, validation_proportion=0.2)\n",
    "optimizer = torch.optim.Adam(prnn_net.parameters(), lr=0.001)\n",
    "\n",
    "loaded, starting_epoch = IO.initialize_parameters(\n",
    "    prnn_net, data, optimizer, \n",
    "    suffix=prnn_loss.name(), by_validation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Training.normalize_and_train(\n",
    "    prnn_net, data, prnn_loss, optimizer,\n",
    "    input_normalization, epochs=10000, starting_epoch=starting_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_list = Training.plot_loss(prnn_net, separate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ErrorAnalysis.error_analysis_fixed_net(\n",
    "    prnn_net, test_mu, input_normalization, output_normalization\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ErrorAnalysis.plot_solution_difference(\n",
    "    prnn_net, (8.0, -1.0), input_normalization, output_normalization\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nets = dict()\n",
    "nets[\"pinn_net\"] = pinn_net\n",
    "nets[\"pdnn_net\"] = pdnn_net\n",
    "nets[\"prnn_net\"] = prnn_net\n",
    "\n",
    "_ = ErrorAnalysis.error_analysis_by_network(\n",
    "    nets, test_mu, input_normalization, output_normalization, euclidean=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7. Perform an error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduction_method.initialize_testing_set(100)\n",
    "reduction_method.error_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8. Perform a speedup analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction_method.initialize_testing_set(100)\n",
    "reduction_method.speedup_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Assignments\n",
    "1. Assume now also the conductivity on $\\Omega_2$ to be paramerized, i.e.\n",
    "$$\n",
    "\\kappa(\\mu_0, \\mu_2) =\n",
    "\\begin{cases}\n",
    "\t\\mu_0 & \\text{in } \\Omega_1,\\\\\n",
    "\t\\mu_2 & \\text{in } \\Omega_2,\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "for\n",
    "$$\n",
    "\\boldsymbol{\\mu} = (\\mu_0, \\mu_1, \\mu_2) \\in \\mathbb{P}=[0.1,10]\\times[-1,1] \\times [0.1,10].\n",
    "$$\n",
    "Create a copy of this notebook and update the code accordingly. _Suggestion: for every new notebook copy change the value returned by the name() method of the ThermalBlock class to avoid conflicts between this notebook and your copy_.\n",
    "\n",
    "2. Create another copy of this notebook, and change the model reduction technique from certified reduced basis to POD-Galerkin. Compare the results of the error analysis and speedup analysis for the two reduction techniques.\n",
    "\n",
    "3. [*] Why is the $H^1$ seminorm used on $\\mathbb{V}$? What would you need to change by using the $H^1$ norm instead?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
