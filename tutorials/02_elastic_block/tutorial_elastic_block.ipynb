{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TUTORIAL 02 - Elastic block problem\n",
    "**_Keywords: POD-Galerkin method, vector problem_**\n",
    "\n",
    "### 1. Introduction\n",
    "In this Tutorial we consider a linear elasticity problem in a two-dimensional square domain $\\Omega$.\n",
    "\n",
    "The domain is partioned in nine square subdomains.\n",
    "\n",
    "Parameters of this problem include Young moduli of each subdomain, as well as lateral traction on the right side of square. In particular:\n",
    "* the ratio between the Young modulus of the each subdomain $\\Omega_{p+1}$, $p=0,\\dots,7$ and the top-right subdomain $\\Omega_9$ is denoted by $\\mu_p$, being\n",
    "\n",
    "$$\n",
    "\\mu_p \\in \\left[1, 100\\right] \\qquad \\text{for }p=0,\\dots,7.\n",
    "$$\n",
    "\n",
    "* the horizontal tractions on each boundary $\\Gamma_{p-6}$, $p=8,\\dots,10$, being\n",
    "\n",
    "$$\n",
    "\\mu_p \\in \\left[-1,1\\right] \\qquad \\text{for } p=8,\\dots, 10.\n",
    "$$\n",
    "\n",
    "For what concerns the remaining boundaries, the left boundary $\\Gamma_6$ is clamped, while the top and bottom boundaries $\\Gamma_1 \\cup \\Gamma_5$ are traction free.\n",
    "\n",
    "The parameter vector $\\boldsymbol{\\mu}$ is thus given by \n",
    "$$\n",
    "\\boldsymbol{\\mu} = (\\mu_0, \\cdots,\\mu_{10})\n",
    "$$\n",
    "on the parameter domain\n",
    "$$\n",
    "\\mathbb{P}=[1,100]^8\\times[-1,1]^3.\n",
    "$$\n",
    "\n",
    "In order to obtain a faster approximation of the problem we pursue a model reduction by means of a POD-Galerkin reduced order method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Parametrized formulation\n",
    "\n",
    "Let $\\boldsymbol{u}(\\boldsymbol{\\mu})$ be the displacement in the domain $\\Omega$.\n",
    "\n",
    "In each subdomain $\\Omega_{p+1}$, $p=0,\\dots,7$, we assume an isotropic linear elastic material, characterized by the following Lam√® constants for plane strain\n",
    "$$\\lambda_1(\\mu_p) = \\frac{\\mu_p \\nu}{(1+\\nu)(1-2\\nu)},$$\n",
    "$$\\lambda_2(\\mu_p) = \\frac{\\mu_p}{2(1+\\nu)},$$\n",
    "for $\\nu=0.30$, with the following Piola-Kirchhoff tensor\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\pi}(\\boldsymbol{u}; \\mu_p) = \n",
    "\\lambda_1(\\mu_p)\\;\\text{tr}\\left[\\nabla_{S}\\boldsymbol{u}\\right]\\; \\boldsymbol{I} +\n",
    "2\\;\\lambda_2(\\mu_p)\\;\\nabla_{S}\\boldsymbol{u}\n",
    "$$\n",
    "where $\\nabla_{S}$ denotes the symmetric part of the gradient.\n",
    "\n",
    "Similarly, the Piola-Kirchhoff tensor in the top right subdomain $\\Omega_9$ is given by $\\boldsymbol{\\pi}(\\boldsymbol{u}; 1)$.\n",
    "\n",
    "Thus, the Piola-Kirchhoff tensor on the domain $\\Omega$ can be obtained as\n",
    "$$\n",
    "\\boldsymbol{P}(\\boldsymbol{u}; \\boldsymbol{\\mu}) = \n",
    "\\Lambda_1(\\boldsymbol{\\mu})\\;\\text{tr}\\left[\\nabla_{S}\\boldsymbol{u}\\right]\\; \\boldsymbol{I} +\n",
    "2\\;\\Lambda_2(\\boldsymbol{\\mu})\\;\\nabla_{S}\\boldsymbol{u}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\Lambda_1(\\boldsymbol{\\mu}) = \\sum_{p=0}^{7} \\lambda_1(\\mu_p) \\mathbb{1}_{\\Omega_{p+1}} + \\lambda_1(1) \\mathbb{1}_{\\Omega_{9}}\n",
    "$$\n",
    "$$\n",
    "\\Lambda_2(\\boldsymbol{\\mu}) = \\sum_{p=0}^{7} \\lambda_2(\\mu_p) \\mathbb{1}_{\\Omega_{p+1}} + \\lambda_2(1) \\mathbb{1}_{\\Omega_{9}}\n",
    "$$\n",
    "\n",
    "The strong formulation of the parametrized problem is given by: for a given parameter $\\boldsymbol{\\mu}\\in\\mathbb{P}$, find $\\boldsymbol{u}(\\boldsymbol{\\mu})$ such that\n",
    "$$\n",
    "\\begin{cases}\n",
    "\t- \\text{div} \\boldsymbol{P}(\\boldsymbol{u}(\\boldsymbol{\\mu}); \\boldsymbol{\\mu})) = 0 & \\text{in } \\Omega,\\\\\n",
    "    \\boldsymbol{P}(\\boldsymbol{u}(\\boldsymbol{\\mu}); \\boldsymbol{\\mu})) \\mathbf{n} = \\mathbf{0} & \\text{on } \\Gamma_{1},\\\\\n",
    "\t\\boldsymbol{P}(\\boldsymbol{u}(\\boldsymbol{\\mu}); \\boldsymbol{\\mu})) \\mathbf{n} = \\mu_p \\mathbf{n} & \\text{on } \\Gamma_{p-6}, p=8,\\dots, 10,\\\\\n",
    "    \\boldsymbol{P}(\\boldsymbol{u}(\\boldsymbol{\\mu}); \\boldsymbol{\\mu})) \\mathbf{n} = \\mathbf{0} & \\text{on } \\Gamma_{5},\\\\\n",
    "\t\\boldsymbol{u}(\\boldsymbol{\\mu}) = \\boldsymbol{0} & \\text{on } \\Gamma_{6},\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "<br>\n",
    "\n",
    "where $\\mathbf{n}$ denotes the outer normal to the boundary $\\partial\\Omega$.\n",
    "\n",
    "The corresponding weak formulation reads: for a given parameter $\\boldsymbol{\\mu}\\in\\mathbb{P}$, find $u(\\boldsymbol{\\mu})\\in\\mathbb{V}$ such that\n",
    "\n",
    "$$a\\left(u(\\boldsymbol{\\mu}),v;\\boldsymbol{\\mu}\\right)=f(v;\\boldsymbol{\\mu})\\quad \\forall v\\in\\mathbb{V}$$\n",
    "\n",
    "where\n",
    "\n",
    "* the function space $\\mathbb{V}$ is defined as\n",
    "$$\n",
    "\\mathbb{V} = \\{\\boldsymbol{v}\\in H^1(\\Omega; \\mathbb{R}^2) : \\boldsymbol{v}|_{\\Gamma_{6}}=\\boldsymbol{0}\\}\n",
    "$$\n",
    "* the parametrized bilinear form $a(\\cdot, \\cdot; \\boldsymbol{\\mu}): \\mathbb{V} \\times \\mathbb{V} \\to \\mathbb{R}$ is defined by\n",
    "$$a(\\boldsymbol{u}, \\boldsymbol{v}; \\boldsymbol{\\mu})=\\int_{\\Omega}\n",
    "\\left\\{\n",
    "\\Lambda_1(\\boldsymbol{\\mu})\\;\\text{tr}\\left[\\nabla_{S}\\boldsymbol{u}\\right]\\;\\text{tr}\\left[\\nabla_{S}\\boldsymbol{v}\\right] + 2\\;\\Lambda_2(\\boldsymbol{\\mu})\\;\\nabla_{S}\\boldsymbol{u} : \\nabla_{S}\\boldsymbol{v}\n",
    "\\right\\}  d\\boldsymbol{x}\n",
    "$$,\n",
    "* the parametrized linear form $f(\\cdot; \\boldsymbol{\\mu}): \\mathbb{V} \\to \\mathbb{R}$ is defined by\n",
    "$$f(\\boldsymbol{v}; \\boldsymbol{\\mu})= \\sum_{p=8}^{10} \\mu_p \\int_{\\Gamma_{p-6}} \\boldsymbol{v} \\cdot \\mathbf{n} \\ ds$$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from mlnics import NN, Losses, Normalization, RONNData, IO, Training, ErrorAnalysis\n",
    "from dolfin import *\n",
    "from rbnics import *\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Affine decomposition\n",
    "\n",
    "For this problem the affine decomposition is straightforward. Indeed, owing to the definitions of $\\Lambda_1(\\boldsymbol{\\mu})$ and $\\Lambda_2(\\boldsymbol{\\mu})$, we have:\n",
    "$$\n",
    "a(\\boldsymbol{u}, \\boldsymbol{v}; \\boldsymbol{\\mu}) = \\sum_{p=0}^7 \\underbrace{\\mu_{\\color{red} p}}_{\\Theta^{a}_{\\color{red} p}(\\boldsymbol{\\mu})} \\underbrace{\\int_{\\Omega_{\\color{red}{p + 1}}}\n",
    "\\left\\{\\lambda_1(1)\\;\\text{tr}\\left[\\nabla_{S}\\boldsymbol{u}\\right]\\;\\text{tr}\\left[\\nabla_{S}\\boldsymbol{v}\\right] + 2\\;\\lambda_2(1)\\;\\nabla_{S}\\boldsymbol{u} : \\nabla_{S}\\boldsymbol{v} \\right\\}  d\\boldsymbol{x}}_{a_{\\color{red} p}(\\boldsymbol{u}, \\boldsymbol{v})} +\\\\\n",
    "\\underbrace{1}_{\\Theta^{a}_{\\color{red} 8}(\\boldsymbol{\\mu})} \\underbrace{\\int_{\\Omega_{\\color{red} 9}}\n",
    "\\left\\{\\lambda_1(1)\\;\\text{tr}\\left[\\nabla_{S}\\boldsymbol{u}\\right]\\;\\text{tr}\\left[\\nabla_{S}\\boldsymbol{v}\\right] + 2\\;\\lambda_2(1)\\;\\nabla_{S}\\boldsymbol{u} : \\nabla_{S}\\boldsymbol{v} \\right\\}  d\\boldsymbol{x}}_{a_{\\color{red} 8}(\\boldsymbol{u}, \\boldsymbol{v})}\\\\\n",
    "$$\n",
    "$$\n",
    "f(\\boldsymbol{v}; \\boldsymbol{\\mu}) = \n",
    "\\sum_{p=8}^{10} \\underbrace{\\mu_{\\color{red} p}}_{\\Theta^{f}_{\\color{red}{p-8}}(\\boldsymbol{\\mu})} \\underbrace{\\int_{\\Gamma_{\\color{red}{p-6}}} \\boldsymbol{v} \\cdot \\mathbf{n}}_{f_{\\color{red}{p-8}}(\\boldsymbol{v})}.\n",
    "$$\n",
    "\n",
    "We will implement the numerical discretization of the problem in the class\n",
    "```\n",
    "class ElasticBlock(EllipticCoerciveProblem):\n",
    "```\n",
    "by specifying the coefficients $\\Theta^{a}_*(\\boldsymbol{\\mu})$ and $\\Theta^{f}_*(\\boldsymbol{\\mu})$ in the method\n",
    "```\n",
    "    def compute_theta(self, term):     \n",
    "```\n",
    "and the bilinear forms $a_*(\\boldsymbol{u}, \\boldsymbol{v})$ and linear forms $f_*(\\boldsymbol{v})$ in\n",
    "```\n",
    "    def assemble_operator(self, term):\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElasticBlock(EllipticCoerciveProblem):\n",
    "\n",
    "    # Default initialization of members\n",
    "    def __init__(self, V, **kwargs):\n",
    "        # Call the standard initialization\n",
    "        EllipticCoerciveProblem.__init__(self, V, **kwargs)\n",
    "        # ... and also store FEniCS data structures for assembly\n",
    "        assert \"subdomains\" in kwargs\n",
    "        assert \"boundaries\" in kwargs\n",
    "        self.subdomains, self.boundaries = kwargs[\"subdomains\"], kwargs[\"boundaries\"]\n",
    "        self.u = TrialFunction(V)\n",
    "        self.v = TestFunction(V)\n",
    "        self.dx = Measure(\"dx\")(subdomain_data=self.subdomains)\n",
    "        self.ds = Measure(\"ds\")(subdomain_data=self.boundaries)\n",
    "        # ...\n",
    "        self.f = Constant((1.0, 0.0))\n",
    "        self.E = 1.0\n",
    "        self.nu = 0.3\n",
    "        self.lambda_1 = self.E * self.nu / ((1.0 + self.nu) * (1.0 - 2.0 * self.nu))\n",
    "        self.lambda_2 = self.E / (2.0 * (1.0 + self.nu))\n",
    "\n",
    "    # Return custom problem name\n",
    "    def name(self):\n",
    "        return \"ElasticBlock\"\n",
    "\n",
    "    # Return theta multiplicative terms of the affine expansion of the problem.\n",
    "    def compute_theta(self, term):\n",
    "        mu = self.mu\n",
    "        if term == \"a\":\n",
    "            theta_a0 = mu[0]\n",
    "            theta_a1 = 1.\n",
    "            theta_a2 = mu[1]\n",
    "            theta_a3 = 1.\n",
    "            theta_a4 = 1.\n",
    "            theta_a5 = 1.\n",
    "            theta_a6 = mu[2]\n",
    "            theta_a7 = 1.\n",
    "            theta_a8 = mu[3]\n",
    "            return (theta_a0, theta_a1, theta_a2, theta_a3, theta_a4, theta_a5, theta_a6, theta_a7, theta_a8)\n",
    "        elif term == \"f\":\n",
    "            theta_f0 = 1.\n",
    "            theta_f1 = mu[4]\n",
    "            theta_f2 = 1.\n",
    "            return (theta_f0, theta_f1, theta_f2)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid term for compute_theta().\")\n",
    "\n",
    "    # Return forms resulting from the discretization of the affine expansion of the problem operators.\n",
    "    def assemble_operator(self, term):\n",
    "        v = self.v\n",
    "        dx = self.dx\n",
    "        if term == \"a\":\n",
    "            u = self.u\n",
    "            a0 = self.elasticity(u, v) * dx(1)\n",
    "            a1 = self.elasticity(u, v) * dx(2)\n",
    "            a2 = self.elasticity(u, v) * dx(3)\n",
    "            a3 = self.elasticity(u, v) * dx(4)\n",
    "            a4 = self.elasticity(u, v) * dx(5)\n",
    "            a5 = self.elasticity(u, v) * dx(6)\n",
    "            a6 = self.elasticity(u, v) * dx(7)\n",
    "            a7 = self.elasticity(u, v) * dx(8)\n",
    "            a8 = self.elasticity(u, v) * dx(9)\n",
    "            return (a0, a1, a2, a3, a4, a5, a6, a7, a8)\n",
    "        elif term == \"f\":\n",
    "            ds = self.ds\n",
    "            f = self.f\n",
    "            f0 = inner(f, v) * ds(2)\n",
    "            f1 = inner(f, v) * ds(3)\n",
    "            f2 = inner(f, v) * ds(4)\n",
    "            return (f0, f1, f2)\n",
    "        elif term == \"dirichlet_bc\":\n",
    "            bc0 = [DirichletBC(self.V, Constant((0.0, 0.0)), self.boundaries, 6)]\n",
    "            return (bc0,)\n",
    "        elif term == \"inner_product\":\n",
    "            u = self.u\n",
    "            x0 = inner(u, v) * dx + inner(grad(u), grad(v)) * dx\n",
    "            return (x0,)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid term for assemble_operator().\")\n",
    "\n",
    "    # Auxiliary function to compute the elasticity bilinear form\n",
    "    def elasticity(self, u, v):\n",
    "        lambda_1 = self.lambda_1\n",
    "        lambda_2 = self.lambda_2\n",
    "        return 2.0 * lambda_2 * inner(sym(grad(u)), sym(grad(v))) + lambda_1 * tr(sym(grad(u))) * tr(sym(grad(v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Main program\n",
    "### 4.1. Read the mesh for this problem\n",
    "The mesh was generated by the [data/generate_mesh.ipynb](data/generate_mesh.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = Mesh(\"data/elastic_block.xml\")\n",
    "subdomains = MeshFunction(\"size_t\", mesh, \"data/elastic_block_physical_region.xml\")\n",
    "boundaries = MeshFunction(\"size_t\", mesh, \"data/elastic_block_facet_region.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Create Finite Element space (Lagrange P1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = VectorFunctionSpace(mesh, \"Lagrange\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Allocate an object of the ElasticBlock class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = ElasticBlock(V, subdomains=subdomains, boundaries=boundaries)\n",
    "mu_range = [\n",
    "    (1.0, 100.0),\n",
    "    (1.0, 100.0),\n",
    "    (1.0, 100.0),\n",
    "    (1.0, 100.0),\n",
    "    (-1.0, 1.0)\n",
    "]\n",
    "problem.set_mu_range(mu_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Prepare reduction with a POD-Galerkin method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction_method = PODGalerkin(problem)\n",
    "reduction_method.set_Nmax(20)\n",
    "reduction_method.set_tolerance(1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Perform the offline phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.1 Fit Reduction Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "=                ElasticBlock POD-Galerkin offline phase begins                =\n",
      "================================================================================\n",
      "\n",
      "###################################### 0 #######################################\n",
      "truth solve for mu = (55.33253688880515, 71.80374727086952, 60.67357423109274, 54.94343511669279, -0.15269040132219058)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 1 #######################################\n",
      "truth solve for mu = (64.94351719359895, 44.321133915006556, 89.2855270774259, 96.4026132896019, -0.2331169623484446)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 2 #######################################\n",
      "truth solve for mu = (79.3807787701838, 53.360597055537546, 57.2364115482993, 92.63406719097344, -0.8579278836042261)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 3 #######################################\n",
      "truth solve for mu = (9.62580067045253, 3.001621346592246, 83.42936470924586, 78.03751834403519, 0.7400242964936383)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 4 #######################################\n",
      "truth solve for mu = (97.88321588104364, 80.11669785745563, 46.686456863040256, 78.2723884523591, -0.7634511482621336)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 5 #######################################\n",
      "truth solve for mu = (64.35218111142485, 15.191975453495594, 94.5222227879088, 52.662983853257096, -0.17067612001895283)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 6 #######################################\n",
      "truth solve for mu = (27.19100559835807, 77.64913525398745, 46.1588828894383, 57.274960937996205, -0.9624203991272897)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 7 #######################################\n",
      "truth solve for mu = (62.145914210511826, 61.59747654951972, 62.076465690600934, 94.43105977294779, 0.3636405982069668)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 8 #######################################\n",
      "truth solve for mu = (36.591282156804816, 44.2661634261348, 70.06548839679922, 6.9623216912977135, 0.33353343089133536)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 9 #######################################\n",
      "truth solve for mu = (67.39314909219779, 21.82787354631025, 13.763703467830478, 32.22740674149421, -0.2725784581147548)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 10 ######################################\n",
      "truth solve for mu = (57.449480271370085, 44.42154983276971, 98.8490099678634, 11.102436264054779, -0.5822464878103306)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 11 ######################################\n",
      "truth solve for mu = (16.969642270614628, 65.65772422107445, 26.07586865143843, 47.16476651277432, -0.5111488159967945)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 12 ######################################\n",
      "truth solve for mu = (16.737988780906452, 11.927138975266208, 65.97662935706207, 14.680112183512767, -0.606835276639893)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 13 ######################################\n",
      "truth solve for mu = (37.50379189543545, 82.27832975494557, 10.613026303513065, 83.95654584238159, -0.8078031842120739)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 14 ######################################\n",
      "truth solve for mu = (97.66948703632617, 47.39646896312246, 97.69934773084337, 60.87970645475955, 0.47852715879660335)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 15 ######################################\n",
      "truth solve for mu = (4.879591433177747, 28.99788929506455, 12.899459560103722, 30.317879554692347, -0.7625445620915119)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 16 ######################################\n",
      "truth solve for mu = (32.48033476000363, 42.01203645695233, 7.350602138529652, 69.55473981763197, 0.1332029084131503)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 17 ######################################\n",
      "truth solve for mu = (27.273559603005097, 52.80155729320327, 10.300110565085726, 58.018703060061746, 0.8585923951524281)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 18 ######################################\n",
      "truth solve for mu = (32.53832629268104, 67.0736276164045, 14.047988378034825, 71.91639320773798, -0.4211878141055978)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 19 ######################################\n",
      "truth solve for mu = (19.135944838704567, 59.06478054619823, 2.9906470725618615, 83.06506289251895, -0.9906090476149059)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 20 ######################################\n",
      "truth solve for mu = (68.10383714282678, 27.73078934602432, 73.7842081901369, 96.25666596662639, -0.5024937129600839)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 21 ######################################\n",
      "truth solve for mu = (58.03957610736585, 59.61215119591206, 57.65293867329646, 23.08508163142121, 0.90549802303397)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 22 ######################################\n",
      "truth solve for mu = (45.265412483145106, 84.79445857464165, 70.24844825643292, 30.446258134658233, 0.6275956394049544)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 23 ######################################\n",
      "truth solve for mu = (40.25406834385148, 88.229216514005, 58.54601439095001, 88.29180082363042, 0.38506318015553176)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 24 ######################################\n",
      "truth solve for mu = (72.8001737021444, 50.63111381074352, 95.65227983759917, 64.75502972373411, -0.15228990288364064)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 25 ######################################\n",
      "truth solve for mu = (61.032928198664514, 2.900126632624019, 30.855906850780382, 66.35718021177581, -0.41984478557911187)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 26 ######################################\n",
      "truth solve for mu = (62.18352747088531, 43.44810139363085, 14.411932358022574, 30.529950269647046, 0.13992982140252974)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 27 ######################################\n",
      "truth solve for mu = (59.49640336356915, 57.8581996361083, 65.66688116585622, 65.5582237301672, -0.1371631291320521)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 28 ######################################\n",
      "truth solve for mu = (89.75811298925524, 37.38862513474176, 44.15062760129705, 89.30041214655154, 0.6123879780921715)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 29 ######################################\n",
      "truth solve for mu = (70.68496977049627, 10.92246184391781, 92.02877876072269, 71.70988865536204, 0.997694013135733)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 30 ######################################\n",
      "truth solve for mu = (15.795382161141381, 86.94447967945321, 17.086800532961107, 61.94039686410057, -0.752360034301117)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 31 ######################################\n",
      "truth solve for mu = (84.95281470290121, 80.92457691377606, 57.34097312284474, 41.31114642537397, -0.8616660090897239)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 32 ######################################\n",
      "truth solve for mu = (70.0454485413118, 45.90072558512882, 72.48350434756445, 86.7718502669343, 0.9510430100057716)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 33 ######################################\n",
      "truth solve for mu = (85.72453089686849, 2.159694334315195, 36.63782838335803, 73.26906567998175, -0.656740645477119)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 34 ######################################\n",
      "truth solve for mu = (52.5826240142088, 6.3794608455861095, 20.799655964743607, 2.833657651600783, 0.5873954067148413)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 35 ######################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth solve for mu = (23.168544117977632, 35.189816388993364, 92.8800480530935, 70.73702579042974, -0.9363221409373843)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 36 ######################################\n",
      "truth solve for mu = (17.30472149329336, 62.52636174847659, 58.14563027181259, 24.551389316076353, 0.8684279958495875)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 37 ######################################\n",
      "truth solve for mu = (61.7826296406237, 54.02764749947087, 59.40108765910253, 73.28208092216019, -0.3761100090407963)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 38 ######################################\n",
      "truth solve for mu = (40.423885159393095, 21.774531148537093, 19.43310758215328, 94.49286660840943, 0.4791015900985751)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 39 ######################################\n",
      "truth solve for mu = (49.55542205313914, 23.514048169359, 26.1812916952689, 6.744886872063686, -0.13116674888375845)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 40 ######################################\n",
      "truth solve for mu = (31.867792317416153, 69.93800539273049, 38.39743208995561, 18.780764078403845, -0.9506425432173375)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 41 ######################################\n",
      "truth solve for mu = (7.65771351486161, 68.25988457635816, 45.915987611048486, 54.1213418997635, 0.7933425860806842)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 42 ######################################\n",
      "truth solve for mu = (99.04355579227374, 22.47280145544892, 66.64474210690997, 27.068915296977913, -0.9586980010685426)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 43 ######################################\n",
      "truth solve for mu = (76.079486729778, 32.68169793142432, 38.9629255230179, 59.24339424180697, 0.6620969104723808)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 44 ######################################\n",
      "truth solve for mu = (63.26920251552372, 87.39241488929213, 28.080661446747943, 80.00663655734381, -0.6287281113880956)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 45 ######################################\n",
      "truth solve for mu = (95.32637404022252, 69.06133936239371, 22.335260034242285, 94.7896884584035, 0.46171161354031565)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 46 ######################################\n",
      "truth solve for mu = (26.140222616907558, 22.117885759380716, 52.30187067913566, 3.540609087398626, -0.5850598491177812)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 47 ######################################\n",
      "truth solve for mu = (43.04386140639912, 38.04282805308833, 46.893967012116256, 28.48524192317846, 0.17356869291633759)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 48 ######################################\n",
      "truth solve for mu = (86.52170498639991, 12.635653740241276, 52.2205316082573, 14.074742528170178, 0.4337193623851874)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 49 ######################################\n",
      "truth solve for mu = (40.20991057792208, 56.97670987399239, 19.144703785193784, 15.339928174994347, -0.02388743870209087)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 50 ######################################\n",
      "truth solve for mu = (36.205661047145604, 94.1027625800285, 76.76720012688956, 75.11769836520418, 0.8074394794918669)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 51 ######################################\n",
      "truth solve for mu = (9.258821108759836, 55.66705452231825, 58.863130826621116, 96.23170147617567, -0.4157049464149023)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 52 ######################################\n",
      "truth solve for mu = (24.842049211629234, 10.929100284284283, 2.6265333295559463, 93.02340236242686, 0.3398330931818201)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 53 ######################################\n",
      "truth solve for mu = (78.73013829029064, 28.891280469640957, 59.05460645244634, 7.331571345977132, -0.028744808130754196)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 54 ######################################\n",
      "truth solve for mu = (97.77201883470023, 87.7740192863425, 34.477736231847715, 96.19544529960835, -0.536596747057591)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 55 ######################################\n",
      "truth solve for mu = (94.98256341915246, 94.19639276594336, 80.12105614788678, 63.41434574981232, 0.748575933249894)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 56 ######################################\n",
      "truth solve for mu = (30.009008166271876, 85.04541197597891, 62.169792499834855, 2.3104489181310495, -0.30553296413556086)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 57 ######################################\n",
      "truth solve for mu = (15.665945233868339, 98.20110959200707, 48.35866039695882, 50.24174518436761, 0.2789450327974472)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 58 ######################################\n",
      "truth solve for mu = (37.489876006832134, 14.553126896874295, 82.3896555862303, 19.794943278373037, 0.02263796509291205)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 59 ######################################\n",
      "truth solve for mu = (23.207385868499188, 10.68660396490937, 86.35696022474664, 97.3190294132899, 0.9216693161260003)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 60 ######################################\n",
      "truth solve for mu = (90.74899442289671, 77.63068593716524, 33.98137005083555, 9.029037608811679, -0.18551765717238533)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 61 ######################################\n",
      "truth solve for mu = (23.99118007492333, 14.116275841040315, 6.289290996895701, 72.8338420568473, -0.9771450827499379)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 62 ######################################\n",
      "truth solve for mu = (77.28749410177485, 15.547717894637131, 8.87268617608882, 9.870700389621932, 0.3440956147078289)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 63 ######################################\n",
      "truth solve for mu = (25.29135377543163, 42.633407201329746, 56.179510341067775, 86.19456620905058, 0.45408852542265654)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 64 ######################################\n",
      "truth solve for mu = (27.76246261863275, 14.016797129821633, 6.482057721698596, 30.858264813613307, -0.4757637015206435)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 65 ######################################\n",
      "truth solve for mu = (46.15791611324749, 68.64485221922037, 69.86691911824687, 29.068365811634497, -0.24014608819975902)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 66 ######################################\n",
      "truth solve for mu = (18.9339452119534, 79.06600571834535, 6.62795956689079, 70.00272693077375, 0.5573907918822067)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 67 ######################################\n",
      "truth solve for mu = (77.96334862302656, 26.682833870190137, 38.00750065532358, 59.17236388444251, -0.45435619515106596)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 68 ######################################\n",
      "truth solve for mu = (37.71442712257098, 20.508373738378324, 46.52573249184473, 5.416617824157294, 0.599591769141236)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 69 ######################################\n",
      "truth solve for mu = (8.618688251676641, 52.36467973432108, 31.374199854974414, 58.17675193430617, 0.9188666816668503)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 70 ######################################\n",
      "truth solve for mu = (64.91145420114438, 4.5008811397936, 43.609841511298065, 51.49166837950677, 0.07235498940690399)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 71 ######################################\n",
      "truth solve for mu = (68.45785854977996, 28.482013675444843, 13.7571959811657, 39.87489197816234, 0.9128114455918976)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update snapshots matrix\n",
      "\n",
      "###################################### 72 ######################################\n",
      "truth solve for mu = (19.52595828333363, 90.49441153789546, 54.83678905765531, 46.23423074293081, 0.7640828204597792)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 73 ######################################\n",
      "truth solve for mu = (46.40179221509, 72.69259602454278, 40.503506848607095, 90.50039489719481, 0.3800500403824547)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 74 ######################################\n",
      "truth solve for mu = (70.26258337080115, 33.44431975415477, 75.92108563095204, 63.97004448926699, -0.5199594532405809)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 75 ######################################\n",
      "truth solve for mu = (16.893343426040385, 79.84275597721584, 95.95749370048702, 46.355743898744244, 0.18196833064736984)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 76 ######################################\n",
      "truth solve for mu = (85.91454177516191, 46.26512188203185, 95.23557320644088, 57.99936504244237, 0.6415342414026299)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 77 ######################################\n",
      "truth solve for mu = (90.97552812286109, 81.73685805808832, 16.78203188144664, 63.26094546710834, -0.20313148276064585)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 78 ######################################\n",
      "truth solve for mu = (7.208582250311225, 42.97919293709435, 26.60972262205136, 85.05479253442257, -0.9333907469066076)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 79 ######################################\n",
      "truth solve for mu = (95.93928946448388, 36.18151599872103, 36.313982149851746, 2.6165217656870814, -0.6295353495276321)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 80 ######################################\n",
      "truth solve for mu = (40.72469057955726, 92.99985031296868, 10.861878091905862, 94.58485181442887, 0.7389770610932644)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 81 ######################################\n",
      "truth solve for mu = (45.96207729384763, 33.343387295057745, 24.041668798626628, 61.83200594121056, -0.9338508170489888)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 82 ######################################\n",
      "truth solve for mu = (2.5450003802359933, 43.450776527325544, 7.7393333234973, 25.942157836363197, -0.5576781693078323)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 83 ######################################\n",
      "truth solve for mu = (26.06592817856234, 13.974467890310518, 2.1915860668677727, 12.432945416736061, 0.23696051902549575)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 84 ######################################\n",
      "truth solve for mu = (97.45136506898697, 99.0441551545285, 41.4963554419331, 17.132488178613933, 0.2775235147330586)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 85 ######################################\n",
      "truth solve for mu = (49.540229308324975, 98.95156795115872, 7.46511650802624, 78.5402093930675, -0.42320300533701216)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 86 ######################################\n",
      "truth solve for mu = (24.900443387580825, 66.58795258173492, 25.360255314105483, 66.92005263835958, 0.03461703440457753)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 87 ######################################\n",
      "truth solve for mu = (42.98480985514908, 55.91409305748048, 29.418100472043346, 70.95089592102491, -0.17028626133287195)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 88 ######################################\n",
      "truth solve for mu = (36.69401048810333, 83.03703454101804, 92.57172428336602, 5.554723777842396, -0.534746014340469)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 89 ######################################\n",
      "truth solve for mu = (35.50341757976376, 81.68168145765449, 98.56365133668646, 96.92819876236483, 0.8098966910998537)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 90 ######################################\n",
      "truth solve for mu = (30.35907024133896, 99.20911309803293, 25.69258406458867, 11.484709333340989, 0.9019052221107882)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 91 ######################################\n",
      "truth solve for mu = (24.108605291341533, 69.2870582426973, 6.777279539078277, 73.34020081362014, 0.7634404246676794)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 92 ######################################\n",
      "truth solve for mu = (27.97125265113029, 38.52663271166543, 38.05532214877069, 75.13003749647318, -0.5243855149219223)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 93 ######################################\n",
      "truth solve for mu = (18.013456805716658, 45.47987322008607, 31.142372330354632, 84.07972310360658, -0.5245163479687225)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 94 ######################################\n",
      "truth solve for mu = (50.736556291436884, 94.31577637009511, 63.76577207672141, 86.86165114078402, 0.8804193787095347)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 95 ######################################\n",
      "truth solve for mu = (75.32572132674885, 70.25793096225038, 96.82859109381847, 99.44567817512026, -0.09635663466048072)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 96 ######################################\n",
      "truth solve for mu = (8.016108040236627, 29.986609112611365, 16.083115863085318, 42.331151104805166, -0.7374213430534879)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 97 ######################################\n",
      "truth solve for mu = (60.80766259806732, 38.897997856627555, 89.64320254453278, 96.81167250805169, 0.09376980333884433)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 98 ######################################\n",
      "truth solve for mu = (28.207533416892062, 59.63081145742184, 89.77935466421657, 41.26660123773908, 0.1041565533839417)\n",
      "update snapshots matrix\n",
      "\n",
      "###################################### 99 ######################################\n",
      "truth solve for mu = (27.89362399300844, 46.08897079555267, 40.76964000258027, 25.59293304321413, 0.011732767650616704)\n",
      "update snapshots matrix\n",
      "\n",
      "################################# perform POD ##################################\n",
      "lambda_0 = 19.445782332383885\n",
      "lambda_1 = 6.538940212795487\n",
      "lambda_2 = 0.20775958058162028\n",
      "lambda_3 = 0.09397095966182202\n",
      "lambda_4 = 0.07614227611651596\n",
      "lambda_5 = 0.039934747587349696\n",
      "lambda_6 = 0.01675720082825745\n",
      "lambda_7 = 0.013684471220416992\n",
      "lambda_8 = 0.0015534273396589293\n",
      "lambda_9 = 0.0013709000915684566\n",
      "lambda_10 = 0.0007970183172722555\n",
      "lambda_11 = 0.0005859331912715685\n",
      "lambda_12 = 0.00041405419981224733\n",
      "lambda_13 = 0.0003373711781141816\n",
      "lambda_14 = 7.285315902502063e-05\n",
      "lambda_15 = 5.375666663864013e-05\n",
      "lambda_16 = 1.94697819904694e-05\n",
      "\n",
      "build reduced operators\n",
      "\n",
      "================================================================================\n",
      "=                 ElasticBlock POD-Galerkin offline phase ends                 =\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reduction_method.initialize_training_set(100)\n",
    "reduced_problem = reduction_method.offline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.2 Train PINN\n",
    "\n",
    "Given a training set $X_{PINN} = (\\boldsymbol{\\mu}^{(1)}, \\dots, \\boldsymbol{\\mu}^{(n)})$ of parameters for the PDE, we train a Physics-Informed Neural Network (PINN) $\\operatorname{N}_W(\\boldsymbol{\\mu})$ dependent on the weights and biases $W$ of the network to minimize the loss function\n",
    "\n",
    "$$L_{PINN}(X_{PINN}; W) = \\frac1n \\sum_{i=1}^n \\|A(\\boldsymbol{\\mu^{(i)}}) \\operatorname{N}_W(\\boldsymbol{\\mu}^{(i)}) - \\boldsymbol{f}(\\boldsymbol{\\mu}^{(i)})\\|_2^2$$\n",
    "\n",
    "over $W$, where for a given $\\boldsymbol{\\mu}$, $A(\\boldsymbol{\\mu})$ is the assembled matrix corresponding to the bilinear form $a$ and $\\boldsymbol{f}(\\boldsymbol{\\mu})$ is the assembled vector corresponding to the linear form $f$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_normalization_pinn = Normalization.MinMaxNormalization(input_normalization=True)\n",
    "output_normalization_pinn = Normalization.MinMaxNormalization()\n",
    "\n",
    "pinn_net  = NN.RONN(\"PINN\", problem, reduction_method, n_hidden=2, n_neurons=80)\n",
    "pinn_loss = Losses.PINN_Loss(pinn_net, output_normalization_pinn)\n",
    "data      = RONNData.RONNDataLoader(pinn_net, validation_proportion=0.2, \n",
    "                                    num_without_snapshots=100)\n",
    "optimizer = torch.optim.Adam(pinn_net.parameters(), lr=0.001)\n",
    "\n",
    "pinn_trainer = Training.PINNTrainer(\n",
    "    pinn_net, data, pinn_loss, optimizer,\n",
    "    input_normalization_pinn, num_epochs=10000\n",
    ")\n",
    "\n",
    "loaded, starting_epoch = IO.initialize_parameters(\n",
    "    pinn_net, data, pinn_trainer, optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pinn_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = Training.plot_loss(pinn_trainer, pinn_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.3 Train PDNN\n",
    "\n",
    "Given a training set $X_{PDNN} = ((\\boldsymbol{\\mu}^{(1)}, \\operatorname{HF}(\\boldsymbol{\\mu}^{(1)})), \\dots, (\\boldsymbol{\\mu}^{(n)}, \\operatorname{HF}(\\boldsymbol{\\mu}^{(n)})))$ of parameter and high fidelity solution pairs for the PDE, we train a Projection-Driven Neural Network (PDNN) $\\operatorname{N}_W(\\boldsymbol{\\mu})$ dependent on the weights and biases $W$ of the network to minimize the loss function\n",
    "$$L_{PDNN}(X_{PDNN}; W) = \\frac1n \\sum_{i=1}^n \\|\\operatorname{N}_W(\\boldsymbol{\\mu}^{(i)}) - \\tilde{\\operatorname{HF}}(\\boldsymbol{\\mu}^{(i)})\\|_2^2,$$\n",
    "where for a given $\\boldsymbol{\\mu}$, $\\tilde{\\operatorname{HF}}(\\boldsymbol{\\mu})$ is the projection of $\\operatorname{HF}(\\boldsymbol{\\mu})$ onto the reduced order solution space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_normalization_pdnn = Normalization.StandardNormalization(input_normalization=True)\n",
    "output_normalization_pdnn = Normalization.StandardNormalization()\n",
    "\n",
    "pdnn_net  = NN.RONN(\"PDNN\", problem, reduction_method, n_hidden=2, n_neurons=40)\n",
    "pdnn_loss = Losses.PDNN_Loss(pdnn_net, output_normalization_pdnn)\n",
    "data      = RONNData.RONNDataLoader(pdnn_net, validation_proportion=0.2)\n",
    "optimizer = torch.optim.Adam(pdnn_net.parameters(), lr=0.001)\n",
    "\n",
    "pdnn_trainer = Training.PDNNTrainer(\n",
    "    pdnn_net, data, pdnn_loss, optimizer,\n",
    "    input_normalization_pdnn, num_epochs=10000\n",
    ")\n",
    "\n",
    "loaded, starting_epoch = IO.initialize_parameters(\n",
    "    pdnn_net, data, pdnn_trainer, optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdnn_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = Training.plot_loss(pdnn_trainer, pdnn_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.4 Train PRNN\n",
    "\n",
    "We train a Physics-Reinforced Neural Network (PRNN) $N_W(\\boldsymbol{\\mu})$ dependnent on the weights and biases $W$ of the network to minimize the loss function\n",
    "\n",
    "$$L_{PRNN}(X_{PINN}, X_{PDNN}; W) = L_{PINN}(X_{PINN}; W) + \\omega L_{PDNN}(X_{PDNN}; W),$$\n",
    "\n",
    "where $\\omega$ is a scaling parameter which can be chosen freely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_normalization_prnn = Normalization.MinMaxNormalization(input_normalization=True)\n",
    "output_normalization_prnn = Normalization.MinMaxNormalization()\n",
    "\n",
    "omega = 1.\n",
    "prnn_net  = NN.RONN(f\"PRNN_{omega}\", problem, reduction_method, n_hidden=2, n_neurons=40)\n",
    "prnn_loss = Losses.PRNN_Loss(prnn_net, output_normalization_prnn, omega=omega)\n",
    "data      = RONNData.RONNDataLoader(prnn_net, validation_proportion=0.2,\n",
    "                                    num_without_snapshots=125)\n",
    "optimizer = torch.optim.Adam(prnn_net.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.99999)\n",
    "\n",
    "prnn_trainer = Training.PRNNTrainer(\n",
    "    prnn_net, data, prnn_loss, optimizer, scheduler,\n",
    "    input_normalization_prnn, num_epochs=100000\n",
    ")\n",
    "\n",
    "loaded, starting_epoch = IO.initialize_parameters(\n",
    "    prnn_net, data, prnn_trainer, optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operator 's' not implemented. Continuing without operator 's'...\n",
      "Operator 's' not implemented. Continuing without operator 's'...\n",
      "0 66.25920116037278 \tLoss(validation) = 51.385466901371274\n",
      "100 0.5627312498695463 \tLoss(validation) = 0.5918471267150772\n",
      "200 0.1950048738488442 \tLoss(validation) = 0.20270710517761792\n",
      "300 0.10882963419899858 \tLoss(validation) = 0.12008962247654864\n",
      "400 0.08747451678057949 \tLoss(validation) = 0.10098397607513099\n",
      "500 0.07906588198242376 \tLoss(validation) = 0.09280848185567175\n",
      "600 0.07456238134665316 \tLoss(validation) = 0.08780697840074145\n",
      "700 0.07138085190203594 \tLoss(validation) = 0.08396952508583624\n",
      "800 0.06871315885703481 \tLoss(validation) = 0.0806693145889594\n",
      "900 0.0663120330808224 \tLoss(validation) = 0.07769279007388416\n",
      "1000 0.06408168078454976 \tLoss(validation) = 0.07493823472181235\n",
      "1100 0.06196611315679584 \tLoss(validation) = 0.07233826488477159\n",
      "1200 0.059924293197935664 \tLoss(validation) = 0.06984317545908761\n",
      "1300 0.05792611862644162 \tLoss(validation) = 0.06741764835036036\n",
      "1400 0.05595224886010934 \tLoss(validation) = 0.06503977255657209\n",
      "1500 0.05399430051052877 \tLoss(validation) = 0.06270037984183943\n",
      "1600 0.05205460455120248 \tLoss(validation) = 0.06040210632865551\n",
      "1700 0.05014516258808857 \tLoss(validation) = 0.05815818555142771\n",
      "1800 0.04828619199292138 \tLoss(validation) = 0.055990665657371805\n",
      "1900 0.046503609898831635 \tLoss(validation) = 0.05392709961924137\n",
      "2000 0.044825793573471745 \tLoss(validation) = 0.05199753475127836\n",
      "2100 0.043280006767975054 \tLoss(validation) = 0.05022933315880147\n",
      "2200 0.04188885994921432 \tLoss(validation) = 0.0486442879739981\n",
      "2300 0.04066772535927671 \tLoss(validation) = 0.047255927991568775\n",
      "2400 0.039622894979128694 \tLoss(validation) = 0.046068400790029496\n",
      "2500 0.03875076491762345 \tLoss(validation) = 0.045076152972341375\n",
      "2600 0.038037972471475175 \tLoss(validation) = 0.044264652840222046\n",
      "2700 0.03746295247892762 \tLoss(validation) = 0.04361104148632379\n",
      "2800 0.036999072860834814 \tLoss(validation) = 0.04308738581726358\n",
      "2900 0.03661848410028482 \tLoss(validation) = 0.042664241474737685\n",
      "3000 0.03629583660178223 \tLoss(validation) = 0.0423142033000872\n",
      "3100 0.03601046447959942 \tLoss(validation) = 0.042014526871879704\n",
      "3200 0.03574706731989888 \tLoss(validation) = 0.04174837545928309\n",
      "3300 0.035495180904221275 \tLoss(validation) = 0.041503841603070926\n",
      "3400 0.03524798364469718 \tLoss(validation) = 0.04127361553953715\n",
      "3500 0.03500118942549624 \tLoss(validation) = 0.041053127850366467\n",
      "3600 0.034752093246283915 \tLoss(validation) = 0.04083979607332987\n",
      "3700 0.03449892295046655 \tLoss(validation) = 0.04063202163669\n",
      "3800 0.03424041931549973 \tLoss(validation) = 0.040428759850973266\n",
      "3900 0.03397568930220388 \tLoss(validation) = 0.040229300723554094\n",
      "4000 0.03370417236950764 \tLoss(validation) = 0.04003281624598608\n",
      "4100 0.03342557689007379 \tLoss(validation) = 0.03983867165892556\n",
      "4200 0.033139985847086835 \tLoss(validation) = 0.039646184851283815\n",
      "4300 0.0328478387721061 \tLoss(validation) = 0.0394546887846731\n",
      "4400 0.032549950370415554 \tLoss(validation) = 0.03926349374525911\n",
      "4500 0.032247215731439016 \tLoss(validation) = 0.03907153170384828\n",
      "4600 0.03194037940716667 \tLoss(validation) = 0.03887707377237819\n",
      "4700 0.03162976969745948 \tLoss(validation) = 0.038677431576631276\n",
      "4800 0.03131500543916724 \tLoss(validation) = 0.038468798023266214\n",
      "4900 0.03099494798376941 \tLoss(validation) = 0.038246264993350085\n",
      "5000 0.030667948609223526 \tLoss(validation) = 0.03800437913897986\n",
      "5100 0.030332096794498144 \tLoss(validation) = 0.03773749057978455\n",
      "5200 0.029985625367873595 \tLoss(validation) = 0.03744059633643804\n",
      "5300 0.029627150381406085 \tLoss(validation) = 0.03710982223982749\n",
      "5400 0.02925554963368214 \tLoss(validation) = 0.03674264932196793\n",
      "5500 0.028869872613888483 \tLoss(validation) = 0.036338084052771856\n",
      "5600 0.028468807709776833 \tLoss(validation) = 0.035896207851009256\n",
      "5700 0.028050515285378847 \tLoss(validation) = 0.03541837970565044\n",
      "5800 0.027636194290713 \tLoss(validation) = 0.03490892248265885\n",
      "5900 0.02717558846863229 \tLoss(validation) = 0.03438609930960795\n",
      "6000 0.02672192929430918 \tLoss(validation) = 0.03385727626590998\n",
      "6100 0.02625774471617073 \tLoss(validation) = 0.03332261668123221\n",
      "6200 0.02579608137687539 \tLoss(validation) = 0.03284655614788494\n",
      "6300 0.025335868337324603 \tLoss(validation) = 0.032341654788762206\n",
      "6400 0.02493540925044497 \tLoss(validation) = 0.03202970671149098\n",
      "6500 0.024445832706487453 \tLoss(validation) = 0.031518071737907355\n",
      "6600 0.02401766690412857 \tLoss(validation) = 0.031167578019716827\n",
      "6700 0.0236203090441428 \tLoss(validation) = 0.030831903732035253\n",
      "6800 0.023233610832833824 \tLoss(validation) = 0.03058520188703693\n",
      "6900 0.022870563874669358 \tLoss(validation) = 0.0302414118051984\n",
      "7000 0.022515714411183916 \tLoss(validation) = 0.030097688892631397\n",
      "7100 0.022186771962262507 \tLoss(validation) = 0.029872773905166024\n",
      "7200 0.021971589071827557 \tLoss(validation) = 0.02978786192177477\n",
      "7300 0.02159551756439914 \tLoss(validation) = 0.029488639281337006\n",
      "7400 0.02132022771912919 \tLoss(validation) = 0.029318950736335732\n",
      "7500 0.02107070367950382 \tLoss(validation) = 0.029103731855443217\n",
      "7600 0.020822886344658356 \tLoss(validation) = 0.029016347996152925\n",
      "7700 0.02611574467831418 \tLoss(validation) = 0.03385940980601686\n",
      "7800 0.020355068254268378 \tLoss(validation) = 0.02873496868416788\n",
      "7900 0.020484361702011386 \tLoss(validation) = 0.02881811169519486\n",
      "8000 0.01990868599770781 \tLoss(validation) = 0.02855523476079765\n",
      "8100 0.019690215886452186 \tLoss(validation) = 0.02834342893865597\n",
      "8200 0.019468068384464195 \tLoss(validation) = 0.02823279894531455\n",
      "8300 0.019260309199755153 \tLoss(validation) = 0.02792826159454996\n",
      "8400 0.019021709204042912 \tLoss(validation) = 0.027945008315908716\n",
      "8500 0.0188529136465828 \tLoss(validation) = 0.027795207867101445\n",
      "8600 0.01855668433471181 \tLoss(validation) = 0.027640175601026017\n",
      "8700 0.018323423739354805 \tLoss(validation) = 0.027417668838915464\n",
      "8800 0.01807922775162784 \tLoss(validation) = 0.027297628590225397\n",
      "8900 0.018392869932621948 \tLoss(validation) = 0.02787525123322399\n",
      "9000 0.019319374971054504 \tLoss(validation) = 0.030477574774831998\n",
      "9100 0.017311239093543346 \tLoss(validation) = 0.026729338713510166\n",
      "9200 0.017134648304126674 \tLoss(validation) = 0.026228351796864332\n",
      "9300 0.016775556573497975 \tLoss(validation) = 0.026286535686755756\n",
      "9400 0.016510196445366908 \tLoss(validation) = 0.02599418397533316\n",
      "9500 0.016244938430891462 \tLoss(validation) = 0.025583402518646638\n",
      "9600 0.01597366111854003 \tLoss(validation) = 0.025627823455773892\n",
      "9700 0.015706358360631865 \tLoss(validation) = 0.025395934718722445\n",
      "9800 0.015450203414641513 \tLoss(validation) = 0.025192555981685384\n",
      "9900 0.015189672575409891 \tLoss(validation) = 0.02494049782495108\n",
      "10000 0.014936784421227155 \tLoss(validation) = 0.0247263259061558\n",
      "10100 0.014707445420440373 \tLoss(validation) = 0.02465194421083213\n",
      "10200 0.014435766231043753 \tLoss(validation) = 0.024274637585654346\n",
      "10300 0.014192645434725149 \tLoss(validation) = 0.024065409139091786\n",
      "10400 0.014071976821733901 \tLoss(validation) = 0.024076523616830083\n",
      "10500 0.015833618163456537 \tLoss(validation) = 0.02493472064274002\n",
      "10600 0.013482458800331349 \tLoss(validation) = 0.0235161780221899\n",
      "10700 0.013493940819724298 \tLoss(validation) = 0.023318738740748503\n",
      "10800 0.013040489059952845 \tLoss(validation) = 0.023192708041901582\n",
      "10900 0.012833675736393494 \tLoss(validation) = 0.023117714793904835\n",
      "11000 0.012634335627685081 \tLoss(validation) = 0.022990205406606255\n",
      "11100 0.01248887816432909 \tLoss(validation) = 0.023064670621931228\n",
      "11200 0.01223893751767288 \tLoss(validation) = 0.022777779558880974\n",
      "11300 0.012052100403565573 \tLoss(validation) = 0.02275096580876292\n",
      "11400 0.011869152953386627 \tLoss(validation) = 0.022758441756246278\n",
      "11500 0.011687816459761385 \tLoss(validation) = 0.022636240023225045\n",
      "11600 0.01153085015095901 \tLoss(validation) = 0.022682652287812702\n",
      "11700 0.011332705121822714 \tLoss(validation) = 0.022577252953659185\n",
      "11800 0.0111572466209168 \tLoss(validation) = 0.022566929859846315\n",
      "11900 0.0115527449519875 \tLoss(validation) = 0.022895980870648713\n",
      "12000 0.01080593999338534 \tLoss(validation) = 0.02252167484164828\n",
      "12100 0.010642620722068088 \tLoss(validation) = 0.022656236371652816\n",
      "12200 0.010459495598401165 \tLoss(validation) = 0.022460100739860094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12300 0.010313715301923994 \tLoss(validation) = 0.022381499120986775\n",
      "12400 0.01010837412618616 \tLoss(validation) = 0.022361462066471237\n",
      "12500 0.009945535972998609 \tLoss(validation) = 0.02254296244983734\n",
      "12600 0.009751709761533693 \tLoss(validation) = 0.022313552826288073\n",
      "12700 0.009576069046462887 \tLoss(validation) = 0.02225991307216829\n",
      "12800 0.009401594453583625 \tLoss(validation) = 0.022198082143280215\n",
      "12900 0.009236885817194732 \tLoss(validation) = 0.022101692199830103\n",
      "13000 0.009358948896693173 \tLoss(validation) = 0.021977492538696856\n",
      "13100 0.008888312648901355 \tLoss(validation) = 0.02195311964551062\n",
      "13200 0.008713071164347094 \tLoss(validation) = 0.02187453073375504\n",
      "13300 0.008540867669179525 \tLoss(validation) = 0.02173070362489653\n",
      "13400 0.008375646809087913 \tLoss(validation) = 0.021628718363514494\n",
      "13500 0.008237513784533952 \tLoss(validation) = 0.021607683068188922\n",
      "13600 0.008139998324688784 \tLoss(validation) = 0.02149507438532864\n",
      "13700 0.00789629994775416 \tLoss(validation) = 0.02130489276334601\n",
      "13800 0.007989052576737654 \tLoss(validation) = 0.021309927290467524\n",
      "13900 0.0075902634251926475 \tLoss(validation) = 0.021051956217948614\n",
      "14000 0.007548683889649959 \tLoss(validation) = 0.021195034021348903\n",
      "14100 0.007305557279480027 \tLoss(validation) = 0.020854347773679494\n",
      "14200 0.007164445332181815 \tLoss(validation) = 0.02072964956266911\n",
      "14300 0.007031000821814404 \tLoss(validation) = 0.020621606685248033\n",
      "14400 0.0069024012862535684 \tLoss(validation) = 0.020548026395936374\n",
      "14500 0.006826207168813991 \tLoss(validation) = 0.020415136107902257\n",
      "14600 0.006771446962116156 \tLoss(validation) = 0.02033338883956545\n",
      "14700 0.006537050624635761 \tLoss(validation) = 0.020285358243661622\n",
      "14800 0.006424089209280127 \tLoss(validation) = 0.0201944958536196\n",
      "14900 0.006313422223606006 \tLoss(validation) = 0.020146873642175656\n",
      "15000 0.006239344101925987 \tLoss(validation) = 0.020438388380681752\n",
      "15100 0.006102537019432528 \tLoss(validation) = 0.020013645172309573\n",
      "15200 0.006003616453977671 \tLoss(validation) = 0.01996572968959674\n",
      "15300 0.00697072162474918 \tLoss(validation) = 0.021019697649889594\n",
      "15400 0.005812049809091694 \tLoss(validation) = 0.019860755595487264\n",
      "15500 0.005748731279428773 \tLoss(validation) = 0.019806610868690483\n",
      "15600 0.005681983597388718 \tLoss(validation) = 0.019698971169214728\n",
      "15700 0.005546363275641505 \tLoss(validation) = 0.019744855163231104\n",
      "15800 0.00547100597733945 \tLoss(validation) = 0.019638042074015025\n",
      "15900 0.0054653493019800135 \tLoss(validation) = 0.019884630861025335\n",
      "16000 0.005300559999094108 \tLoss(validation) = 0.01966078992450292\n",
      "16100 0.005259065212469894 \tLoss(validation) = 0.01990680603950403\n",
      "16200 0.006550303349720905 \tLoss(validation) = 0.021280957968342888\n",
      "16300 0.005070962067159583 \tLoss(validation) = 0.01961234215230826\n",
      "16400 0.00503447355485621 \tLoss(validation) = 0.01965986001800751\n",
      "16500 0.00492572424955969 \tLoss(validation) = 0.019600030187867674\n",
      "16600 0.0048574389977320016 \tLoss(validation) = 0.01959751094430251\n",
      "16700 0.004785747781142536 \tLoss(validation) = 0.019604246713110635\n",
      "16800 0.004717633804686242 \tLoss(validation) = 0.019583314616913712\n",
      "16900 0.004649267138184317 \tLoss(validation) = 0.019617489497524232\n",
      "17000 0.004583130353747904 \tLoss(validation) = 0.019635828153186128\n",
      "17100 0.0045528979403243585 \tLoss(validation) = 0.01953704447677182\n",
      "17200 0.0044515620557714 \tLoss(validation) = 0.019664224477253942\n",
      "17300 0.004416945199277242 \tLoss(validation) = 0.019667904268407033\n",
      "17400 0.004324468298365259 \tLoss(validation) = 0.01970422123054814\n",
      "17500 0.004260104722944121 \tLoss(validation) = 0.019737989107461308\n",
      "17600 0.004208654870557254 \tLoss(validation) = 0.019823482268906234\n",
      "17700 0.004163848400907146 \tLoss(validation) = 0.01981520362585666\n",
      "17800 0.004077008403768722 \tLoss(validation) = 0.01983474626980353\n",
      "17900 0.004033381978601887 \tLoss(validation) = 0.019920022619499066\n",
      "18000 0.005492199414624689 \tLoss(validation) = 0.021525868624064554\n",
      "18100 0.003901944680016478 \tLoss(validation) = 0.019940574613771644\n",
      "18200 0.003915791373755376 \tLoss(validation) = 0.019973972196520726\n",
      "18300 0.0037878411956327965 \tLoss(validation) = 0.02000960116704607\n",
      "18400 0.003732159578279595 \tLoss(validation) = 0.02004489098514426\n",
      "18500 0.0037651690579367176 \tLoss(validation) = 0.020451564953463744\n",
      "18600 0.0036234449041953106 \tLoss(validation) = 0.02011429299051923\n",
      "18700 0.0035744229897509607 \tLoss(validation) = 0.02020365020141637\n",
      "18800 0.0035289687212735916 \tLoss(validation) = 0.02003516486228909\n",
      "18900 0.003465723547802256 \tLoss(validation) = 0.020200650264242136\n",
      "19000 0.003789300268433558 \tLoss(validation) = 0.020386656512875252\n",
      "19100 0.003962566656036385 \tLoss(validation) = 0.021095027634924126\n",
      "19200 0.0033152950173517106 \tLoss(validation) = 0.02025826839752553\n",
      "19300 0.0032707444121821763 \tLoss(validation) = 0.020307998832463273\n",
      "19400 0.003440816052831033 \tLoss(validation) = 0.020621567255373133\n",
      "19500 0.0031729111160993034 \tLoss(validation) = 0.02031500996961819\n",
      "19600 0.0031270961824326096 \tLoss(validation) = 0.02029160090002547\n",
      "19700 0.003154268313313455 \tLoss(validation) = 0.020371949683532155\n",
      "19800 0.0030443905870449917 \tLoss(validation) = 0.020410532554584134\n",
      "19900 0.0029943973273278105 \tLoss(validation) = 0.020284875348335035\n",
      "20000 0.0029540837005922237 \tLoss(validation) = 0.02024819085731539\n",
      "20100 0.0029247080221837763 \tLoss(validation) = 0.020204227846702193\n",
      "20200 0.002874449979622021 \tLoss(validation) = 0.020207802921344754\n",
      "20300 0.00283260625377787 \tLoss(validation) = 0.020247538274461865\n",
      "20400 0.002793085527454649 \tLoss(validation) = 0.020213288535697153\n",
      "20500 0.0028182380275541953 \tLoss(validation) = 0.020209532706802213\n",
      "20600 0.004323705406286494 \tLoss(validation) = 0.021642363006071377\n",
      "20700 0.0026820254231888765 \tLoss(validation) = 0.020133312480253216\n",
      "20800 0.0026504690621241113 \tLoss(validation) = 0.02003949104233116\n",
      "20900 0.002612216028779062 \tLoss(validation) = 0.02007427087744154\n",
      "21000 0.0025795766697651974 \tLoss(validation) = 0.020055235089892237\n",
      "21100 0.002545684953178733 \tLoss(validation) = 0.020006272222627856\n",
      "21200 0.0027864729262275225 \tLoss(validation) = 0.02009549527547841\n",
      "21300 0.0024936836953505146 \tLoss(validation) = 0.019920911572190208\n",
      "21400 0.0024495338130814883 \tLoss(validation) = 0.01988627085197418\n",
      "21500 0.0024282279628666838 \tLoss(validation) = 0.01988110968556787\n",
      "21600 0.0023886792876485637 \tLoss(validation) = 0.01980057628930401\n",
      "21700 0.002966417092324216 \tLoss(validation) = 0.020709724039246202\n",
      "21800 0.0027583169018414204 \tLoss(validation) = 0.020692714022847163\n",
      "21900 0.00230238674409041 \tLoss(validation) = 0.019660042586831208\n",
      "22000 0.002597744435483108 \tLoss(validation) = 0.019546635559260145\n",
      "22100 0.0026237739029071733 \tLoss(validation) = 0.01993651831211419\n",
      "22200 0.002220165710888914 \tLoss(validation) = 0.01950936844955831\n",
      "22300 0.002194916645502351 \tLoss(validation) = 0.0194541381904895\n",
      "22400 0.0021720490395558054 \tLoss(validation) = 0.019372701208820044\n",
      "22500 0.0021429834170768125 \tLoss(validation) = 0.019352052101241385\n",
      "22600 0.002118898542110573 \tLoss(validation) = 0.01927727854885486\n",
      "22700 0.0021217087452383675 \tLoss(validation) = 0.01928007636991855\n",
      "22800 0.0020718967716525814 \tLoss(validation) = 0.01920996473948792\n",
      "22900 0.0020467298860940676 \tLoss(validation) = 0.019125767502757487\n",
      "23000 0.002024844826517725 \tLoss(validation) = 0.019065955619055726\n",
      "23100 0.0020111208045599568 \tLoss(validation) = 0.01908503617845049\n",
      "23200 0.0023848553252128974 \tLoss(validation) = 0.019314841074588855\n",
      "23300 0.0031947482169203158 \tLoss(validation) = 0.02011090483952365\n",
      "23400 0.0019351279911887813 \tLoss(validation) = 0.018846452487810396\n",
      "23500 0.0019485088193545762 \tLoss(validation) = 0.01894256726385861\n",
      "23600 0.0018933750142694622 \tLoss(validation) = 0.01873348346384058\n",
      "23700 0.0018921010890957353 \tLoss(validation) = 0.01872813184919766\n",
      "23800 0.001866802400276916 \tLoss(validation) = 0.018718081237995416\n",
      "23900 0.0018938012605238704 \tLoss(validation) = 0.018536015127257263\n",
      "24000 0.0018823936575880877 \tLoss(validation) = 0.01848861367962235\n",
      "24100 0.001794773427349239 \tLoss(validation) = 0.01846820000872405\n",
      "24200 0.0017766861783020677 \tLoss(validation) = 0.01841788377455166\n",
      "24300 0.0017580958760662067 \tLoss(validation) = 0.018363153144351725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24400 0.0017453416412790954 \tLoss(validation) = 0.018342824151828124\n",
      "24500 0.001722265984438788 \tLoss(validation) = 0.01826197782085569\n",
      "24600 0.0017130541763809893 \tLoss(validation) = 0.018219125379381897\n",
      "24700 0.0016912969486207715 \tLoss(validation) = 0.01819552805037953\n",
      "24800 0.0016781424080096674 \tLoss(validation) = 0.018133622933914184\n",
      "24900 0.0016558434821600265 \tLoss(validation) = 0.018080281306060448\n",
      "25000 0.0016404440557900432 \tLoss(validation) = 0.018037219693249562\n",
      "25100 0.0016224658986294035 \tLoss(validation) = 0.017971468518790206\n",
      "25200 0.0016067230102881818 \tLoss(validation) = 0.017936930522753608\n",
      "25300 0.001591797317829257 \tLoss(validation) = 0.017896698718167334\n",
      "25400 0.0015807091626761968 \tLoss(validation) = 0.017836170145491614\n",
      "25500 0.001637134792309959 \tLoss(validation) = 0.017835301541267272\n",
      "25600 0.0015811290079234832 \tLoss(validation) = 0.017842629403644495\n",
      "25700 0.0015675998072559407 \tLoss(validation) = 0.01768984213371176\n",
      "25800 0.002345230255258523 \tLoss(validation) = 0.018704480384260983\n",
      "25900 0.0015052292090094932 \tLoss(validation) = 0.017638126394883075\n",
      "26000 0.0014923338281067839 \tLoss(validation) = 0.017585629452755394\n",
      "26100 0.0014792038823308246 \tLoss(validation) = 0.017566503363031106\n",
      "26200 0.0015302120796701494 \tLoss(validation) = 0.017433923979962025\n",
      "26300 0.0014527713201550082 \tLoss(validation) = 0.017483255189388654\n",
      "26400 0.0014420784513377376 \tLoss(validation) = 0.01744949665781672\n",
      "26500 0.0014371367596109537 \tLoss(validation) = 0.0174224136180626\n",
      "26600 0.001416411487747766 \tLoss(validation) = 0.01737773224971958\n",
      "26700 0.001405998696966339 \tLoss(validation) = 0.017326769753331334\n",
      "26800 0.0013945409136178481 \tLoss(validation) = 0.017309128044145524\n",
      "26900 0.0017970727396656701 \tLoss(validation) = 0.017418715004870623\n",
      "27000 0.0013718049067952074 \tLoss(validation) = 0.017242918054787254\n",
      "27100 0.0013586892524258662 \tLoss(validation) = 0.01719857402428429\n",
      "27200 0.001348560642452396 \tLoss(validation) = 0.017186824628553497\n",
      "27300 0.0021237409853565098 \tLoss(validation) = 0.018454665554281723\n",
      "27400 0.0013265769180424466 \tLoss(validation) = 0.017105371005876106\n",
      "27500 0.001315211167284798 \tLoss(validation) = 0.017074017686822374\n",
      "27600 0.0013072786534022126 \tLoss(validation) = 0.017017657054732106\n",
      "27700 0.00129629914417703 \tLoss(validation) = 0.017034098500633674\n",
      "27800 0.0012860266666162852 \tLoss(validation) = 0.016981289597832176\n",
      "27900 0.0012739822876625256 \tLoss(validation) = 0.01693476988205344\n",
      "28000 0.0012649847356971666 \tLoss(validation) = 0.016920303858995508\n",
      "28100 0.001254268527996999 \tLoss(validation) = 0.01686713559723218\n",
      "28200 0.0012985860175371094 \tLoss(validation) = 0.016842863850755632\n",
      "28300 0.0012348351661957881 \tLoss(validation) = 0.01682494155174477\n",
      "28400 0.0012255008703847164 \tLoss(validation) = 0.01677776628775852\n",
      "28500 0.0012173543071759304 \tLoss(validation) = 0.016733468011749672\n",
      "28600 0.0012141526219380284 \tLoss(validation) = 0.0167036384657353\n",
      "28700 0.0012309766235273753 \tLoss(validation) = 0.016729878950445407\n",
      "28800 0.0011959248716447244 \tLoss(validation) = 0.016662863795251854\n",
      "28900 0.0012671992859204233 \tLoss(validation) = 0.01689389470994233\n",
      "29000 0.0011710005126247002 \tLoss(validation) = 0.01661072100211112\n",
      "29100 0.0012845396765067533 \tLoss(validation) = 0.0168498354805244\n",
      "29200 0.0012259015491056752 \tLoss(validation) = 0.01650876889264529\n",
      "29300 0.0011451841090477767 \tLoss(validation) = 0.016523106072724787\n",
      "29400 0.0011371910226339404 \tLoss(validation) = 0.016489983066842254\n",
      "29500 0.001128655467212926 \tLoss(validation) = 0.016479034857041795\n",
      "29600 0.0011213178129966567 \tLoss(validation) = 0.016444733705710486\n",
      "29700 0.00116459746067217 \tLoss(validation) = 0.01641740116714863\n",
      "29800 0.0013684374901547281 \tLoss(validation) = 0.01681367150499418\n",
      "29900 0.001155913420374185 \tLoss(validation) = 0.01633752128429475\n",
      "30000 0.0010882140585947043 \tLoss(validation) = 0.01634650380941339\n",
      "30100 0.001081202440261219 \tLoss(validation) = 0.01631552855936275\n",
      "30200 0.0010745507416440696 \tLoss(validation) = 0.016293166376704662\n",
      "30300 0.0010764670392101336 \tLoss(validation) = 0.016296056683868652\n",
      "30400 0.0010615996851482303 \tLoss(validation) = 0.01627477014683498\n",
      "30500 0.0010852161523426935 \tLoss(validation) = 0.01634067542116776\n",
      "30600 0.0010770468000384074 \tLoss(validation) = 0.01630145726084341\n",
      "30700 0.0010354039045201698 \tLoss(validation) = 0.016186397816704737\n",
      "30800 0.0010303508657005674 \tLoss(validation) = 0.016159745324588033\n",
      "30900 0.0011050496966161364 \tLoss(validation) = 0.016072104406126532\n",
      "31000 0.0010669457969293154 \tLoss(validation) = 0.01613727713320422\n",
      "31100 0.0010118425777496853 \tLoss(validation) = 0.016087739907207556\n",
      "31200 0.0010021949537874623 \tLoss(validation) = 0.016056191074012315\n",
      "31300 0.0015236483041879384 \tLoss(validation) = 0.01616655641298759\n",
      "31400 0.001226326245834521 \tLoss(validation) = 0.016037548825642147\n",
      "31500 0.0009824986763466124 \tLoss(validation) = 0.01601717115845424\n",
      "31600 0.0009726887009781859 \tLoss(validation) = 0.015992897516330307\n",
      "31700 0.0009669207352966797 \tLoss(validation) = 0.015960364490624754\n",
      "31800 0.001954300091280714 \tLoss(validation) = 0.01739191803399509\n",
      "31900 0.0009534574153976991 \tLoss(validation) = 0.015932308233658946\n",
      "32000 0.0010965572249124116 \tLoss(validation) = 0.015919567449116576\n",
      "32100 0.0009407295326719977 \tLoss(validation) = 0.01588890187102983\n",
      "32200 0.0009415093679555808 \tLoss(validation) = 0.015831882120474768\n",
      "32300 0.0009354092596555877 \tLoss(validation) = 0.015860833747289062\n",
      "32400 0.0010343539867543109 \tLoss(validation) = 0.015833756993020275\n",
      "32500 0.0013049503500146926 \tLoss(validation) = 0.016297685500355416\n",
      "32600 0.001073564500590059 \tLoss(validation) = 0.015725272231786772\n",
      "32700 0.0016429154736234042 \tLoss(validation) = 0.016866218431060984\n",
      "32800 0.0016128097028661984 \tLoss(validation) = 0.01643294707276246\n",
      "32900 0.0022745511945589047 \tLoss(validation) = 0.017560656822245946\n",
      "33000 0.0008909992767163765 \tLoss(validation) = 0.015753561474668894\n",
      "33100 0.0008810772754002226 \tLoss(validation) = 0.015698623330788926\n",
      "33200 0.0008757469037963447 \tLoss(validation) = 0.0156702086668958\n",
      "33300 0.0008794729353230394 \tLoss(validation) = 0.01564334836417875\n",
      "33400 0.0009119915663035194 \tLoss(validation) = 0.01583205926493523\n",
      "33500 0.0008880283172612766 \tLoss(validation) = 0.01565082825271381\n",
      "33600 0.001367148585407043 \tLoss(validation) = 0.016361413894544347\n",
      "33700 0.0010121046473021043 \tLoss(validation) = 0.015543439834506212\n",
      "33800 0.0010721020155892555 \tLoss(validation) = 0.0159864645347737\n",
      "33900 0.0008553517404754631 \tLoss(validation) = 0.0155796561855722\n",
      "34000 0.0008315747757552552 \tLoss(validation) = 0.015555224992224208\n",
      "34100 0.0008276786069649233 \tLoss(validation) = 0.0155567442657138\n",
      "34200 0.0008212219359034917 \tLoss(validation) = 0.015472371583342654\n",
      "34300 0.0010874789860579298 \tLoss(validation) = 0.015583577182676923\n",
      "34400 0.0008106584462758175 \tLoss(validation) = 0.015488528181896716\n",
      "34500 0.0008066298169232176 \tLoss(validation) = 0.015459748502371062\n",
      "34600 0.0008020976378177169 \tLoss(validation) = 0.01543769896674562\n",
      "34700 0.0007959287661754952 \tLoss(validation) = 0.015440646340040304\n",
      "34800 0.0010144531668568404 \tLoss(validation) = 0.015473452269352567\n",
      "34900 0.0007863865412019774 \tLoss(validation) = 0.015397066790748901\n",
      "35000 0.0007809160289816888 \tLoss(validation) = 0.015388493956615873\n",
      "35100 0.0008128052137820786 \tLoss(validation) = 0.015368136089533597\n",
      "35200 0.0008086574515338398 \tLoss(validation) = 0.015310970019547777\n",
      "35300 0.0007697535154137377 \tLoss(validation) = 0.015365303765629315\n",
      "35400 0.0008873682706410983 \tLoss(validation) = 0.015561908413189402\n",
      "35500 0.0007750892335351816 \tLoss(validation) = 0.015358287218938274\n",
      "35600 0.0007666393932211817 \tLoss(validation) = 0.015280854152006147\n",
      "35700 0.0007980773155263166 \tLoss(validation) = 0.015425692890463921\n",
      "35800 0.0007469229016442811 \tLoss(validation) = 0.015262243064897492\n",
      "35900 0.0007749126782049297 \tLoss(validation) = 0.015386366177233032\n",
      "36000 0.0007405851280953008 \tLoss(validation) = 0.015219038330433953\n",
      "36100 0.0007844988358488328 \tLoss(validation) = 0.015292844331275833\n",
      "36200 0.0007316155018991759 \tLoss(validation) = 0.015192495487074837\n",
      "36300 0.0010532426479870217 \tLoss(validation) = 0.015190205005663992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36400 0.0009088786174295774 \tLoss(validation) = 0.015367976042696473\n",
      "36500 0.0008360433752305184 \tLoss(validation) = 0.015272570738724088\n",
      "36600 0.0008157892096355502 \tLoss(validation) = 0.015345880356667917\n",
      "36700 0.0007041797269385343 \tLoss(validation) = 0.015154669325516418\n",
      "36800 0.0007006365775093983 \tLoss(validation) = 0.015135413535195052\n",
      "36900 0.0006968091434615435 \tLoss(validation) = 0.01513923274658232\n",
      "37000 0.0007018119719086257 \tLoss(validation) = 0.015169101232213048\n",
      "37100 0.0009703646867138645 \tLoss(validation) = 0.015349160893163825\n",
      "37200 0.0007548303942565285 \tLoss(validation) = 0.015209238344316478\n",
      "37300 0.0007458579300810391 \tLoss(validation) = 0.015225183065210974\n",
      "37400 0.000719634848384505 \tLoss(validation) = 0.015087417182462884\n",
      "37500 0.0006826703754317606 \tLoss(validation) = 0.015118278283150686\n",
      "37600 0.0008257106182730647 \tLoss(validation) = 0.015147342819381508\n",
      "37700 0.0006711932457344993 \tLoss(validation) = 0.015021770489922329\n",
      "37800 0.0006886306313838488 \tLoss(validation) = 0.01508887785454068\n",
      "37900 0.0006704695846307008 \tLoss(validation) = 0.014968558137487247\n",
      "38000 0.0007238317414931035 \tLoss(validation) = 0.014948533890233935\n",
      "38100 0.0006872312213027694 \tLoss(validation) = 0.014939772010800708\n",
      "38200 0.0006649152086949329 \tLoss(validation) = 0.014944461244266063\n",
      "38300 0.0006441775026071338 \tLoss(validation) = 0.01494779981167732\n",
      "38400 0.0006385226513102949 \tLoss(validation) = 0.014931898565899427\n",
      "38500 0.0006471648761507138 \tLoss(validation) = 0.01496025260167813\n",
      "38600 0.0006914003361422731 \tLoss(validation) = 0.014959692327164818\n",
      "38700 0.0006305867894441206 \tLoss(validation) = 0.014930781738317571\n",
      "38800 0.0012026397044614836 \tLoss(validation) = 0.015565292032877733\n",
      "38900 0.0006397000930578507 \tLoss(validation) = 0.014916225278403493\n",
      "39000 0.0006214239468827481 \tLoss(validation) = 0.014876776717919217\n",
      "39100 0.0006156772587036377 \tLoss(validation) = 0.014820704448534245\n",
      "39200 0.000617231231890934 \tLoss(validation) = 0.01480042451716514\n",
      "39300 0.0006086998538445307 \tLoss(validation) = 0.014800901323766151\n",
      "39400 0.0006048153154570917 \tLoss(validation) = 0.014760217501650503\n",
      "39500 0.0007615974776970656 \tLoss(validation) = 0.014850198690975484\n",
      "39600 0.0006543694121202609 \tLoss(validation) = 0.014787294952264865\n",
      "39700 0.001352592565919708 \tLoss(validation) = 0.015801679957293542\n",
      "39800 0.0007950224703139718 \tLoss(validation) = 0.01479572422731458\n",
      "39900 0.001262029954266936 \tLoss(validation) = 0.01501886145384347\n",
      "40000 0.0010235287627134986 \tLoss(validation) = 0.015165250621457484\n",
      "40100 0.0006123019039824069 \tLoss(validation) = 0.014732282817526768\n",
      "40200 0.0005812316957165463 \tLoss(validation) = 0.014660165552180816\n",
      "40300 0.0005764876244242264 \tLoss(validation) = 0.014664203010195354\n",
      "40400 0.0005762585417197864 \tLoss(validation) = 0.014661342083209003\n",
      "40500 0.0007798516430619746 \tLoss(validation) = 0.014686486985698771\n",
      "40600 0.0005841710163029297 \tLoss(validation) = 0.014640470286689345\n",
      "40700 0.0006129408597693062 \tLoss(validation) = 0.014625937869920533\n",
      "40800 0.0006481190660172183 \tLoss(validation) = 0.014681077225386198\n",
      "40900 0.0005656526617051255 \tLoss(validation) = 0.014564624817045098\n",
      "41000 0.0005761471457749872 \tLoss(validation) = 0.014502598240179347\n",
      "41100 0.0005555272573678111 \tLoss(validation) = 0.014516644239905258\n",
      "41200 0.0005900023130130385 \tLoss(validation) = 0.01443513676109678\n",
      "41300 0.0005670936776414826 \tLoss(validation) = 0.014446077667904997\n",
      "41400 0.0008063112420311618 \tLoss(validation) = 0.014872782428643901\n",
      "41500 0.0005523234502612108 \tLoss(validation) = 0.014491486974144648\n",
      "41600 0.0005392091942507584 \tLoss(validation) = 0.014420613287825436\n",
      "41700 0.0006459503144673399 \tLoss(validation) = 0.014365153762208323\n",
      "41800 0.0005420175307749998 \tLoss(validation) = 0.014385337973341225\n",
      "41900 0.0006540762983290684 \tLoss(validation) = 0.01474556350441006\n",
      "42000 0.0005747535199851298 \tLoss(validation) = 0.014354093789565463\n",
      "42100 0.0005367401597941551 \tLoss(validation) = 0.01431113078469317\n",
      "42200 0.0006050989082441288 \tLoss(validation) = 0.01424213703084049\n",
      "42300 0.0005321197881897502 \tLoss(validation) = 0.014280471718649464\n",
      "42400 0.0005177120331451481 \tLoss(validation) = 0.014239368372643812\n",
      "42500 0.0005151599206386438 \tLoss(validation) = 0.01421567505792636\n",
      "42600 0.0005140611814039545 \tLoss(validation) = 0.01421451751463682\n",
      "42700 0.0005099956057186632 \tLoss(validation) = 0.01417861076928389\n",
      "42800 0.0005185713678546337 \tLoss(validation) = 0.014113963258856763\n",
      "42900 0.0005055002653167419 \tLoss(validation) = 0.014144500547422743\n",
      "43000 0.0007248194431106314 \tLoss(validation) = 0.014169739492813086\n",
      "43100 0.0005016792525949928 \tLoss(validation) = 0.014083397011984833\n",
      "43200 0.0005060004294938295 \tLoss(validation) = 0.014071773057633331\n",
      "43300 0.0005143692059086958 \tLoss(validation) = 0.014042390950710523\n",
      "43400 0.0007018486170401719 \tLoss(validation) = 0.014456402909355223\n",
      "43500 0.0004931057688601515 \tLoss(validation) = 0.01401811320526779\n",
      "43600 0.0004963791345547186 \tLoss(validation) = 0.013964094718362829\n",
      "43700 0.0008806055275020204 \tLoss(validation) = 0.014091622850853275\n",
      "43800 0.0005425122482195946 \tLoss(validation) = 0.013930699877794349\n",
      "43900 0.0004956017178805976 \tLoss(validation) = 0.013916083234199388\n",
      "44000 0.000723542660743708 \tLoss(validation) = 0.01418369475999462\n",
      "44100 0.0005148534728206743 \tLoss(validation) = 0.013808534287113785\n",
      "44200 0.00047966534527636305 \tLoss(validation) = 0.013840360478612113\n",
      "44300 0.0004753150142526039 \tLoss(validation) = 0.013782116030372162\n",
      "44400 0.0004723496919061326 \tLoss(validation) = 0.013770392971692809\n",
      "44500 0.0004694688593240658 \tLoss(validation) = 0.01372988678223944\n",
      "44600 0.000471753991423167 \tLoss(validation) = 0.013742293213142284\n",
      "44700 0.0004879481659458826 \tLoss(validation) = 0.01363049503012098\n",
      "44800 0.0007482255340124364 \tLoss(validation) = 0.013762283900430479\n",
      "44900 0.0004915136613483995 \tLoss(validation) = 0.013643350820841093\n",
      "45000 0.00048372080965857324 \tLoss(validation) = 0.013699912910987381\n",
      "45100 0.0009506163406038313 \tLoss(validation) = 0.014240514419986175\n",
      "45200 0.0004559122770459773 \tLoss(validation) = 0.01354716306853498\n",
      "45300 0.000453137605182216 \tLoss(validation) = 0.013512320877374093\n",
      "45400 0.00045164733038595753 \tLoss(validation) = 0.013490476704942883\n",
      "45500 0.0004754391317817493 \tLoss(validation) = 0.013438098513120247\n",
      "45600 0.0004924394854848291 \tLoss(validation) = 0.013437030376095541\n",
      "45700 0.00045667800017930695 \tLoss(validation) = 0.013424001944981199\n",
      "45800 0.0007251831884962139 \tLoss(validation) = 0.01350413711252669\n",
      "45900 0.0005392211165758079 \tLoss(validation) = 0.013370747575998918\n",
      "46000 0.0004408554971878536 \tLoss(validation) = 0.013335295449776803\n",
      "46100 0.0004384823561986019 \tLoss(validation) = 0.013295245208587742\n",
      "46200 0.00047783716036654367 \tLoss(validation) = 0.013307370649656413\n",
      "46300 0.0004396212017618823 \tLoss(validation) = 0.013213659915655554\n",
      "46400 0.0004820864470078624 \tLoss(validation) = 0.013156514175097724\n",
      "46500 0.00046197437248636476 \tLoss(validation) = 0.013191307089791469\n",
      "46600 0.0009168960440998961 \tLoss(validation) = 0.013404535174326535\n",
      "46700 0.00044449602205790537 \tLoss(validation) = 0.013079150647385235\n",
      "46800 0.00043686178427573954 \tLoss(validation) = 0.013084775010638584\n",
      "46900 0.0005191677356095675 \tLoss(validation) = 0.013259487206831996\n",
      "47000 0.00045208741765504043 \tLoss(validation) = 0.012993266787277379\n",
      "47100 0.00043215146098967696 \tLoss(validation) = 0.012999331759464593\n",
      "47200 0.0004279152549847492 \tLoss(validation) = 0.012952181502013358\n",
      "47300 0.00042379708376616025 \tLoss(validation) = 0.012970359685928076\n",
      "47400 0.0004163012675255089 \tLoss(validation) = 0.01291054176258323\n",
      "47500 0.00048151971776355326 \tLoss(validation) = 0.012841179540637408\n",
      "47600 0.0008051258277949974 \tLoss(validation) = 0.013756181087139432\n",
      "47700 0.0004225422091596288 \tLoss(validation) = 0.012805385270190182\n",
      "47800 0.0005445147795364524 \tLoss(validation) = 0.012955125736330226\n",
      "47900 0.00040862359797639696 \tLoss(validation) = 0.01278437690544339\n",
      "48000 0.0004100325908712285 \tLoss(validation) = 0.012745662055087393\n",
      "48100 0.00041155833063017 \tLoss(validation) = 0.012691464850557312\n",
      "48200 0.0007016706374026395 \tLoss(validation) = 0.013044499586421562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48300 0.0004086885076994949 \tLoss(validation) = 0.01269124616429047\n",
      "48400 0.0004010534723920286 \tLoss(validation) = 0.012639892315392158\n",
      "48500 0.0005172373600956292 \tLoss(validation) = 0.012758143429120279\n",
      "48600 0.0007766365421144662 \tLoss(validation) = 0.012759910239953853\n",
      "48700 0.0004081045367982999 \tLoss(validation) = 0.012523280393411747\n",
      "48800 0.0003952915532251832 \tLoss(validation) = 0.012537124507960712\n",
      "48900 0.00039890401251297574 \tLoss(validation) = 0.01247522237413691\n",
      "49000 0.0004943402169505605 \tLoss(validation) = 0.01267450674093101\n",
      "49100 0.00042937378360044813 \tLoss(validation) = 0.012405847139979425\n",
      "49200 0.0004825601211695548 \tLoss(validation) = 0.012416483258637267\n",
      "49300 0.0005065791670124426 \tLoss(validation) = 0.01239200438946742\n",
      "49400 0.0006566389856807206 \tLoss(validation) = 0.013011957410640419\n",
      "49500 0.0006806030733870305 \tLoss(validation) = 0.012364968890964351\n",
      "49600 0.0006770747482969418 \tLoss(validation) = 0.013023415343612035\n",
      "49700 0.00039934576053217896 \tLoss(validation) = 0.0123262599599996\n",
      "49800 0.00042776799108131826 \tLoss(validation) = 0.012216327120908591\n",
      "49900 0.00041476578646244876 \tLoss(validation) = 0.012311738795033552\n",
      "50000 0.0004245036415000408 \tLoss(validation) = 0.012274984002284117\n",
      "50100 0.00037866941338908516 \tLoss(validation) = 0.012217857510804916\n",
      "50200 0.0005160262535703032 \tLoss(validation) = 0.01224217378331192\n",
      "50300 0.00042797751948223475 \tLoss(validation) = 0.012122125350950806\n",
      "50400 0.0003949997654222974 \tLoss(validation) = 0.012119533794350965\n",
      "50500 0.0004231654397128295 \tLoss(validation) = 0.012050314249040218\n",
      "50600 0.00045702956702190633 \tLoss(validation) = 0.012074710922169852\n",
      "50700 0.0004234160674781418 \tLoss(validation) = 0.012056070887222816\n",
      "50800 0.00037088029282194613 \tLoss(validation) = 0.012051851306642776\n",
      "50900 0.00037556003683437457 \tLoss(validation) = 0.012047352037448722\n",
      "51000 0.0004776255805905319 \tLoss(validation) = 0.011955019845371895\n",
      "51100 0.0003707050879969523 \tLoss(validation) = 0.011999804650266328\n",
      "51200 0.0006316267438088467 \tLoss(validation) = 0.011926916369934452\n",
      "51300 0.00048613695349874087 \tLoss(validation) = 0.012067514931027621\n",
      "51400 0.0003618081181967454 \tLoss(validation) = 0.011909981643749977\n",
      "51500 0.00036492159690264546 \tLoss(validation) = 0.011856438737590574\n",
      "51600 0.0006051730957314309 \tLoss(validation) = 0.012207343632719287\n",
      "51700 0.0003605870028920384 \tLoss(validation) = 0.011820292777608815\n",
      "51800 0.0003610513722452326 \tLoss(validation) = 0.011859657226064841\n",
      "51900 0.0003604312305133695 \tLoss(validation) = 0.011800812838943615\n",
      "52000 0.0004173066797196312 \tLoss(validation) = 0.011893950945128\n",
      "52100 0.00035986236413400655 \tLoss(validation) = 0.01172940991793237\n",
      "52200 0.0003585116838297406 \tLoss(validation) = 0.011745677073889016\n",
      "52300 0.00039352125190108894 \tLoss(validation) = 0.011721634121878816\n",
      "52400 0.0003538075602615699 \tLoss(validation) = 0.011721804162096314\n",
      "52500 0.00035543385900923196 \tLoss(validation) = 0.011650081729220899\n",
      "52600 0.00035452737397717745 \tLoss(validation) = 0.011642973170532\n",
      "52700 0.0003524792005977195 \tLoss(validation) = 0.011651427783887957\n",
      "52800 0.000406778546921579 \tLoss(validation) = 0.011565857427668781\n",
      "52900 0.00039337055274183346 \tLoss(validation) = 0.011546121693200823\n",
      "53000 0.00036127726350820974 \tLoss(validation) = 0.011573487183326563\n",
      "53100 0.00034559751311066773 \tLoss(validation) = 0.011563789045354402\n",
      "53200 0.0003817028306015511 \tLoss(validation) = 0.011674778980339412\n",
      "53300 0.00046622284986595937 \tLoss(validation) = 0.011673217272125563\n",
      "53400 0.00043516874515026033 \tLoss(validation) = 0.011455121889498798\n",
      "53500 0.0003487480556524433 \tLoss(validation) = 0.011536780752454755\n",
      "53600 0.000350894257504749 \tLoss(validation) = 0.0114484986292584\n",
      "53700 0.0003717685012710404 \tLoss(validation) = 0.01149979326570599\n",
      "53800 0.0003393907801270518 \tLoss(validation) = 0.01143465994413821\n",
      "53900 0.0003403869266722745 \tLoss(validation) = 0.01145277029291741\n",
      "54000 0.0003538579083148635 \tLoss(validation) = 0.011427325545102198\n",
      "54100 0.00033432496243710207 \tLoss(validation) = 0.011404058402589961\n",
      "54200 0.00036476851458231037 \tLoss(validation) = 0.01144137368078469\n",
      "54300 0.0003434247954664234 \tLoss(validation) = 0.011339196784650354\n",
      "54400 0.00033452776227583245 \tLoss(validation) = 0.011329435593250812\n",
      "54500 0.0003407938363873847 \tLoss(validation) = 0.011394095336267297\n",
      "54600 0.0003638478802012184 \tLoss(validation) = 0.011314785529336858\n",
      "54700 0.0004601409160709834 \tLoss(validation) = 0.011353529086747385\n",
      "54800 0.00033108358986197657 \tLoss(validation) = 0.011282212924807912\n",
      "54900 0.0003323621917576913 \tLoss(validation) = 0.011222531888523226\n",
      "55000 0.0003349198735314055 \tLoss(validation) = 0.011285973579122737\n",
      "55100 0.00032712878649990805 \tLoss(validation) = 0.011228576358426192\n",
      "55200 0.000327553658373902 \tLoss(validation) = 0.011208592422898579\n",
      "55300 0.0003426237939513085 \tLoss(validation) = 0.011278626616312602\n",
      "55400 0.00039692543264837656 \tLoss(validation) = 0.0111882865707128\n",
      "55500 0.0003215721892996931 \tLoss(validation) = 0.011186450983014398\n",
      "55600 0.00032041427268545114 \tLoss(validation) = 0.011152875956715422\n",
      "55700 0.0003195437284247928 \tLoss(validation) = 0.011141208607247493\n",
      "55800 0.0003220683855950519 \tLoss(validation) = 0.011108896383652183\n",
      "55900 0.0003526549923051746 \tLoss(validation) = 0.011177143752399893\n",
      "56000 0.0003174828153770556 \tLoss(validation) = 0.011108127104223436\n",
      "56100 0.0003177335710799205 \tLoss(validation) = 0.011098481286875917\n",
      "56200 0.00031651403575066355 \tLoss(validation) = 0.011072079530530785\n",
      "56300 0.0003168548987215689 \tLoss(validation) = 0.011031143460618096\n",
      "56400 0.00039330280876451846 \tLoss(validation) = 0.010999719384925288\n",
      "56500 0.0003530111335218214 \tLoss(validation) = 0.011004931598965602\n",
      "56600 0.0003767096491666534 \tLoss(validation) = 0.011083607090720482\n",
      "56700 0.00034317082809121947 \tLoss(validation) = 0.01099873359287745\n",
      "56800 0.000335498908593651 \tLoss(validation) = 0.010984145191807307\n",
      "56900 0.00031682437291315115 \tLoss(validation) = 0.010960847635589382\n",
      "57000 0.0003107687451934254 \tLoss(validation) = 0.010976173059908698\n",
      "57100 0.0003088747323198807 \tLoss(validation) = 0.010949610735451353\n",
      "57200 0.0003807561019085427 \tLoss(validation) = 0.010885826322529627\n",
      "57300 0.0003157018566493328 \tLoss(validation) = 0.010921370151756298\n",
      "57400 0.0003164193927930924 \tLoss(validation) = 0.010965078079774543\n",
      "57500 0.00030580969611007994 \tLoss(validation) = 0.010907005995848727\n",
      "57600 0.00031679122178952226 \tLoss(validation) = 0.010878094945892598\n",
      "57700 0.00031621997189870384 \tLoss(validation) = 0.010873089392647622\n",
      "57800 0.000303888863548971 \tLoss(validation) = 0.010880912872881893\n",
      "57900 0.0003616967391581675 \tLoss(validation) = 0.011072112398743532\n",
      "58000 0.00030578159486987073 \tLoss(validation) = 0.010856509389592551\n",
      "58100 0.00031629473450276834 \tLoss(validation) = 0.010869179072520958\n",
      "58200 0.0003001889518385728 \tLoss(validation) = 0.010807367924478985\n",
      "58300 0.0002990485834410823 \tLoss(validation) = 0.010796255821445841\n",
      "58400 0.000301476992193008 \tLoss(validation) = 0.010800247552395868\n",
      "58500 0.0002978647988581082 \tLoss(validation) = 0.010788229377055203\n",
      "58600 0.0005803833773404924 \tLoss(validation) = 0.010960024641294417\n",
      "58700 0.00029851799898019256 \tLoss(validation) = 0.010748691211817733\n",
      "58800 0.00029790937474056053 \tLoss(validation) = 0.010741786132056353\n",
      "58900 0.0003708300606808691 \tLoss(validation) = 0.010851080015725817\n",
      "59000 0.000452293253598517 \tLoss(validation) = 0.010731738491329803\n",
      "59100 0.000296317169879117 \tLoss(validation) = 0.010674899964738093\n",
      "59200 0.000320045659345025 \tLoss(validation) = 0.010691216284254656\n",
      "59300 0.0002915223380595346 \tLoss(validation) = 0.01067787200647581\n",
      "59400 0.00029150281490366475 \tLoss(validation) = 0.010669156548011592\n",
      "59500 0.00029057216024126086 \tLoss(validation) = 0.010654587442134553\n",
      "59600 0.0002945378501288249 \tLoss(validation) = 0.010680144148463699\n",
      "59700 0.00029576455944864475 \tLoss(validation) = 0.010625042059694282\n",
      "59800 0.0002927848488482826 \tLoss(validation) = 0.010634318127287962\n",
      "59900 0.0004489226019463034 \tLoss(validation) = 0.010615604056518067\n",
      "60000 0.00029371031088630404 \tLoss(validation) = 0.01060203199615371\n",
      "60100 0.00028728552124963446 \tLoss(validation) = 0.010598655188950921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60200 0.00029293070478636995 \tLoss(validation) = 0.010636168264200717\n",
      "60300 0.0003101892090687418 \tLoss(validation) = 0.010653088415249722\n",
      "60400 0.0002919079109328644 \tLoss(validation) = 0.010573072268611532\n",
      "60500 0.0005388773036939467 \tLoss(validation) = 0.010879388223496362\n",
      "60600 0.0003110030399722551 \tLoss(validation) = 0.010598884729952643\n",
      "60700 0.0004589441972502582 \tLoss(validation) = 0.010639768730813588\n",
      "60800 0.0002849914408643805 \tLoss(validation) = 0.01054258100037209\n",
      "60900 0.00031202314097092203 \tLoss(validation) = 0.0105173879029815\n",
      "61000 0.0002861911020291159 \tLoss(validation) = 0.010468387852330927\n",
      "61100 0.00029942417000733347 \tLoss(validation) = 0.010482261753256764\n",
      "61200 0.0002887785982007642 \tLoss(validation) = 0.010445854401280827\n",
      "61300 0.00032270143687164704 \tLoss(validation) = 0.010605571963972656\n",
      "61400 0.0002822536322676096 \tLoss(validation) = 0.010430487638662686\n",
      "61500 0.00027709849131827354 \tLoss(validation) = 0.01045435218773156\n",
      "61600 0.00027645294858792745 \tLoss(validation) = 0.01044159927945231\n",
      "61700 0.0002765303956165533 \tLoss(validation) = 0.010430803958824706\n",
      "61800 0.0002751670404764743 \tLoss(validation) = 0.0104168790049925\n",
      "61900 0.0002754977348081905 \tLoss(validation) = 0.01039965578594933\n",
      "62000 0.0002741668524434378 \tLoss(validation) = 0.010393915836514143\n",
      "62100 0.0002776502477451194 \tLoss(validation) = 0.010378232794570223\n",
      "62200 0.0002941663212028133 \tLoss(validation) = 0.010449924845740581\n",
      "62300 0.00027293378070505014 \tLoss(validation) = 0.010375691527571004\n",
      "62400 0.0002731218176780958 \tLoss(validation) = 0.01034693411914608\n",
      "62500 0.00027584058861177685 \tLoss(validation) = 0.010366257337050827\n",
      "62600 0.0002706124946665689 \tLoss(validation) = 0.010343512002087024\n",
      "62700 0.0004694385825259073 \tLoss(validation) = 0.010726197811640907\n",
      "62800 0.00045590639145884663 \tLoss(validation) = 0.01036118087073618\n",
      "62900 0.0005504653596808439 \tLoss(validation) = 0.010311059579124003\n",
      "63000 0.00033475329531569375 \tLoss(validation) = 0.010353603948931839\n",
      "63100 0.00033172371717325397 \tLoss(validation) = 0.010319640664680755\n",
      "63200 0.0002811676112523453 \tLoss(validation) = 0.010247386316294257\n",
      "63300 0.00028598666579798614 \tLoss(validation) = 0.010315252941075161\n",
      "63400 0.0002758067181124548 \tLoss(validation) = 0.010308161904818708\n",
      "63500 0.00026573093894879046 \tLoss(validation) = 0.01025088514398937\n",
      "63600 0.00027307133403353786 \tLoss(validation) = 0.010305810148007926\n",
      "63700 0.00026882415578747415 \tLoss(validation) = 0.010248776157069848\n",
      "63800 0.00027099987092112744 \tLoss(validation) = 0.010193772020140199\n",
      "63900 0.0006587367815567496 \tLoss(validation) = 0.010927229152731852\n",
      "64000 0.0003880998770618793 \tLoss(validation) = 0.01028429743753382\n",
      "64100 0.0003458190715206142 \tLoss(validation) = 0.010281024275379483\n",
      "64200 0.0002619849944515995 \tLoss(validation) = 0.010188032330508114\n",
      "64300 0.00027384858444433373 \tLoss(validation) = 0.010156254738477682\n",
      "64400 0.0002833205535620943 \tLoss(validation) = 0.010143001680563812\n",
      "64500 0.00027783356388384864 \tLoss(validation) = 0.01015958630488503\n",
      "64600 0.0004114413354415257 \tLoss(validation) = 0.010298558914497545\n",
      "64700 0.00029604923888114094 \tLoss(validation) = 0.010188217245063639\n",
      "64800 0.0003202012405413489 \tLoss(validation) = 0.010285616480899434\n",
      "64900 0.0002881876040116458 \tLoss(validation) = 0.010241174825185089\n",
      "65000 0.0002592721525051032 \tLoss(validation) = 0.010108597039877999\n",
      "65100 0.00026574319386999876 \tLoss(validation) = 0.010118251801391266\n",
      "65200 0.0003050141503306511 \tLoss(validation) = 0.010071950178185147\n",
      "65300 0.00027614254050959243 \tLoss(validation) = 0.010058477424227583\n",
      "65400 0.00026155647279007307 \tLoss(validation) = 0.01007883605862764\n",
      "65500 0.00028242708818391706 \tLoss(validation) = 0.010031047230062342\n",
      "65600 0.0002620694582692674 \tLoss(validation) = 0.010110979004145019\n",
      "65700 0.00029440905607275644 \tLoss(validation) = 0.010054045873869023\n",
      "65800 0.0002632301806323032 \tLoss(validation) = 0.0100215529927931\n",
      "65900 0.00025326485515955656 \tLoss(validation) = 0.010053159974655597\n",
      "66000 0.000257113371346167 \tLoss(validation) = 0.010005400923440181\n",
      "66100 0.00026687645016165793 \tLoss(validation) = 0.010033527638859749\n",
      "66200 0.000371761787187801 \tLoss(validation) = 0.01008243179123018\n",
      "66300 0.0002796313240259734 \tLoss(validation) = 0.01010744481093256\n",
      "66400 0.0002598293263282224 \tLoss(validation) = 0.010001520186637188\n",
      "66500 0.0002564940672150326 \tLoss(validation) = 0.00997368742616923\n",
      "66600 0.0002584372844380653 \tLoss(validation) = 0.009985696429914055\n",
      "66700 0.00026072499514141745 \tLoss(validation) = 0.009942555586126944\n",
      "66800 0.0002649853364030451 \tLoss(validation) = 0.009971738904053187\n",
      "66900 0.0002526893353905056 \tLoss(validation) = 0.009999168890711799\n",
      "67000 0.00028759334444220923 \tLoss(validation) = 0.009994117482964734\n",
      "67100 0.00033342942514366154 \tLoss(validation) = 0.01014594916797202\n",
      "67200 0.0002463162614095651 \tLoss(validation) = 0.009923520267948498\n",
      "67300 0.0002523573092637086 \tLoss(validation) = 0.009934081345895443\n",
      "67400 0.00028041002467848054 \tLoss(validation) = 0.009885278588596483\n",
      "67500 0.00043262023019402854 \tLoss(validation) = 0.010016154559845203\n",
      "67600 0.00044935462935683423 \tLoss(validation) = 0.00990654514119978\n",
      "67700 0.0004214613773197306 \tLoss(validation) = 0.010256869675285734\n",
      "67800 0.0002542843632597686 \tLoss(validation) = 0.009903628078590505\n",
      "67900 0.00033068051890535925 \tLoss(validation) = 0.010095721827488958\n",
      "68000 0.0002432583969514809 \tLoss(validation) = 0.00987225635799156\n",
      "68100 0.0002431857647766056 \tLoss(validation) = 0.00987833726928804\n",
      "68200 0.00024095607399800986 \tLoss(validation) = 0.00984996512698721\n",
      "68300 0.00024188147001018393 \tLoss(validation) = 0.009834733106271594\n",
      "68400 0.0002407163957717299 \tLoss(validation) = 0.009853060913885823\n",
      "68500 0.00025412795969192623 \tLoss(validation) = 0.009854219888514646\n",
      "68600 0.00024489563267994757 \tLoss(validation) = 0.009788186994645325\n",
      "68700 0.00023974721938704069 \tLoss(validation) = 0.009825178091269829\n",
      "68800 0.0002443933004828001 \tLoss(validation) = 0.009813229522571023\n",
      "68900 0.0002668696604453765 \tLoss(validation) = 0.009775445928054521\n",
      "69000 0.00028698540076295924 \tLoss(validation) = 0.00984773414961278\n",
      "69100 0.00026320804831446334 \tLoss(validation) = 0.009834538882250948\n",
      "69200 0.00024233419820280505 \tLoss(validation) = 0.009772741584893843\n",
      "69300 0.00023729464428464114 \tLoss(validation) = 0.009746592539089266\n",
      "69400 0.00023602729873832323 \tLoss(validation) = 0.009745848545844869\n",
      "69500 0.0002374023732155721 \tLoss(validation) = 0.009768010165636588\n",
      "69600 0.0002355371734287501 \tLoss(validation) = 0.009747671572665045\n",
      "69700 0.00024255973914421284 \tLoss(validation) = 0.009774334146534214\n",
      "69800 0.0003612374379565563 \tLoss(validation) = 0.009800966825260528\n",
      "69900 0.0003129005846154078 \tLoss(validation) = 0.009704116927420936\n",
      "70000 0.00023472328767932252 \tLoss(validation) = 0.009696471216746109\n",
      "70100 0.00024564212886044756 \tLoss(validation) = 0.00971786812152797\n",
      "70200 0.0002497809013244778 \tLoss(validation) = 0.00974054613744194\n",
      "70300 0.00024479260036495916 \tLoss(validation) = 0.009682613782631175\n",
      "70400 0.00023549968804153766 \tLoss(validation) = 0.009653705832088508\n",
      "70500 0.00023553559841490963 \tLoss(validation) = 0.009654771027826362\n",
      "70600 0.0002320494895256975 \tLoss(validation) = 0.009678742954762926\n",
      "70700 0.000312600416372287 \tLoss(validation) = 0.009717645318141368\n",
      "70800 0.000244199927864434 \tLoss(validation) = 0.009636293321573657\n",
      "70900 0.00023933539521957468 \tLoss(validation) = 0.009708987621233851\n",
      "71000 0.00023191499291282976 \tLoss(validation) = 0.009650914546925356\n",
      "71100 0.00027318595026399716 \tLoss(validation) = 0.009688049913183491\n",
      "71200 0.0002503114603642601 \tLoss(validation) = 0.009613545292891093\n",
      "71300 0.00023523197862515376 \tLoss(validation) = 0.009583863538852745\n",
      "71400 0.00023301829981224115 \tLoss(validation) = 0.00964157516342055\n",
      "71500 0.00024085763857726713 \tLoss(validation) = 0.00957957381030022\n",
      "71600 0.0002380048276888022 \tLoss(validation) = 0.009587683637371119\n",
      "71700 0.0003370317979754491 \tLoss(validation) = 0.009572496746269407\n",
      "71800 0.00024854625586929433 \tLoss(validation) = 0.00961150851232115\n",
      "71900 0.00023245378033937285 \tLoss(validation) = 0.009535274068153425\n",
      "72000 0.00023051455968309335 \tLoss(validation) = 0.009528438796982798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72100 0.00028838747191992206 \tLoss(validation) = 0.009590703565433572\n",
      "72200 0.0002333373556255743 \tLoss(validation) = 0.009525376996420672\n",
      "72300 0.0002359093318227608 \tLoss(validation) = 0.009520561948884555\n",
      "72400 0.0002393542871254333 \tLoss(validation) = 0.00953859817719905\n",
      "72500 0.000276448618805594 \tLoss(validation) = 0.009596525553843308\n",
      "72600 0.0002223676535973045 \tLoss(validation) = 0.00950758724499906\n",
      "72700 0.00022183653328004786 \tLoss(validation) = 0.009501729672268311\n",
      "72800 0.00023503508958408768 \tLoss(validation) = 0.009480918827054725\n",
      "72900 0.00022155432480077715 \tLoss(validation) = 0.009486028017884514\n",
      "73000 0.0002228525323757044 \tLoss(validation) = 0.009465121070415757\n",
      "73100 0.00022059772056045034 \tLoss(validation) = 0.009463502829626016\n",
      "73200 0.0002207696469469435 \tLoss(validation) = 0.009460281081346037\n",
      "73300 0.0002314917607303555 \tLoss(validation) = 0.009470190039275574\n",
      "73400 0.0002714866096114583 \tLoss(validation) = 0.009424640235673912\n",
      "73500 0.00022740421808671216 \tLoss(validation) = 0.009469894349263213\n",
      "73600 0.00022134239663440996 \tLoss(validation) = 0.009446315360373622\n",
      "73700 0.0002213393073673376 \tLoss(validation) = 0.009412943591365514\n",
      "73800 0.00023160066302294302 \tLoss(validation) = 0.009425589793048528\n",
      "73900 0.0002260638302990277 \tLoss(validation) = 0.009438183354307673\n",
      "74000 0.00021910532097941022 \tLoss(validation) = 0.009405314028187972\n",
      "74100 0.00023253353538297435 \tLoss(validation) = 0.009443152252205586\n",
      "74200 0.0004104191019980777 \tLoss(validation) = 0.009513844730892246\n",
      "74300 0.00035960906186416656 \tLoss(validation) = 0.009500351565869463\n",
      "74400 0.0004427904711782287 \tLoss(validation) = 0.009557522765174862\n",
      "74500 0.0002520519227350911 \tLoss(validation) = 0.009390477083120588\n",
      "74600 0.00021930715708164995 \tLoss(validation) = 0.009394254959161966\n",
      "74700 0.0002163697685904807 \tLoss(validation) = 0.009346190893981636\n",
      "74800 0.00027006560636439955 \tLoss(validation) = 0.009329811628411587\n",
      "74900 0.00023850534396176664 \tLoss(validation) = 0.009428623938808263\n",
      "75000 0.00023369549744542845 \tLoss(validation) = 0.009310570892399546\n",
      "75100 0.00022193637200197797 \tLoss(validation) = 0.00934074462122211\n",
      "75200 0.00023620025717468215 \tLoss(validation) = 0.009398287853978393\n",
      "75300 0.00021518786567131267 \tLoss(validation) = 0.009300213907528054\n",
      "75400 0.0002994655573904043 \tLoss(validation) = 0.009543267828854948\n",
      "75500 0.00021973448838330772 \tLoss(validation) = 0.009302917916646792\n",
      "75600 0.00021146134925968885 \tLoss(validation) = 0.009291406767845149\n",
      "75700 0.00021556791313903444 \tLoss(validation) = 0.009287329905252899\n",
      "75800 0.0004121919971281945 \tLoss(validation) = 0.009418872972936521\n",
      "75900 0.0002169478835609405 \tLoss(validation) = 0.00928496020894488\n",
      "76000 0.00021074863498508645 \tLoss(validation) = 0.009259874822378517\n",
      "76100 0.0002095780160515018 \tLoss(validation) = 0.009257603530457618\n",
      "76200 0.00030023565245736894 \tLoss(validation) = 0.009230220443782518\n",
      "76300 0.0002767688470091151 \tLoss(validation) = 0.009421555774877868\n",
      "76400 0.00021266574358101318 \tLoss(validation) = 0.009209253071200867\n",
      "76500 0.0002094403593227448 \tLoss(validation) = 0.009227051715083498\n",
      "76600 0.0005235446128143831 \tLoss(validation) = 0.00963657170240947\n",
      "76700 0.00045752272326701656 \tLoss(validation) = 0.009530125379044265\n",
      "76800 0.00020849492680664026 \tLoss(validation) = 0.009213789262860077\n",
      "76900 0.00020879979338534962 \tLoss(validation) = 0.00920055984455091\n",
      "77000 0.0002095653215067064 \tLoss(validation) = 0.009192525106545536\n",
      "77100 0.000377792498118929 \tLoss(validation) = 0.009268498461878844\n",
      "77200 0.0002055104255531499 \tLoss(validation) = 0.009173772194627972\n",
      "77300 0.00020746816725293924 \tLoss(validation) = 0.009168730850622319\n",
      "77400 0.00020595693373528932 \tLoss(validation) = 0.009153693605634713\n",
      "77500 0.00020585811410161106 \tLoss(validation) = 0.00916191715919142\n",
      "77600 0.00036996540704098874 \tLoss(validation) = 0.00939576561945732\n",
      "77700 0.0002040822658912829 \tLoss(validation) = 0.009142460514125325\n",
      "77800 0.00020340273643018304 \tLoss(validation) = 0.009130683449179777\n",
      "77900 0.00020316363890230798 \tLoss(validation) = 0.009124987198986748\n",
      "78000 0.0002096343805136489 \tLoss(validation) = 0.009100804609473972\n",
      "78100 0.0003160730596227114 \tLoss(validation) = 0.00911881439249221\n",
      "78200 0.00021333651606854158 \tLoss(validation) = 0.00913904418110447\n",
      "78300 0.00020613580544156666 \tLoss(validation) = 0.009114528522048908\n",
      "78400 0.00021362942157960593 \tLoss(validation) = 0.009099273169042188\n",
      "78500 0.000210318240342847 \tLoss(validation) = 0.009079776145133799\n",
      "78600 0.0002918827725430556 \tLoss(validation) = 0.009180473703163205\n",
      "78700 0.00020317461087858413 \tLoss(validation) = 0.009086818933133341\n",
      "78800 0.0003092986234543647 \tLoss(validation) = 0.00926028123458579\n",
      "78900 0.00020579825627816211 \tLoss(validation) = 0.00908212572780517\n",
      "79000 0.00020029948956428579 \tLoss(validation) = 0.009049615512765827\n",
      "79100 0.00023289129994617872 \tLoss(validation) = 0.009149691925126087\n",
      "79200 0.00021283188631025644 \tLoss(validation) = 0.009041437307057993\n",
      "79300 0.0002160068481702217 \tLoss(validation) = 0.009087631146751337\n",
      "79400 0.00024137812700555206 \tLoss(validation) = 0.009107778300298144\n",
      "79500 0.00019900982663197562 \tLoss(validation) = 0.00901898947577708\n",
      "79600 0.00023605183236681423 \tLoss(validation) = 0.009042468559100883\n",
      "79700 0.0002892000980638467 \tLoss(validation) = 0.00907881050940342\n",
      "79800 0.00019784794125280263 \tLoss(validation) = 0.008997860890321743\n",
      "79900 0.00019689498704688853 \tLoss(validation) = 0.009002424208004687\n",
      "80000 0.00024621508972517384 \tLoss(validation) = 0.009023407635470722\n",
      "80100 0.00043048410078142993 \tLoss(validation) = 0.009455569586314005\n",
      "80200 0.00019694951963817106 \tLoss(validation) = 0.008977978559800303\n",
      "80300 0.00019543493373791793 \tLoss(validation) = 0.008974299575680581\n",
      "80400 0.0001957911339664446 \tLoss(validation) = 0.008968034054654454\n",
      "80500 0.00021784516853701967 \tLoss(validation) = 0.008965222052143616\n",
      "80600 0.00020766835966644955 \tLoss(validation) = 0.008951692655728758\n",
      "80700 0.0002500797607427625 \tLoss(validation) = 0.009027674219598903\n",
      "80800 0.00019854209653376998 \tLoss(validation) = 0.008932084701979074\n",
      "80900 0.00021469796326003778 \tLoss(validation) = 0.008931508092923451\n",
      "81000 0.00019656678749554335 \tLoss(validation) = 0.008932837949326724\n",
      "81100 0.00019372577332917251 \tLoss(validation) = 0.00892674410021728\n",
      "81200 0.00019443451908044088 \tLoss(validation) = 0.00892034051377747\n",
      "81300 0.00020084822677925707 \tLoss(validation) = 0.008891543295715416\n",
      "81400 0.00019380430535435 \tLoss(validation) = 0.008901747881299046\n",
      "81500 0.00023150464438231522 \tLoss(validation) = 0.00894977450743474\n",
      "81600 0.00019569359087736614 \tLoss(validation) = 0.00888326729647533\n",
      "81700 0.00021011330655294094 \tLoss(validation) = 0.00895351583790778\n",
      "81800 0.00022936265880712858 \tLoss(validation) = 0.008896038907034045\n",
      "81900 0.00022480612855608388 \tLoss(validation) = 0.008929079471926888\n",
      "82000 0.0003270738899070465 \tLoss(validation) = 0.008886987048976471\n",
      "82100 0.00019741514826365148 \tLoss(validation) = 0.008865665942656923\n",
      "82200 0.0001900306808005246 \tLoss(validation) = 0.00884920552300485\n",
      "82300 0.00019898731232644257 \tLoss(validation) = 0.008859539865798807\n",
      "82400 0.0001917262334337295 \tLoss(validation) = 0.008833437138429823\n",
      "82500 0.00025221913609084034 \tLoss(validation) = 0.008875816488530988\n",
      "82600 0.0002544000555945884 \tLoss(validation) = 0.008977853165831757\n",
      "82700 0.0001923759733945201 \tLoss(validation) = 0.008832315670783058\n",
      "82800 0.00018984183072708014 \tLoss(validation) = 0.008821754762289224\n",
      "82900 0.00020767648891438614 \tLoss(validation) = 0.008820401380542752\n",
      "83000 0.00023206699830234483 \tLoss(validation) = 0.008813721968826325\n",
      "83100 0.0001870569016243848 \tLoss(validation) = 0.008800961149548219\n",
      "83200 0.00018712095626338432 \tLoss(validation) = 0.008797361396181994\n",
      "83300 0.00024044535297113379 \tLoss(validation) = 0.008891139282409444\n",
      "83400 0.00019439588632201338 \tLoss(validation) = 0.008814636659300906\n",
      "83500 0.00018962535686062033 \tLoss(validation) = 0.008765836728620512\n",
      "83600 0.00018702131184787703 \tLoss(validation) = 0.008771142141133852\n",
      "83700 0.00018650557391376217 \tLoss(validation) = 0.0087665418865389\n",
      "83800 0.00024144489143511653 \tLoss(validation) = 0.00876456889287399\n",
      "83900 0.000221153169586092 \tLoss(validation) = 0.008760551632851391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84000 0.00025049335582149875 \tLoss(validation) = 0.008860540203994316\n",
      "84100 0.00019491137050910745 \tLoss(validation) = 0.008725017853550626\n",
      "84200 0.00023735628147902066 \tLoss(validation) = 0.008761241815321431\n",
      "84300 0.0001935403619099767 \tLoss(validation) = 0.008754743367999232\n",
      "84400 0.0002985612277136703 \tLoss(validation) = 0.008887746132955027\n",
      "84500 0.00018351852286065142 \tLoss(validation) = 0.008720264262026189\n",
      "84600 0.00018630140306009348 \tLoss(validation) = 0.008734315440908903\n",
      "84700 0.00018461159711091738 \tLoss(validation) = 0.00870108300158039\n",
      "84800 0.00019013030520670138 \tLoss(validation) = 0.00869709714624087\n",
      "84900 0.00021461987247228532 \tLoss(validation) = 0.008789207490256381\n",
      "85000 0.0001993198739757558 \tLoss(validation) = 0.008711243516216044\n",
      "85100 0.00018358264774963486 \tLoss(validation) = 0.008694092588142244\n",
      "85200 0.00021435909043596185 \tLoss(validation) = 0.008674721916140797\n",
      "85300 0.000296625469022337 \tLoss(validation) = 0.00873611249742484\n",
      "85400 0.00018076788648447862 \tLoss(validation) = 0.008666139951338248\n",
      "85500 0.00018398644616561403 \tLoss(validation) = 0.008662434635396132\n",
      "85600 0.00018066131039799212 \tLoss(validation) = 0.008662156153873241\n",
      "85700 0.00022678692134535188 \tLoss(validation) = 0.008711110231213195\n",
      "85800 0.00017974269426247313 \tLoss(validation) = 0.008647010248790894\n",
      "85900 0.00021926868133106866 \tLoss(validation) = 0.008666369452214823\n",
      "86000 0.0002377950866335678 \tLoss(validation) = 0.008687202223394797\n",
      "86100 0.00018139524808122824 \tLoss(validation) = 0.008635112925171877\n",
      "86200 0.00018016522952836429 \tLoss(validation) = 0.008631592706127103\n",
      "86300 0.00020396074253281756 \tLoss(validation) = 0.008621670707686102\n",
      "86400 0.00019535982550931695 \tLoss(validation) = 0.008624890529422835\n",
      "86500 0.00022565324458426788 \tLoss(validation) = 0.008624566880205138\n",
      "86600 0.00018868782251182635 \tLoss(validation) = 0.008599281020476862\n",
      "86700 0.00018549715001852984 \tLoss(validation) = 0.008624008223730323\n",
      "86800 0.00018711123683203684 \tLoss(validation) = 0.008611496019753632\n",
      "86900 0.00021239564613669337 \tLoss(validation) = 0.008624492634358199\n",
      "87000 0.00019632196095745272 \tLoss(validation) = 0.008576905767803143\n",
      "87100 0.00017697535163646046 \tLoss(validation) = 0.008587158003422253\n",
      "87200 0.00017698122383089763 \tLoss(validation) = 0.008568848911382182\n",
      "87300 0.00018392791404979914 \tLoss(validation) = 0.008590015500977956\n",
      "87400 0.0001789857032445622 \tLoss(validation) = 0.008558071789174261\n",
      "87500 0.00017553763221718333 \tLoss(validation) = 0.008557313720949202\n",
      "87600 0.0001764240015483147 \tLoss(validation) = 0.008562341205931441\n",
      "87700 0.0001764369041596985 \tLoss(validation) = 0.00854060494012809\n",
      "87800 0.00018369204923359512 \tLoss(validation) = 0.008558893447359238\n",
      "87900 0.00017971905842774754 \tLoss(validation) = 0.008538248458308504\n",
      "88000 0.00017586855085866373 \tLoss(validation) = 0.008534454212933489\n",
      "88100 0.0003632308047406499 \tLoss(validation) = 0.008592839087788972\n",
      "88200 0.0001795245835532729 \tLoss(validation) = 0.008518283981738432\n",
      "88300 0.0001755863955169932 \tLoss(validation) = 0.008522316133326824\n",
      "88400 0.000372692389809843 \tLoss(validation) = 0.008686298443113766\n",
      "88500 0.00018801755958952507 \tLoss(validation) = 0.008513902286804247\n",
      "88600 0.00018065514309350007 \tLoss(validation) = 0.008491746153219975\n",
      "88700 0.00017319169913220282 \tLoss(validation) = 0.008490960055840172\n",
      "88800 0.0001741528372431857 \tLoss(validation) = 0.008497567532395693\n",
      "88900 0.00019447954781549984 \tLoss(validation) = 0.008502106202182228\n",
      "89000 0.000172481606935918 \tLoss(validation) = 0.008478108681370364\n",
      "89100 0.00019742303194229664 \tLoss(validation) = 0.008509185374431334\n",
      "89200 0.0002770760691046807 \tLoss(validation) = 0.008570031684905076\n",
      "89300 0.00017131892295669355 \tLoss(validation) = 0.008462079763375726\n",
      "89400 0.0001714888586990245 \tLoss(validation) = 0.00845482322888633\n",
      "89500 0.00018287676401794326 \tLoss(validation) = 0.008460068752222313\n",
      "89600 0.00021609017114730412 \tLoss(validation) = 0.008480066015661807\n",
      "89700 0.00017332614651400323 \tLoss(validation) = 0.008437333026140217\n",
      "89800 0.0002592542776598857 \tLoss(validation) = 0.008562345417046681\n",
      "89900 0.00020301744966753595 \tLoss(validation) = 0.00846232425785641\n",
      "90000 0.00021576636095643176 \tLoss(validation) = 0.008464395452858929\n",
      "90100 0.00018823329952287693 \tLoss(validation) = 0.008432080816461513\n",
      "90200 0.00017873747017960827 \tLoss(validation) = 0.008410975688894044\n",
      "90300 0.00018893904863399093 \tLoss(validation) = 0.008414199797371114\n",
      "90400 0.00019377978163914305 \tLoss(validation) = 0.008442916519061539\n",
      "90500 0.00017108883813198302 \tLoss(validation) = 0.008406161528855517\n",
      "90600 0.0002504810711032084 \tLoss(validation) = 0.008454799775574569\n",
      "90700 0.00017377658608963635 \tLoss(validation) = 0.008399863426159834\n",
      "90800 0.00018013843802748244 \tLoss(validation) = 0.008401114146562716\n",
      "90900 0.00017303258046150275 \tLoss(validation) = 0.008384114821211616\n",
      "91000 0.00016801903752443247 \tLoss(validation) = 0.008376901308046894\n",
      "91100 0.0001680246956915145 \tLoss(validation) = 0.008380886214699537\n",
      "91200 0.00016788159993510224 \tLoss(validation) = 0.008367345909664781\n",
      "91300 0.00023272091003994835 \tLoss(validation) = 0.008453300142832399\n",
      "91400 0.0001668357974241024 \tLoss(validation) = 0.008369229699052249\n",
      "91500 0.0001969127728216684 \tLoss(validation) = 0.00839577472951391\n",
      "91600 0.0001670881110378368 \tLoss(validation) = 0.008354511086975214\n",
      "91700 0.00017970612861309748 \tLoss(validation) = 0.008388038017716624\n",
      "91800 0.00016978534578880117 \tLoss(validation) = 0.00835403927085478\n",
      "91900 0.0002006813057480383 \tLoss(validation) = 0.00835157854632956\n",
      "92000 0.00017257424457604907 \tLoss(validation) = 0.00833202188658858\n",
      "92100 0.000256406176957985 \tLoss(validation) = 0.008438930035662193\n",
      "92200 0.0001761314616879529 \tLoss(validation) = 0.008341118942277667\n",
      "92300 0.00017702328489507121 \tLoss(validation) = 0.008317973026997062\n",
      "92400 0.00023741772321802054 \tLoss(validation) = 0.008353440710947922\n",
      "92500 0.0001640660127001943 \tLoss(validation) = 0.008315829278079938\n",
      "92600 0.00019802387428637745 \tLoss(validation) = 0.008325861600902274\n",
      "92700 0.0001672717870550497 \tLoss(validation) = 0.008308752131757382\n",
      "92800 0.0001733971515938348 \tLoss(validation) = 0.008318735834172482\n",
      "92900 0.0001781473123699285 \tLoss(validation) = 0.008323245316671418\n",
      "93000 0.0001641785665990318 \tLoss(validation) = 0.008297737229942578\n",
      "93100 0.00018901178236977175 \tLoss(validation) = 0.00828954099067544\n",
      "93200 0.00016627503232116155 \tLoss(validation) = 0.008285512822233852\n",
      "93300 0.00022795638727478543 \tLoss(validation) = 0.008344661933607347\n",
      "93400 0.00016218459136843857 \tLoss(validation) = 0.00827307755520227\n",
      "93500 0.00021902671684985016 \tLoss(validation) = 0.00827273589027668\n",
      "93600 0.00017092085464581204 \tLoss(validation) = 0.008283622700655484\n",
      "93700 0.0003588764092656672 \tLoss(validation) = 0.008533552907642936\n",
      "93800 0.00016768081836709885 \tLoss(validation) = 0.008251709765082436\n",
      "93900 0.00018279864564090033 \tLoss(validation) = 0.00828606957510771\n",
      "94000 0.00018373830656090244 \tLoss(validation) = 0.008288582815280774\n",
      "94100 0.00017735208777273833 \tLoss(validation) = 0.008244679620496256\n",
      "94200 0.00017250052444735454 \tLoss(validation) = 0.008260248278053313\n",
      "94300 0.00022011887036376955 \tLoss(validation) = 0.008276668358676895\n",
      "94400 0.00017820718128328455 \tLoss(validation) = 0.008274257634636888\n",
      "94500 0.00021431953395846276 \tLoss(validation) = 0.008315450083464418\n",
      "94600 0.00033321987312057817 \tLoss(validation) = 0.008378443208742094\n",
      "94700 0.00016124060056185615 \tLoss(validation) = 0.00822398998537998\n",
      "94800 0.00015916996308276433 \tLoss(validation) = 0.008214517592546178\n",
      "94900 0.00016292531264452937 \tLoss(validation) = 0.008213658708938233\n",
      "95000 0.00015990524541494301 \tLoss(validation) = 0.008232341764474557\n",
      "95100 0.00016076511304700895 \tLoss(validation) = 0.008204851018280824\n",
      "95200 0.00017472962183996931 \tLoss(validation) = 0.008197038072823595\n",
      "95300 0.0001607410016822898 \tLoss(validation) = 0.008204777352436642\n",
      "95400 0.00015764121386009923 \tLoss(validation) = 0.008191946456797598\n",
      "95500 0.00015747175892082176 \tLoss(validation) = 0.00818675327898757\n",
      "95600 0.00015904776318899765 \tLoss(validation) = 0.008184269190237453\n",
      "95700 0.00015816155081860425 \tLoss(validation) = 0.008176116765717022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95800 0.0002087256117505234 \tLoss(validation) = 0.00825525744305927\n",
      "95900 0.00016240341834402992 \tLoss(validation) = 0.008166106273893609\n",
      "96000 0.00016110319041317476 \tLoss(validation) = 0.008174991974121765\n",
      "96100 0.00016138387535482912 \tLoss(validation) = 0.008167015015796468\n",
      "96200 0.0002020506344093663 \tLoss(validation) = 0.00818545240482197\n",
      "96300 0.0002572581207758944 \tLoss(validation) = 0.008290802655506711\n",
      "96400 0.0001613213268288548 \tLoss(validation) = 0.008147713152445255\n",
      "96500 0.00016432634523316927 \tLoss(validation) = 0.008151615489548996\n",
      "96600 0.00015665668460778233 \tLoss(validation) = 0.008144522133472965\n",
      "96700 0.00015591552139668043 \tLoss(validation) = 0.008143536519596987\n",
      "96800 0.00015564563825030207 \tLoss(validation) = 0.008135022573628619\n",
      "96900 0.00015470288802778818 \tLoss(validation) = 0.008134155868631516\n",
      "97000 0.0003171640447354444 \tLoss(validation) = 0.008211980727250833\n",
      "97100 0.000250400867261564 \tLoss(validation) = 0.008155831658344354\n",
      "97200 0.00015781311370513263 \tLoss(validation) = 0.008134936642019834\n",
      "97300 0.00015928073194643508 \tLoss(validation) = 0.008124102120093126\n",
      "97400 0.00015404979170899352 \tLoss(validation) = 0.008113472647564915\n",
      "97500 0.00015487236893102225 \tLoss(validation) = 0.008116508639951909\n",
      "97600 0.00015334053873808192 \tLoss(validation) = 0.008107210230935628\n",
      "97700 0.00015695828780493698 \tLoss(validation) = 0.008103478358336795\n",
      "97800 0.0001848258239775705 \tLoss(validation) = 0.008103974495834332\n",
      "97900 0.0001887522569322542 \tLoss(validation) = 0.008138098732052039\n",
      "98000 0.00015837508815328235 \tLoss(validation) = 0.008098482740164623\n",
      "98100 0.00015304968007386288 \tLoss(validation) = 0.00808965545375944\n",
      "98200 0.00018991619078468947 \tLoss(validation) = 0.00812060523540479\n",
      "98300 0.00015510734674128673 \tLoss(validation) = 0.008080293968865988\n",
      "98400 0.00015642104636652286 \tLoss(validation) = 0.00807432844075277\n",
      "98500 0.00015180934341564334 \tLoss(validation) = 0.008076922541036298\n",
      "98600 0.00015138279893774404 \tLoss(validation) = 0.008070750666199\n",
      "98700 0.0001533792162210269 \tLoss(validation) = 0.008069633925471982\n",
      "98800 0.00020712114030435887 \tLoss(validation) = 0.008077630158978577\n",
      "98900 0.0001533775872974051 \tLoss(validation) = 0.008081764817411862\n",
      "99000 0.0002571375814010669 \tLoss(validation) = 0.008095147052048312\n",
      "99100 0.00021404897163594666 \tLoss(validation) = 0.008143277342744126\n",
      "99200 0.00017569238530432937 \tLoss(validation) = 0.008089122557456689\n",
      "99300 0.00019924850389183 \tLoss(validation) = 0.008071970994814699\n",
      "99400 0.00016620298319422165 \tLoss(validation) = 0.008053096459137588\n",
      "99500 0.0002023731296991016 \tLoss(validation) = 0.008079905745123475\n",
      "99600 0.00015592845381206134 \tLoss(validation) = 0.008032720040581276\n",
      "99700 0.00025182088365162365 \tLoss(validation) = 0.008085086895909019\n",
      "99800 0.00015674836100530303 \tLoss(validation) = 0.008031184042124159\n",
      "99900 0.00016547121761281892 \tLoss(validation) = 0.008023124570375876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlnics.Losses.PRNN_Loss at 0x13583b280>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prnn_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = Training.plot_loss(prnn_trainer, prnn_net, separate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6. Perform an error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.1 Reduction Method Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "=               ElasticBlock POD-Galerkin error analysis begins                =\n",
      "================================================================================\n",
      "\n",
      "###################################### 0 #######################################\n",
      "###################################### 1 #######################################\n",
      "###################################### 2 #######################################\n",
      "###################################### 3 #######################################\n",
      "###################################### 4 #######################################\n",
      "###################################### 5 #######################################\n",
      "###################################### 6 #######################################\n",
      "###################################### 7 #######################################\n",
      "###################################### 8 #######################################\n",
      "###################################### 9 #######################################\n",
      "###################################### 10 ######################################\n",
      "###################################### 11 ######################################\n",
      "###################################### 12 ######################################\n",
      "###################################### 13 ######################################\n",
      "###################################### 14 ######################################\n",
      "###################################### 15 ######################################\n",
      "###################################### 16 ######################################\n",
      "###################################### 17 ######################################\n",
      "###################################### 18 ######################################\n",
      "###################################### 19 ######################################\n",
      "###################################### 20 ######################################\n",
      "###################################### 21 ######################################\n",
      "###################################### 22 ######################################\n",
      "###################################### 23 ######################################\n",
      "###################################### 24 ######################################\n",
      "###################################### 25 ######################################\n",
      "###################################### 26 ######################################\n",
      "###################################### 27 ######################################\n",
      "###################################### 28 ######################################\n",
      "###################################### 29 ######################################\n",
      "###################################### 30 ######################################\n",
      "###################################### 31 ######################################\n",
      "###################################### 32 ######################################\n",
      "###################################### 33 ######################################\n",
      "###################################### 34 ######################################\n",
      "###################################### 35 ######################################\n",
      "###################################### 36 ######################################\n",
      "###################################### 37 ######################################\n",
      "###################################### 38 ######################################\n",
      "###################################### 39 ######################################\n",
      "###################################### 40 ######################################\n",
      "###################################### 41 ######################################\n",
      "###################################### 42 ######################################\n",
      "###################################### 43 ######################################\n",
      "###################################### 44 ######################################\n",
      "###################################### 45 ######################################\n",
      "###################################### 46 ######################################\n",
      "###################################### 47 ######################################\n",
      "###################################### 48 ######################################\n",
      "###################################### 49 ######################################\n",
      "###################################### 50 ######################################\n",
      "###################################### 51 ######################################\n",
      "###################################### 52 ######################################\n",
      "###################################### 53 ######################################\n",
      "###################################### 54 ######################################\n",
      "###################################### 55 ######################################\n",
      "###################################### 56 ######################################\n",
      "###################################### 57 ######################################\n",
      "###################################### 58 ######################################\n",
      "###################################### 59 ######################################\n",
      "###################################### 60 ######################################\n",
      "###################################### 61 ######################################\n",
      "###################################### 62 ######################################\n",
      "###################################### 63 ######################################\n",
      "###################################### 64 ######################################\n",
      "###################################### 65 ######################################\n",
      "###################################### 66 ######################################\n",
      "###################################### 67 ######################################\n",
      "###################################### 68 ######################################\n",
      "###################################### 69 ######################################\n",
      "###################################### 70 ######################################\n",
      "###################################### 71 ######################################\n",
      "###################################### 72 ######################################\n",
      "###################################### 73 ######################################\n",
      "###################################### 74 ######################################\n",
      "###################################### 75 ######################################\n",
      "###################################### 76 ######################################\n",
      "###################################### 77 ######################################\n",
      "###################################### 78 ######################################\n",
      "###################################### 79 ######################################\n",
      "###################################### 80 ######################################\n",
      "###################################### 81 ######################################\n",
      "###################################### 82 ######################################\n",
      "###################################### 83 ######################################\n",
      "###################################### 84 ######################################\n",
      "###################################### 85 ######################################\n",
      "###################################### 86 ######################################\n",
      "###################################### 87 ######################################\n",
      "###################################### 88 ######################################\n",
      "###################################### 89 ######################################\n",
      "###################################### 90 ######################################\n",
      "###################################### 91 ######################################\n",
      "###################################### 92 ######################################\n",
      "###################################### 93 ######################################\n",
      "###################################### 94 ######################################\n",
      "###################################### 95 ######################################\n",
      "###################################### 96 ######################################\n",
      "###################################### 97 ######################################\n",
      "###################################### 98 ######################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################################### 99 ######################################\n",
      "\n",
      "N \tgmean(error_u)        \tmax(error_u)       \tgmean(relative_error_u)\tmax(relative_error_u)\n",
      "1 \t0.19927780949783297   \t0.47869278732346776\t0.38461767207095693    \t0.8710453321160461   \n",
      "2 \t0.07524772982618032   \t0.47313078247746265\t0.14523246089115863    \t0.6862019383236299   \n",
      "3 \t0.06140908645136783   \t0.4483717015721346 \t0.11852308059009482    \t0.6502927776061976   \n",
      "4 \t0.04513381940913807   \t0.4474036863031761 \t0.08711087600048323    \t0.648888823396311    \n",
      "5 \t0.026884519315773812  \t0.44672289552368044\t0.051888673706502346   \t0.6479014432262097   \n",
      "6 \t0.014381017702910644  \t0.14035459538319958\t0.02775619405313095    \t0.203562310827172    \n",
      "7 \t0.009560532649642453  \t0.13405449381598214\t0.018452379724215325   \t0.19442500235524587  \n",
      "8 \t0.006542922603391332  \t0.09997194694242247\t0.0126282181974917     \t0.144993617643437    \n",
      "9 \t0.005773951784727203  \t0.09991633012540968\t0.011144060142410754   \t0.14491295417986416  \n",
      "10\t0.004611735766283556  \t0.10200907993926633\t0.008900916158723843   \t0.14794815931104424  \n",
      "11\t0.0038438626451957436 \t0.09995367009511757\t0.0074188767233101     \t0.1449671099451186   \n",
      "12\t0.003321478210801542  \t0.08810699870294253\t0.006410644619649888   \t0.12778537252058136  \n",
      "13\t0.0021122752541424673 \t0.0888080935971547 \t0.004076813133728272   \t0.12880220062218584  \n",
      "14\t0.0012828189309439478 \t0.06181041728249602\t0.0024759145644542074  \t0.089646308628971    \n",
      "15\t0.0010063569746284631 \t0.06118813125322002\t0.0019423270349535812  \t0.08874378041627487  \n",
      "16\t0.0006634524374985263 \t0.06072650947913202\t0.0012805014902738583  \t0.08807427048818925  \n",
      "17\t0.00048138752414265306\t0.02623649216284999\t0.0009291057010628296  \t0.03805191385495611  \n",
      "\n",
      "================================================================================\n",
      "=                ElasticBlock POD-Galerkin error analysis ends                 =\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reduction_method.initialize_testing_set(100)\n",
    "reduction_method.error_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.2 PINN Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "reduction_method.initialize_testing_set(100)\n",
    "test_mu = torch.tensor(reduction_method.testing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ErrorAnalysis.error_analysis_fixed_net(\n",
    "    pinn_net, test_mu, input_normalization_pinn, output_normalization_pinn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ErrorAnalysis.plot_solution_difference(\n",
    "    pinn_net, (1.0, -1.0), input_normalization_pinn, output_normalization_pinn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.3 PDNN Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ErrorAnalysis.error_analysis_fixed_net(\n",
    "    pdnn_net, test_mu, input_normalization_pdnn, output_normalization_pdnn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ErrorAnalysis.plot_solution_difference(\n",
    "    pdnn_net, (1.0, -1.0), input_normalization_pdnn, output_normalization_pdnn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.4 PRNN Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################### N = 17 ####################################\n",
      "ERROR\tNN-HF\t\t\tNN-RO\t\t\tRO-HF\n",
      "min\t0.0018325689742102684\t0.0017317348168840406\t0.00016086903772963645\n",
      "mean\t0.010410139574475407\t0.010383358556485955\t0.0007091434982020529\n",
      "max\t0.07016117133035003\t0.07014387118524616\t0.0021554753882416307\n"
     ]
    }
   ],
   "source": [
    "_ = ErrorAnalysis.error_analysis_fixed_net(\n",
    "    prnn_net, test_mu, input_normalization_prnn, output_normalization_prnn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ErrorAnalysis.plot_solution_difference(\n",
    "    prnn_net, (1.0, -1.0), input_normalization_prnn, output_normalization_prnn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.5 Neural Network Error Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nets = dict()\n",
    "nets[\"pinn_net\"] = pinn_net\n",
    "nets[\"pdnn_net\"] = pdnn_net\n",
    "nets[\"prnn_net\"] = prnn_net\n",
    "\n",
    "input_normalizations = dict()\n",
    "input_normalizations[\"pinn_net\"] = input_normalization_pinn\n",
    "input_normalizations[\"pdnn_net\"] = input_normalization_pdnn\n",
    "input_normalizations[\"prnn_net\"] = input_normalization_prnn\n",
    "\n",
    "output_normalizations = dict()\n",
    "output_normalizations[\"pinn_net\"] = output_normalization_pinn\n",
    "output_normalizations[\"pdnn_net\"] = output_normalization_pdnn\n",
    "output_normalizations[\"prnn_net\"] = output_normalization_prnn\n",
    "\n",
    "_ = ErrorAnalysis.error_analysis_by_network(\n",
    "    nets, test_mu, input_normalizations, output_normalizations, euclidean=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7. Perform a speedup analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction_method.initialize_testing_set(100)\n",
    "reduction_method.speedup_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_problem.set_mu(reduction_method.testing_set[0])\n",
    "reduced_problem.solve()\n",
    "solution = reduced_problem._solution\n",
    "np.array(solution.vector()[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
