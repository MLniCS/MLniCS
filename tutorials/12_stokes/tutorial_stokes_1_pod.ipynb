{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TUTORIAL 12 - Stokes Equations\n",
    "**_Keywords: geometrical parametrization, POD-Galerkin method, mixed formulation, inf sup condition_**\n",
    "\n",
    "### 1. Introduction\n",
    "\n",
    "This tutorial addresses geometrical parametrization and the POD-Galerkin method applied to the steady Stokes equations in a domain $\\Omega_o \\subset \\mathbb{R}^2$ divided into 4 parts with boundary $\\Gamma_o$.\n",
    "\n",
    "The problem is characterized by six parameters. We introduce a vector of parameters $\\boldsymbol{\\mu} = \\{t,D,L,S,H,\\theta \\}$ that control the shape of the subdomains. The ranges of the six parameters are the following:\n",
    "\n",
    "The parameter vector $\\boldsymbol{\\mu}$ is thus given by $$\\boldsymbol{\\mu}=(\\mu_0,\\mu_1,\\mu_2,\\mu_3,\\mu_4,\\mu_5)$$ which corresponds to $\\boldsymbol{\\mu} = \\{t,D,L,S,H,\\theta \\}$, respectively, on the parameter domain $$\\mathbb{P}=[0.5,1.5]\\times[0.5,1.5]\\times[0.5,1.5]\\times[0.5,1.5]\\times[0.5,1.5]\\times[0,\\pi/6]$$\n",
    "\n",
    "In this program, we apply the following conditions on the boundaries: \n",
    "* Zero velocity on the left boundary $\\Gamma_{o,w}$ \n",
    "* Constant inflow on the right boundary $\\Gamma_{o,in}$\n",
    "* Stress free Neumann condition on the bottom boundary $\\Gamma_{o,out}$\n",
    "\n",
    "In order to obtain a faster approximation of the problem we pursue a model reduction by means of a POD-Galerkin reduced order method from a fixed reference domain.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Parametrized formulation\n",
    "\n",
    "Let $\\boldsymbol{u_o}(\\boldsymbol{\\mu})$ be the velocity vector and $p_o(\\boldsymbol{\\mu})$ be the pressure in the domain $\\Omega_o(\\boldsymbol{\\mu})$.\n",
    "\n",
    "We will directly provide a weak formulation for this problem:\n",
    "for a given parameter $\\boldsymbol{\\mu} \\in\\mathbb{P}$, find $\\boldsymbol{u_o}(\\boldsymbol{\\mu}) \\in\\mathbb{V_o}(\\boldsymbol{\\mu})$, $p_o \\in\\mathbb{M_o}$ such that \n",
    "\n",
    "<center>\n",
    "    $\n",
    "    \\begin{cases}\n",
    "        \\nu \\int_{\\Omega_o} \\nabla \\boldsymbol{u_o} : \\nabla \\boldsymbol{v_o} \\ d\\Omega - \\int_{\\Omega_o} p_o \\nabla \\cdot \\boldsymbol{v_o} \\ d\\Omega = \\int_{\\Omega_o} \\boldsymbol{f_o} \\cdot \\boldsymbol{v_o} \\ d\\Omega, \\quad \\forall \\boldsymbol{v_o} \\in\\mathbb{V_o},  \\\\\n",
    "        \\int_{\\Omega_o} q_o \\nabla \\cdot \\boldsymbol{u_o} \\ d\\Omega = 0, \\quad \\forall q_o \\in\\mathbb{M_o}\n",
    "    \\end{cases}\n",
    "    $\n",
    "</center>\n",
    "\n",
    "where\n",
    "\n",
    "* $\\nu$ represents kinematic viscosity\n",
    "* the functional space $\\mathbb{V_o}(\\boldsymbol{\\mu})$ is defined as $$\\mathbb{V_o}(\\boldsymbol{\\mu}) = [H_{\\Gamma_{o,w}}^{1}(\\Omega_o)]^2$$\n",
    "* the functional space $\\mathbb{M_o}(\\boldsymbol{\\mu})$ is defined as $$\\mathbb{M_o}(\\boldsymbol{\\mu}) = L^2(\\Omega_o)$$ Note that the functional spaces are parameter dependent due to the shape variation\n",
    "\n",
    "Since this problem utilizes mixed finite element discretization with the velocity and pressure as solution variables, the inf-sup condition is necessary for the well posedness of this problem. Thus, the supremizer operator $T^{\\mu}: \\mathbb{M_o}_h \\rightarrow \\mathbb{V_o}_h$ will be used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from mlnics import NN, Losses, Normalization, RONNData, IO, Training, ErrorAnalysis\n",
    "from dolfin import *\n",
    "from rbnics import *\n",
    "from sampling import LinearlyDependentUniformDistribution\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Affine decomposition\n",
    "\n",
    "In order to obtain an affine decomposition, we recast the problem on a fixed, parameter independent, reference domain $\\Omega$. We choose one characterized by $\\mu_0=\\mu_1=\\mu_2=\\mu_3=\\mu_4=1$ and $\\mu_5=0$, which we generate through the generate_mesh notebook provided in the *data* folder. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@PullBackFormsToReferenceDomain()\n",
    "@AffineShapeParametrization(\"data/t_bypass_vertices_mapping.vmp\")\n",
    "class Stokes(StokesProblem):\n",
    "\n",
    "    # Default initialization of members\n",
    "    def __init__(self, V, **kwargs):\n",
    "        # Call the standard initialization\n",
    "        StokesProblem.__init__(self, V, **kwargs)\n",
    "        # ... and also store FEniCS data structures for assembly\n",
    "        assert \"subdomains\" in kwargs\n",
    "        assert \"boundaries\" in kwargs\n",
    "        self.subdomains, self.boundaries = kwargs[\"subdomains\"], kwargs[\"boundaries\"]\n",
    "        up = TrialFunction(V)\n",
    "        (self.u, self.p) = split(up)\n",
    "        vq = TestFunction(V)\n",
    "        (self.v, self.q) = split(vq)\n",
    "        self.dx = Measure(\"dx\")(subdomain_data=self.subdomains)\n",
    "        self.ds = Measure(\"ds\")(subdomain_data=self.boundaries)\n",
    "        #\n",
    "        self.f = Constant((0.0, -10.0))\n",
    "        self.g = Constant(0.0)\n",
    "\n",
    "    # Return custom problem name\n",
    "    def name(self):\n",
    "        return \"Stokes1POD\"\n",
    "\n",
    "    # Return theta multiplicative terms of the affine expansion of the problem.\n",
    "    @compute_theta_for_supremizers\n",
    "    def compute_theta(self, term):\n",
    "        if term == \"a\":\n",
    "            theta_a0 = 1.0\n",
    "            return (theta_a0, )\n",
    "        elif term in (\"b\", \"bt\"):\n",
    "            theta_b0 = 1.0\n",
    "            return (theta_b0, )\n",
    "        elif term == \"f\":\n",
    "            theta_f0 = 1.0\n",
    "            return (theta_f0, )\n",
    "        elif term == \"g\":\n",
    "            theta_g0 = 1.0\n",
    "            return (theta_g0, )\n",
    "        else:\n",
    "            raise ValueError(\"Invalid term for compute_theta().\")\n",
    "\n",
    "    # Return forms resulting from the discretization of the affine expansion of the problem operators.\n",
    "    @assemble_operator_for_supremizers\n",
    "    def assemble_operator(self, term):\n",
    "        dx = self.dx\n",
    "        if term == \"a\":\n",
    "            u = self.u\n",
    "            v = self.v\n",
    "            a0 = inner(grad(u), grad(v)) * dx\n",
    "            return (a0, )\n",
    "        elif term == \"b\":\n",
    "            u = self.u\n",
    "            q = self.q\n",
    "            b0 = - q * div(u) * dx\n",
    "            return (b0, )\n",
    "        elif term == \"bt\":\n",
    "            p = self.p\n",
    "            v = self.v\n",
    "            bt0 = - p * div(v) * dx\n",
    "            return (bt0, )\n",
    "        elif term == \"f\":\n",
    "            v = self.v\n",
    "            f0 = inner(self.f, v) * dx\n",
    "            return (f0, )\n",
    "        elif term == \"g\":\n",
    "            q = self.q\n",
    "            g0 = self.g * q * dx\n",
    "            return (g0, )\n",
    "        elif term == \"dirichlet_bc_u\":\n",
    "            bc0 = [DirichletBC(self.V.sub(0), Constant((0.0, 0.0)), self.boundaries, 3)]\n",
    "            return (bc0, )\n",
    "        elif term == \"inner_product_u\":\n",
    "            u = self.u\n",
    "            v = self.v\n",
    "            x0 = inner(grad(u), grad(v)) * dx\n",
    "            return (x0, )\n",
    "        elif term == \"inner_product_p\":\n",
    "            p = self.p\n",
    "            q = self.q\n",
    "            x0 = inner(p, q) * dx\n",
    "            return (x0, )\n",
    "        else:\n",
    "            raise ValueError(\"Invalid term for assemble_operator().\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Main program\n",
    "### 4.1. Read the mesh for this problem\n",
    "The mesh was generated by the [data/generate_mesh.ipynb](data/generate_mesh.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = Mesh(\"data/t_bypass.xml\")\n",
    "subdomains = MeshFunction(\"size_t\", mesh, \"data/t_bypass_physical_region.xml\")\n",
    "boundaries = MeshFunction(\"size_t\", mesh, \"data/t_bypass_facet_region.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Create Finite Element space (Taylor-Hood P2-P1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element_u = VectorElement(\"Lagrange\", mesh.ufl_cell(), 2)\n",
    "element_p = FiniteElement(\"Lagrange\", mesh.ufl_cell(), 1)\n",
    "element = MixedElement(element_u, element_p)\n",
    "V = FunctionSpace(mesh, element, components=[[\"u\", \"s\"], \"p\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Allocate an object of the Stokes class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = Stokes(V, subdomains=subdomains, boundaries=boundaries)\n",
    "mu_range = [\n",
    "    (0.5, 1.5),\n",
    "    (0.5, 1.5),\n",
    "    (0.5, 1.5),\n",
    "    (0.5, 1.5),\n",
    "    (0.5, 1.5),\n",
    "    (0., pi / 6.)\n",
    "]\n",
    "problem.set_mu_range(mu_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Prepare reduction with a POD-Galerkin method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction_method = PODGalerkin(problem)\n",
    "reduction_method.set_Nmax(25)\n",
    "reduction_method.set_tolerance(1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Perform the offline phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.1 Fit Reduction Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduction_method.initialize_training_set(10, sampling=LinearlyDependentUniformDistribution())\n",
    "reduced_problem = reduction_method.offline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.2 Train PINN\n",
    "\n",
    "Given a training set $X_{PINN} = (\\boldsymbol{\\mu}^{(1)}, \\dots, \\boldsymbol{\\mu}^{(n)})$ of parameters for the PDE, we train a Physics-Informed Neural Network (PINN) $\\operatorname{N}_W(\\boldsymbol{\\mu})$ dependent on the weights and biases $W$ of the network to minimize the loss function\n",
    "\n",
    "$$\\begin{align*}\n",
    "    L_{PINN}(X_{PINN}; W) &= \\frac1n \\sum_{i=1}^n \\left\\|A(\\boldsymbol{\\mu^{(i)}}) \\operatorname{N}_W(\\boldsymbol{\\mu}^{(i)}) + B^\\top(\\boldsymbol{\\mu}^{(i)})\\operatorname{N}_W(\\boldsymbol{\\mu}^{(i)}) - \\boldsymbol{f}(\\boldsymbol{\\mu}^{(i)})\\right\\|_2^2\\\\\n",
    "        &\\hspace{10ex}+ \\left\\|B(\\boldsymbol{\\mu}^{(i)})\\operatorname{N}_W(\\boldsymbol{\\mu}^{(i)}) - \\boldsymbol{g}(\\boldsymbol{\\mu}^{(i)})\\right\\|_2^2\n",
    "    \\end{align*}$$\n",
    "\n",
    "over $W$, where for a given $\\boldsymbol{\\mu}$, $A(\\boldsymbol{\\mu})$ is the stiffness matrix, $\\boldsymbol{f}(\\boldsymbol{\\mu})$ is the vector corresponding to the forcing term for the first equation in the system, $B(\\boldsymbol{\\mu})$ is the matrix which corresponds to the second equation in the system, and $\\boldsymbol{g}(\\boldsymbol{\\mu})$ is the vector corresponding to the forcing term for the second equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_normalization_pinn = Normalization.StandardNormalization(input_normalization=True)\n",
    "output_normalization_pinn = Normalization.StandardNormalization()\n",
    "\n",
    "pinn_net  = NN.RONN(\"PINN\", problem, reduction_method, n_hidden=2, n_neurons=40)\n",
    "pinn_loss = Losses.PINN_Loss(pinn_net, output_normalization_pinn)\n",
    "data      = RONNData.RONNDataLoader(pinn_net, validation_proportion=0.2, \n",
    "                                    num_without_snapshots=100)\n",
    "optimizer = torch.optim.Adam(pinn_net.parameters(), lr=0.001)\n",
    "\n",
    "pinn_trainer = Training.PINNTrainer(\n",
    "    pinn_net, data, pinn_loss, optimizer,\n",
    "    input_normalization_pinn, num_epochs=10000\n",
    ")\n",
    "\n",
    "loaded, starting_epoch = IO.initialize_parameters(\n",
    "    pinn_net, data, pinn_trainer, optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pinn_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = Training.plot_loss(pinn_trainer, pinn_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.3 Train PDNN\n",
    "\n",
    "Given a training set $X_{PDNN} = ((\\boldsymbol{\\mu}^{(1)}, \\operatorname{HF}(\\boldsymbol{\\mu}^{(1)})), \\dots, (\\boldsymbol{\\mu}^{(n)}, \\operatorname{HF}(\\boldsymbol{\\mu}^{(n)})))$ of parameter and high fidelity solution pairs for the PDE, we train a Projection-Driven Neural Network (PDNN) $\\operatorname{N}_W(\\boldsymbol{\\mu})$ dependent on the weights and biases $W$ of the network to minimize the loss function\n",
    "$$L_{PDNN}(X_{PDNN}; W) = \\frac1n \\sum_{i=1}^n \\|\\operatorname{N}_W(\\boldsymbol{\\mu}^{(i)}) - \\tilde{\\operatorname{HF}}(\\boldsymbol{\\mu}^{(i)})\\|_2^2,$$\n",
    "where for a given $\\boldsymbol{\\mu}$, $\\tilde{\\operatorname{HF}}(\\boldsymbol{\\mu})$ is the projection of $\\operatorname{HF}(\\boldsymbol{\\mu})$ onto the reduced order solution space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_normalization_pdnn = Normalization.StandardNormalization(input_normalization=True)\n",
    "output_normalization_pdnn = Normalization.StandardNormalization()\n",
    "\n",
    "pdnn_net  = NN.RONN(\"PDNN\", problem, reduction_method, n_hidden=2, n_neurons=40)\n",
    "pdnn_loss = Losses.PDNN_Loss(pdnn_net, output_normalization_pdnn)\n",
    "data      = RONNData.RONNDataLoader(pdnn_net, validation_proportion=0.2)\n",
    "optimizer = torch.optim.Adam(pdnn_net.parameters(), lr=0.001)\n",
    "\n",
    "pdnn_trainer = Training.PDNNTrainer(\n",
    "    pdnn_net, data, pdnn_loss, optimizer,\n",
    "    input_normalization_pdnn, num_epochs=10000\n",
    ")\n",
    "\n",
    "loaded, starting_epoch = IO.initialize_parameters(\n",
    "    pdnn_net, data, pdnn_trainer, optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdnn_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = Training.plot_loss(pdnn_trainer, pdnn_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.4 Train PRNN\n",
    "\n",
    "We train a Physics-Reinforced Neural Network (PRNN) $N_W(\\boldsymbol{\\mu})$ dependnent on the weights and biases $W$ of the network to minimize the loss function\n",
    "\n",
    "$$L_{PRNN}(X_{PINN}, X_{PDNN}; W) = L_{PINN}(X_{PINN}; W) + \\omega L_{PDNN}(X_{PDNN}; W),$$\n",
    "\n",
    "where $\\omega$ is a scaling parameter which can be chosen freely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_normalization_prnn = Normalization.StandardNormalization(input_normalization=True)\n",
    "output_normalization_prnn = Normalization.StandardNormalization()\n",
    "\n",
    "omega = 1.\n",
    "prnn_net  = NN.RONN(f\"PRNN_{omega}\", problem, reduction_method, n_hidden=2, n_neurons=40)\n",
    "prnn_loss = Losses.PRNN_Loss(prnn_net, output_normalization_prnn, omega=omega)\n",
    "data      = RONNData.RONNDataLoader(prnn_net, validation_proportion=0.2,\n",
    "                                    num_without_snapshots=100)\n",
    "optimizer = torch.optim.Adam(prnn_net.parameters(), lr=0.001)\n",
    "\n",
    "prnn_trainer = Training.PRNNTrainer(\n",
    "    prnn_net, data, prnn_loss, optimizer,\n",
    "    input_normalization_prnn, num_epochs=10000\n",
    ")\n",
    "\n",
    "loaded, starting_epoch = IO.initialize_parameters(\n",
    "    prnn_net, data, prnn_trainer, optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prnn_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = Training.plot_loss(prnn_trainer, prnn_net, separate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6. Perform an error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.1 Reduction Method Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reduction_method.initialize_testing_set(100, sampling=LinearlyDependentUniformDistribution())\n",
    "reduction_method.error_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.2 PINN Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mu = torch.tensor(reduction_method.testing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ErrorAnalysis.error_analysis_fixed_net(\n",
    "    pinn_net, test_mu, input_normalization_pinn, output_normalization_pinn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ErrorAnalysis.plot_solution_difference(\n",
    "    pinn_net, (1.0, 1.0, 1.0, 1.0, 1.0, pi / 6.), \n",
    "    input_normalization_pinn, output_normalization_pinn, colorbar=True, component=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.3 PDNN Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ErrorAnalysis.error_analysis_fixed_net(\n",
    "    pdnn_net, test_mu, input_normalization_pdnn, output_normalization_pdnn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ErrorAnalysis.plot_solution_difference(\n",
    "    pdnn_net, (1.0, 1.0, 1.0, 1.0, 1.0, pi / 6.), \n",
    "    input_normalization_pdnn, output_normalization_pdnn, colorbar=True, component=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.4 PRNN Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ErrorAnalysis.error_analysis_fixed_net(\n",
    "    prnn_net, test_mu, input_normalization_prnn, output_normalization_prnn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ErrorAnalysis.plot_solution_difference(\n",
    "    prnn_net, (1.0, 1.0, 1.0, 1.0, 1.0, pi / 6.), \n",
    "    input_normalization_prnn, output_normalization_prnn, colorbar=True, component=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.5 Neural Network Error Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nets = dict()\n",
    "nets[\"pinn_net\"] = pinn_net\n",
    "nets[\"pdnn_net\"] = pdnn_net\n",
    "nets[\"prnn_net\"] = prnn_net\n",
    "\n",
    "input_normalizations = dict()\n",
    "input_normalizations[\"pinn_net\"] = input_normalization_pinn\n",
    "input_normalizations[\"pdnn_net\"] = input_normalization_pdnn\n",
    "input_normalizations[\"prnn_net\"] = input_normalization_prnn\n",
    "\n",
    "output_normalizations = dict()\n",
    "output_normalizations[\"pinn_net\"] = output_normalization_pinn\n",
    "output_normalizations[\"pdnn_net\"] = output_normalization_pdnn\n",
    "output_normalizations[\"prnn_net\"] = output_normalization_prnn\n",
    "\n",
    "_ = ErrorAnalysis.error_analysis_by_network(\n",
    "    nets, test_mu, input_normalizations, output_normalizations, euclidean=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7. Perform a speedup analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction_method.speedup_analysis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
