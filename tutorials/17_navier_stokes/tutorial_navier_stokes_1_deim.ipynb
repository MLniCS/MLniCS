{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 17 - Navier Stokes equations\n",
    "**_Keywords: DEIM, supremizer operator_**\n",
    "\n",
    "### 1. Introduction\n",
    "\n",
    "In this tutorial, we will study the Navier-Stokes equations over a two-dimensional backward-facing step domain $\\Omega$.\n",
    "\n",
    "A Poiseuille flow profile is imposed on the inlet boundary, and a no-flow (zero velocity) condition is imposed on the walls. A homogeneous Neumann condition of the Cauchy stress tensor is applied at the outflow boundary.\n",
    "\n",
    "The inflow velocity boundary condition is characterized by $$\\boldsymbol{u}(\\boldsymbol{x};\\mu)=\\mu\\bigg \\{\\frac{1}{2.25}(x_1-2)(5-x_1),0\\bigg \\} \\quad \\forall \\boldsymbol{x}=(x_0,x_1) \\in \\Omega$$ \n",
    "\n",
    "This problem is characterized by one parameter $\\mu$, which characterizes the inlet velocity. The range of $\\mu$ is the following $$\\mu \\in [1.0, 80.0].$$ \n",
    "\n",
    "Thus, the parameter domain is $$\\mathbb{P}=[1.0,80.0].$$\n",
    "\n",
    "In order to obtain a faster approximation of the problem, we pursue a model reduction by means of a POD-Galerkin reduced order method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Parametrized formulation\n",
    "\n",
    "Let $\\boldsymbol{u}(\\mu)$ be the velocity vector and $p(\\mu)$ be the pressure in the domain $\\Omega$.\n",
    "\n",
    "We will directly provide a weak formulation for this problem: for a given parameter $\\mu \\in \\mathbb{P},$ find $u(\\mu) \\in \\mathbb{V}(\\mu), \\; p \\in\\mathbb{M}$ such that\n",
    "    \n",
    "<center>\n",
    "    $\n",
    "    \\begin{cases}\n",
    "        \\nu \\int_{\\Omega} \\nabla \\boldsymbol{u} : \\nabla \\boldsymbol{v} \\ d\\Omega + \\int_{\\Omega} [(\\boldsymbol{u} \\cdot \\nabla) \\boldsymbol{u}] \\cdot \\boldsymbol{v} \\ d\\Omega - \\int_{\\Omega} p \\nabla \\cdot \\boldsymbol{v} \\ d\\Omega = \\int_{\\Omega} \\boldsymbol{f} \\cdot \\boldsymbol{v} \\ d\\Omega, \\quad \\forall \\boldsymbol{v} \\in\\mathbb{V},  \\\\\n",
    "        \\int_{\\Omega} q \\nabla \\cdot \\boldsymbol{u} \\ d\\Omega = 0, \\quad \\forall q \\in\\mathbb{M}\n",
    "    \\end{cases}\n",
    "    $\n",
    "</center>    \n",
    "where\n",
    "\n",
    "* $\\nu$ represents kinematic viscosity\n",
    "* the functional space $\\mathbb{V}(\\mu)$ is defined as $\\mathbb{V}=[H^1_{\\Gamma_{wall}}(\\Omega)]^2$\n",
    "* the functional space $\\mathbb{M}(\\mu)$ is defined as $\\mathbb{M}=L^2(\\Omega)$\n",
    "\n",
    "\n",
    "Since this problem utilizes mixed finite element discretization with the velocity and pressure as solution variables, the inf-sup condition is necessary for the well posedness of this problem. Thus, the supremizer operator $T^{\\mu}: \\mathbb{M}_h \\rightarrow \\mathbb{V}_h$ will be used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "from mlnics import NN, Losses, Normalization, RONNData, IO, Training, ErrorAnalysis\n",
    "from dolfin import *\n",
    "from rbnics import *\n",
    "from ufl import transpose\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Affine Decomposition \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@DEIM(\"online\", basis_generation=\"Greedy\")\n",
    "@ExactParametrizedFunctions(\"offline\")\n",
    "class NavierStokes(NavierStokesProblem):\n",
    "\n",
    "    # Default initialization of members\n",
    "    def __init__(self, V, **kwargs):\n",
    "        # Call the standard initialization\n",
    "        NavierStokesProblem.__init__(self, V, **kwargs)\n",
    "        # ... and also store FEniCS data structures for assembly\n",
    "        assert \"subdomains\" in kwargs\n",
    "        assert \"boundaries\" in kwargs\n",
    "        self.subdomains, self.boundaries = kwargs[\"subdomains\"], kwargs[\"boundaries\"]\n",
    "        dup = TrialFunction(V)\n",
    "        (self.du, self.dp) = split(dup)\n",
    "        (self.u, _) = split(self._solution)\n",
    "        vq = TestFunction(V)\n",
    "        (self.v, self.q) = split(vq)\n",
    "        self.dx = Measure(\"dx\")(subdomain_data=self.subdomains)\n",
    "        self.ds = Measure(\"ds\")(subdomain_data=self.boundaries)\n",
    "        #\n",
    "        self.inlet = Expression((\"1. / 2.25 * (x[1] - 2) * (5 - x[1])\", \"0.\"), degree=2)\n",
    "        self.f = Constant((0.0, 0.0))\n",
    "        self.g = Constant(0.0)\n",
    "        # Customize nonlinear solver parameters\n",
    "        self._nonlinear_solver_parameters.update({\n",
    "            \"linear_solver\": \"mumps\",\n",
    "            \"maximum_iterations\": 20,\n",
    "            \"report\": True\n",
    "        })\n",
    "\n",
    "    # Return custom problem name\n",
    "    def name(self):\n",
    "        return \"NavierStokesDEIM1\"\n",
    "\n",
    "    # Return theta multiplicative terms of the affine expansion of the problem.\n",
    "    @compute_theta_for_derivatives\n",
    "    @compute_theta_for_supremizers\n",
    "    def compute_theta(self, term):\n",
    "        mu = self.mu\n",
    "        if term == \"a\":\n",
    "            theta_a0 = 1.\n",
    "            return (theta_a0,)\n",
    "        elif term in (\"b\", \"bt\"):\n",
    "            theta_b0 = 1.\n",
    "            return (theta_b0,)\n",
    "        elif term == \"c\":\n",
    "            theta_c0 = 1.\n",
    "            return (theta_c0,)\n",
    "        elif term == \"f\":\n",
    "            theta_f0 = 1.\n",
    "            return (theta_f0,)\n",
    "        elif term == \"g\":\n",
    "            theta_g0 = 1.\n",
    "            return (theta_g0,)\n",
    "        elif term == \"dirichlet_bc_u\":\n",
    "            theta_bc00 = mu[0]\n",
    "            return (theta_bc00,)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid term for compute_theta().\")\n",
    "\n",
    "    # Return forms resulting from the discretization of the affine expansion of the problem operators.\n",
    "    @assemble_operator_for_derivatives\n",
    "    @assemble_operator_for_supremizers\n",
    "    def assemble_operator(self, term):\n",
    "        dx = self.dx\n",
    "        if term == \"a\":\n",
    "            u = self.du\n",
    "            v = self.v\n",
    "            a0 = inner(grad(u) + transpose(grad(u)), grad(v)) * dx\n",
    "            return (a0,)\n",
    "        elif term == \"b\":\n",
    "            u = self.du\n",
    "            q = self.q\n",
    "            b0 = - q * div(u) * dx\n",
    "            return (b0,)\n",
    "        elif term == \"bt\":\n",
    "            p = self.dp\n",
    "            v = self.v\n",
    "            bt0 = - p * div(v) * dx\n",
    "            return (bt0,)\n",
    "        elif term == \"c\":\n",
    "            u = self.u\n",
    "            v = self.v\n",
    "            c0 = inner(grad(u) * u, v) * dx\n",
    "            return (c0,)\n",
    "        elif term == \"f\":\n",
    "            v = self.v\n",
    "            f0 = inner(self.f, v) * dx\n",
    "            return (f0,)\n",
    "        elif term == \"g\":\n",
    "            q = self.q\n",
    "            g0 = self.g * q * dx\n",
    "            return (g0,)\n",
    "        elif term == \"dirichlet_bc_u\":\n",
    "            bc0 = [DirichletBC(self.V.sub(0), self.inlet, self.boundaries, 1),\n",
    "                   DirichletBC(self.V.sub(0), Constant((0.0, 0.0)), self.boundaries, 2)]\n",
    "            return (bc0,)\n",
    "        elif term == \"inner_product_u\":\n",
    "            u = self.du\n",
    "            v = self.v\n",
    "            x0 = inner(grad(u), grad(v)) * dx\n",
    "            return (x0,)\n",
    "        elif term == \"inner_product_p\":\n",
    "            p = self.dp\n",
    "            q = self.q\n",
    "            x0 = inner(p, q) * dx\n",
    "            return (x0,)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid term for assemble_operator().\")\n",
    "\n",
    "\n",
    "# Customize the resulting reduced problem\n",
    "@CustomizeReducedProblemFor(NavierStokesProblem)\n",
    "def CustomizeReducedNavierStokes(ReducedNavierStokes_Base):\n",
    "    class ReducedNavierStokes(ReducedNavierStokes_Base):\n",
    "        def __init__(self, truth_problem, **kwargs):\n",
    "            ReducedNavierStokes_Base.__init__(self, truth_problem, **kwargs)\n",
    "            self._nonlinear_solver_parameters.update({\n",
    "                \"report\": True,\n",
    "                \"line_search\": \"wolfe\"\n",
    "            })\n",
    "\n",
    "    return ReducedNavierStokes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Main program\n",
    "\n",
    "### 4.1. Read the mesh for this problem\n",
    "The mesh was generated by the [data/generate_mesh.ipynb](data/generate_mesh.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = Mesh(\"data/backward_facing_step.xml\")\n",
    "subdomains = MeshFunction(\"size_t\", mesh, \"data/backward_facing_step_physical_region.xml\")\n",
    "boundaries = MeshFunction(\"size_t\", mesh, \"data/backward_facing_step_facet_region.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Create Finite Element Space (Taylor-Hood P2-P1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element_u = VectorElement(\"Lagrange\", mesh.ufl_cell(), 2)\n",
    "element_p = FiniteElement(\"Lagrange\", mesh.ufl_cell(), 1)\n",
    "element = MixedElement(element_u, element_p)\n",
    "V = FunctionSpace(mesh, element, components=[[\"u\", \"s\"], \"p\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Allocate an object of the NavierStokes class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = NavierStokes(V, subdomains=subdomains, boundaries=boundaries)\n",
    "mu_range = [(1.0, 80.0)]\n",
    "problem.set_mu_range(mu_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Prepare reduction with a POD-Galerkin method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction_method = PODGalerkin(problem)\n",
    "reduction_method.set_Nmax(10, DEIM=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Perform the offline phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.1 Fit Reduction Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lifting_mu = (1.0,)\n",
    "problem.set_mu(lifting_mu)\n",
    "reduction_method.initialize_training_set(100, DEIM=144, sampling=EquispacedDistribution())\n",
    "reduced_problem = reduction_method.offline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.2 Train PINN\n",
    "\n",
    "Given a training set $X_{PINN} = (\\boldsymbol{\\mu}^{(1)}, \\dots, \\boldsymbol{\\mu}^{(n)})$ of parameters for the PDE, we train a Physics-Informed Neural Network (PINN) $\\operatorname{N}_W(\\boldsymbol{\\mu})$ dependent on the weights and biases $W$ of the network to minimize the loss function\n",
    "\n",
    "$$\\begin{align*}\n",
    "    L_{PINN}(X_{PINN}; W) &= \\frac1n \\sum_{i=1}^n \\left\\|A(\\boldsymbol{\\mu^{(i)}}) \\operatorname{N}_W(\\boldsymbol{\\mu}^{(i)}) + B^\\top(\\boldsymbol{\\mu}^{(i)})\\operatorname{N}_W(\\boldsymbol{\\mu}^{(i)}) - \\boldsymbol{f}(\\boldsymbol{\\mu}^{(i)}) + \\boldsymbol{c}(\\boldsymbol{\\mu}^{(i)})\\right\\|_2^2\\\\\n",
    "        &\\hspace{10ex}+ \\left\\|B(\\boldsymbol{\\mu}^{(i)})\\operatorname{N}_W(\\boldsymbol{\\mu}^{(i)}) - \\boldsymbol{g}(\\boldsymbol{\\mu}^{(i)})\\right\\|_2^2\n",
    "    \\end{align*}$$\n",
    "\n",
    "over $W$, where for a given $\\boldsymbol{\\mu}$, $A(\\boldsymbol{\\mu})$ is the stiffness matrix, $\\boldsymbol{f}(\\boldsymbol{\\mu})$ is the vector corresponding to the forcing term for the first equation in the system, $\\boldsymbol{c}(\\boldsymbol{\\mu})$ is a vector corresponding to the nonlinear term, $B(\\boldsymbol{\\mu})$ is the matrix which corresponds to the second equation in the system, and $\\boldsymbol{g}(\\boldsymbol{\\mu})$ is the vector corresponding to the forcing term for the second equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_normalization_pinn = Normalization.StandardNormalization(input_normalization=True)\n",
    "output_normalization_pinn = Normalization.StandardNormalization()\n",
    "\n",
    "pinn_net  = NN.RONN(\"PINN\", problem, reduction_method, n_hidden=2, n_neurons=40)\n",
    "pinn_loss = Losses.PINN_Loss(pinn_net, output_normalization_pinn)\n",
    "data      = RONNData.RONNDataLoader(pinn_net, validation_proportion=0.2, \n",
    "                                    num_without_snapshots=100)\n",
    "optimizer = torch.optim.Adam(pinn_net.parameters(), lr=0.001)\n",
    "\n",
    "pinn_trainer = Training.PINNTrainer(\n",
    "    pinn_net, data, pinn_loss, optimizer,\n",
    "    input_normalization_pinn, num_epochs=10000\n",
    ")\n",
    "\n",
    "loaded, starting_epoch = IO.initialize_parameters(\n",
    "    pinn_net, data, pinn_trainer, optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pinn_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = Training.plot_loss(pinn_trainer, pinn_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.3 Train PDNN\n",
    "\n",
    "Given a training set $X_{PDNN} = ((\\boldsymbol{\\mu}^{(1)}, \\operatorname{HF}(\\boldsymbol{\\mu}^{(1)})), \\dots, (\\boldsymbol{\\mu}^{(n)}, \\operatorname{HF}(\\boldsymbol{\\mu}^{(n)})))$ of parameter and high fidelity solution pairs for the PDE, we train a Projection-Driven Neural Network (PDNN) $\\operatorname{N}_W(\\boldsymbol{\\mu})$ dependent on the weights and biases $W$ of the network to minimize the loss function\n",
    "$$L_{PDNN}(X_{PDNN}; W) = \\frac1n \\sum_{i=1}^n \\|\\operatorname{N}_W(\\boldsymbol{\\mu}^{(i)}) - \\tilde{\\operatorname{HF}}(\\boldsymbol{\\mu}^{(i)})\\|_2^2,$$\n",
    "where for a given $\\boldsymbol{\\mu}$, $\\tilde{\\operatorname{HF}}(\\boldsymbol{\\mu})$ is the projection of $\\operatorname{HF}(\\boldsymbol{\\mu})$ onto the reduced order solution space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_normalization_pdnn = Normalization.StandardNormalization(input_normalization=True)\n",
    "output_normalization_pdnn = Normalization.StandardNormalization()\n",
    "\n",
    "pdnn_net  = NN.RONN(\"PDNN\", problem, reduction_method, n_hidden=2, n_neurons=40)\n",
    "pdnn_loss = Losses.PDNN_Loss(pdnn_net, output_normalization_pdnn)\n",
    "data      = RONNData.RONNDataLoader(pdnn_net, validation_proportion=0.2)\n",
    "optimizer = torch.optim.Adam(pdnn_net.parameters(), lr=0.001)\n",
    "\n",
    "pdnn_trainer = Training.PDNNTrainer(\n",
    "    pdnn_net, data, pdnn_loss, optimizer,\n",
    "    input_normalization_pdnn, num_epochs=10000\n",
    ")\n",
    "\n",
    "loaded, starting_epoch = IO.initialize_parameters(\n",
    "    pdnn_net, data, pdnn_trainer, optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdnn_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = Training.plot_loss(pdnn_trainer, pdnn_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.4 Train PRNN\n",
    "\n",
    "We train a Physics-Reinforced Neural Network (PRNN) $N_W(\\boldsymbol{\\mu})$ dependnent on the weights and biases $W$ of the network to minimize the loss function\n",
    "\n",
    "$$L_{PRNN}(X_{PINN}, X_{PDNN}; W) = L_{PINN}(X_{PINN}; W) + \\omega L_{PDNN}(X_{PDNN}; W),$$\n",
    "\n",
    "where $\\omega$ is a scaling parameter which can be chosen freely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_normalization_prnn = Normalization.StandardNormalization(input_normalization=True)\n",
    "output_normalization_prnn = Normalization.StandardNormalization()\n",
    "\n",
    "omega = 1.\n",
    "prnn_net  = NN.RONN(f\"PRNN_{omega}\", problem, reduction_method, n_hidden=2, n_neurons=40)\n",
    "prnn_loss = Losses.PRNN_Loss(prnn_net, output_normalization_prnn, omega=omega)\n",
    "data      = RONNData.RONNDataLoader(prnn_net, validation_proportion=0.2,\n",
    "                                    num_without_snapshots=100)\n",
    "optimizer = torch.optim.Adam(prnn_net.parameters(), lr=0.001)\n",
    "\n",
    "prnn_trainer = Training.PRNNTrainer(\n",
    "    prnn_net, data, prnn_loss, optimizer,\n",
    "    input_normalization_prnn, num_epochs=10000\n",
    ")\n",
    "\n",
    "loaded, starting_epoch = IO.initialize_parameters(\n",
    "    prnn_net, data, prnn_trainer, optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prnn_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = Training.plot_loss(prnn_trainer, prnn_net, separate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6. Perform an error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.1 Reduction Method Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction_method.initialize_testing_set(16, DEIM=25, sampling=EquispacedDistribution())\n",
    "reduction_method.error_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.2 PINN Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mu = torch.tensor(reduction_method.testing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = ErrorAnalysis.error_analysis_fixed_net(\n",
    "    pinn_net, test_mu, input_normalization_pinn, output_normalization_pinn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ErrorAnalysis.plot_solution_difference(\n",
    "    pinn_net, (10.0,), \n",
    "    input_normalization_pinn, output_normalization_pinn, \n",
    "    colorbar=True, component=\"u\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.3 PDNN Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ErrorAnalysis.error_analysis_fixed_net(\n",
    "    pdnn_net, test_mu, input_normalization_pdnn, output_normalization_pdnn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ErrorAnalysis.plot_solution_difference(\n",
    "    pdnn_net, (10.0,), \n",
    "    input_normalization_pdnn, output_normalization_pdnn,\n",
    "    colorbar=True, component=\"u\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.4 PRNN Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ErrorAnalysis.error_analysis_fixed_net(\n",
    "    prnn_net, test_mu, input_normalization_prnn, output_normalization_prnn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ErrorAnalysis.plot_solution_difference(\n",
    "    prnn_net, (10.0,), \n",
    "    input_normalization_prnn, output_normalization_prnn,\n",
    "    colorbar=True, component=\"u\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.5 Neural Network Error Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nets = dict()\n",
    "nets[\"pinn_net\"] = pinn_net\n",
    "nets[\"pdnn_net\"] = pdnn_net\n",
    "nets[\"prnn_net\"] = prnn_net\n",
    "\n",
    "input_normalizations = dict()\n",
    "input_normalizations[\"pinn_net\"] = input_normalization_pinn\n",
    "input_normalizations[\"pdnn_net\"] = input_normalization_pdnn\n",
    "input_normalizations[\"prnn_net\"] = input_normalization_prnn\n",
    "\n",
    "output_normalizations = dict()\n",
    "output_normalizations[\"pinn_net\"] = output_normalization_pinn\n",
    "output_normalizations[\"pdnn_net\"] = output_normalization_pdnn\n",
    "output_normalizations[\"prnn_net\"] = output_normalization_prnn\n",
    "\n",
    "_ = ErrorAnalysis.error_analysis_by_network(\n",
    "    nets, test_mu, input_normalizations, output_normalizations, euclidean=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7. Perform a speedup analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction_method.speedup_analysis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
